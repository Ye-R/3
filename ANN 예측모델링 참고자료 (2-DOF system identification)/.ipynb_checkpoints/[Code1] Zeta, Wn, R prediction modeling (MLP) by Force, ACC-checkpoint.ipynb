{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows',    100)      # DataFrame 데이터 확인 시 최대 표시 행 수\n",
    "pd.set_option('display.max_columns', 100)      # DataFrame 데이터 확인 시 최대 표시 열 수"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sb\n",
    "import scipy.stats       as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.random.set_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일러 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wn, R 값 예측용 학습 레이블 + 특징데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>62.346819</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>18.819444</td>\n",
       "      <td>42.663128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>732.288395</td>\n",
       "      <td>1.0</td>\n",
       "      <td>469.290044</td>\n",
       "      <td>0.036390</td>\n",
       "      <td>62.3</td>\n",
       "      <td>8.285670</td>\n",
       "      <td>1.678860</td>\n",
       "      <td>12.199542</td>\n",
       "      <td>0.077772</td>\n",
       "      <td>208.100000</td>\n",
       "      <td>3.321399</td>\n",
       "      <td>1.291597</td>\n",
       "      <td>1.055578</td>\n",
       "      <td>0.970291</td>\n",
       "      <td>50.389497</td>\n",
       "      <td>353.396089</td>\n",
       "      <td>11.517543</td>\n",
       "      <td>887.431640</td>\n",
       "      <td>48.892481</td>\n",
       "      <td>48.892481</td>\n",
       "      <td>357.444026</td>\n",
       "      <td>11.649530</td>\n",
       "      <td>887.224665</td>\n",
       "      <td>0.900127</td>\n",
       "      <td>28.908205</td>\n",
       "      <td>236.794175</td>\n",
       "      <td>8.316594</td>\n",
       "      <td>671.664158</td>\n",
       "      <td>26.021061</td>\n",
       "      <td>26.021061</td>\n",
       "      <td>245.048963</td>\n",
       "      <td>8.606972</td>\n",
       "      <td>670.635833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62.346819</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>18.819444</td>\n",
       "      <td>42.663128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>473.807821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>682.449602</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>62.2</td>\n",
       "      <td>6.304050</td>\n",
       "      <td>1.408511</td>\n",
       "      <td>11.360424</td>\n",
       "      <td>0.077981</td>\n",
       "      <td>208.100000</td>\n",
       "      <td>3.215684</td>\n",
       "      <td>1.265030</td>\n",
       "      <td>1.132055</td>\n",
       "      <td>0.844457</td>\n",
       "      <td>49.881039</td>\n",
       "      <td>189.391803</td>\n",
       "      <td>7.090905</td>\n",
       "      <td>540.854766</td>\n",
       "      <td>42.122382</td>\n",
       "      <td>42.122382</td>\n",
       "      <td>188.929868</td>\n",
       "      <td>7.073497</td>\n",
       "      <td>540.957119</td>\n",
       "      <td>0.956998</td>\n",
       "      <td>31.945800</td>\n",
       "      <td>314.973439</td>\n",
       "      <td>10.407146</td>\n",
       "      <td>842.448885</td>\n",
       "      <td>30.572066</td>\n",
       "      <td>30.572066</td>\n",
       "      <td>315.966464</td>\n",
       "      <td>10.439829</td>\n",
       "      <td>842.425164</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62.346819</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>18.819444</td>\n",
       "      <td>42.663128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>900.055637</td>\n",
       "      <td>1.0</td>\n",
       "      <td>893.455418</td>\n",
       "      <td>0.015511</td>\n",
       "      <td>208.3</td>\n",
       "      <td>3.317409</td>\n",
       "      <td>1.304131</td>\n",
       "      <td>0.765970</td>\n",
       "      <td>1.000099</td>\n",
       "      <td>22.415223</td>\n",
       "      <td>952.238465</td>\n",
       "      <td>30.112858</td>\n",
       "      <td>994.948496</td>\n",
       "      <td>22.417446</td>\n",
       "      <td>22.417446</td>\n",
       "      <td>921.020446</td>\n",
       "      <td>29.125669</td>\n",
       "      <td>994.954680</td>\n",
       "      <td>0.999922</td>\n",
       "      <td>22.264137</td>\n",
       "      <td>477.666714</td>\n",
       "      <td>21.360747</td>\n",
       "      <td>494.937548</td>\n",
       "      <td>22.262395</td>\n",
       "      <td>22.262395</td>\n",
       "      <td>471.141840</td>\n",
       "      <td>20.998106</td>\n",
       "      <td>494.964056</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>62.346819</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>18.819444</td>\n",
       "      <td>42.663128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>306.061520</td>\n",
       "      <td>1.0</td>\n",
       "      <td>387.123464</td>\n",
       "      <td>0.081118</td>\n",
       "      <td>62.4</td>\n",
       "      <td>8.130715</td>\n",
       "      <td>1.680750</td>\n",
       "      <td>10.952507</td>\n",
       "      <td>0.241797</td>\n",
       "      <td>208.500000</td>\n",
       "      <td>3.232120</td>\n",
       "      <td>1.313286</td>\n",
       "      <td>0.218982</td>\n",
       "      <td>0.913739</td>\n",
       "      <td>84.606953</td>\n",
       "      <td>233.474654</td>\n",
       "      <td>8.078741</td>\n",
       "      <td>710.988133</td>\n",
       "      <td>77.308657</td>\n",
       "      <td>77.308657</td>\n",
       "      <td>230.815485</td>\n",
       "      <td>7.987224</td>\n",
       "      <td>711.180320</td>\n",
       "      <td>0.724451</td>\n",
       "      <td>61.952396</td>\n",
       "      <td>115.614670</td>\n",
       "      <td>5.655271</td>\n",
       "      <td>271.639590</td>\n",
       "      <td>44.881473</td>\n",
       "      <td>44.881473</td>\n",
       "      <td>136.766349</td>\n",
       "      <td>5.862931</td>\n",
       "      <td>349.742017</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>62.346819</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>0.020533</td>\n",
       "      <td>0.024944</td>\n",
       "      <td>18.819444</td>\n",
       "      <td>42.663128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>611.271481</td>\n",
       "      <td>1.0</td>\n",
       "      <td>470.678625</td>\n",
       "      <td>0.043269</td>\n",
       "      <td>62.4</td>\n",
       "      <td>8.112951</td>\n",
       "      <td>1.669590</td>\n",
       "      <td>11.349660</td>\n",
       "      <td>0.094189</td>\n",
       "      <td>208.300000</td>\n",
       "      <td>3.334917</td>\n",
       "      <td>1.305788</td>\n",
       "      <td>0.818104</td>\n",
       "      <td>0.999246</td>\n",
       "      <td>50.226717</td>\n",
       "      <td>773.283513</td>\n",
       "      <td>24.472135</td>\n",
       "      <td>992.110533</td>\n",
       "      <td>50.188837</td>\n",
       "      <td>50.188837</td>\n",
       "      <td>741.716481</td>\n",
       "      <td>23.473399</td>\n",
       "      <td>992.135108</td>\n",
       "      <td>0.999297</td>\n",
       "      <td>37.040093</td>\n",
       "      <td>786.538157</td>\n",
       "      <td>24.889629</td>\n",
       "      <td>992.402600</td>\n",
       "      <td>37.014062</td>\n",
       "      <td>37.014062</td>\n",
       "      <td>710.634156</td>\n",
       "      <td>22.488347</td>\n",
       "      <td>992.467940</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>227.002988</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>0.010698</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>82.645020</td>\n",
       "      <td>17.658259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>739.315511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>320.164171</td>\n",
       "      <td>0.810251</td>\n",
       "      <td>227.1</td>\n",
       "      <td>5.955234</td>\n",
       "      <td>1.614085</td>\n",
       "      <td>4.617579</td>\n",
       "      <td>0.936557</td>\n",
       "      <td>233.483456</td>\n",
       "      <td>269.580098</td>\n",
       "      <td>9.101260</td>\n",
       "      <td>777.529216</td>\n",
       "      <td>218.670632</td>\n",
       "      <td>218.670632</td>\n",
       "      <td>260.609075</td>\n",
       "      <td>8.800788</td>\n",
       "      <td>777.611577</td>\n",
       "      <td>0.667817</td>\n",
       "      <td>48.860549</td>\n",
       "      <td>136.984261</td>\n",
       "      <td>6.483044</td>\n",
       "      <td>340.747136</td>\n",
       "      <td>32.629894</td>\n",
       "      <td>32.629894</td>\n",
       "      <td>135.822030</td>\n",
       "      <td>6.428241</td>\n",
       "      <td>340.895343</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>227.002988</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>0.010698</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>82.645020</td>\n",
       "      <td>17.658259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>315.056388</td>\n",
       "      <td>1.0</td>\n",
       "      <td>955.733028</td>\n",
       "      <td>0.778914</td>\n",
       "      <td>227.1</td>\n",
       "      <td>5.846152</td>\n",
       "      <td>1.604307</td>\n",
       "      <td>4.294153</td>\n",
       "      <td>0.877040</td>\n",
       "      <td>256.684120</td>\n",
       "      <td>206.270145</td>\n",
       "      <td>7.436043</td>\n",
       "      <td>614.143711</td>\n",
       "      <td>225.122162</td>\n",
       "      <td>225.122162</td>\n",
       "      <td>204.931433</td>\n",
       "      <td>7.390423</td>\n",
       "      <td>613.533329</td>\n",
       "      <td>0.940453</td>\n",
       "      <td>35.855883</td>\n",
       "      <td>275.305103</td>\n",
       "      <td>9.255789</td>\n",
       "      <td>789.781285</td>\n",
       "      <td>33.720774</td>\n",
       "      <td>33.720774</td>\n",
       "      <td>274.103507</td>\n",
       "      <td>9.215484</td>\n",
       "      <td>789.861916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>227.002988</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>0.010698</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>82.645020</td>\n",
       "      <td>17.658259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>825.670525</td>\n",
       "      <td>1.0</td>\n",
       "      <td>416.316746</td>\n",
       "      <td>0.392901</td>\n",
       "      <td>227.0</td>\n",
       "      <td>5.720511</td>\n",
       "      <td>1.550430</td>\n",
       "      <td>5.102091</td>\n",
       "      <td>0.053255</td>\n",
       "      <td>302.800000</td>\n",
       "      <td>1.491456</td>\n",
       "      <td>1.072172</td>\n",
       "      <td>-1.106293</td>\n",
       "      <td>0.783496</td>\n",
       "      <td>115.088094</td>\n",
       "      <td>161.558070</td>\n",
       "      <td>6.519259</td>\n",
       "      <td>436.104103</td>\n",
       "      <td>90.171079</td>\n",
       "      <td>90.171079</td>\n",
       "      <td>160.518134</td>\n",
       "      <td>6.477050</td>\n",
       "      <td>436.323107</td>\n",
       "      <td>0.977166</td>\n",
       "      <td>41.489814</td>\n",
       "      <td>388.334066</td>\n",
       "      <td>12.566214</td>\n",
       "      <td>911.607984</td>\n",
       "      <td>40.542454</td>\n",
       "      <td>40.542454</td>\n",
       "      <td>382.365099</td>\n",
       "      <td>12.373180</td>\n",
       "      <td>911.791538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>227.002988</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>0.010698</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>82.645020</td>\n",
       "      <td>17.658259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>649.504305</td>\n",
       "      <td>1.0</td>\n",
       "      <td>343.395226</td>\n",
       "      <td>0.667726</td>\n",
       "      <td>227.0</td>\n",
       "      <td>5.558074</td>\n",
       "      <td>1.511400</td>\n",
       "      <td>5.362551</td>\n",
       "      <td>0.084570</td>\n",
       "      <td>302.100000</td>\n",
       "      <td>367.906940</td>\n",
       "      <td>11.933460</td>\n",
       "      <td>903.806963</td>\n",
       "      <td>0.974940</td>\n",
       "      <td>175.636801</td>\n",
       "      <td>395.519228</td>\n",
       "      <td>12.827796</td>\n",
       "      <td>903.142022</td>\n",
       "      <td>171.235331</td>\n",
       "      <td>171.235331</td>\n",
       "      <td>391.288854</td>\n",
       "      <td>12.690817</td>\n",
       "      <td>903.218944</td>\n",
       "      <td>0.791740</td>\n",
       "      <td>59.651483</td>\n",
       "      <td>223.107106</td>\n",
       "      <td>8.817297</td>\n",
       "      <td>460.540479</td>\n",
       "      <td>47.228468</td>\n",
       "      <td>47.228468</td>\n",
       "      <td>227.033053</td>\n",
       "      <td>8.972035</td>\n",
       "      <td>460.426707</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>227.002988</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>0.010698</td>\n",
       "      <td>0.027413</td>\n",
       "      <td>82.645020</td>\n",
       "      <td>17.658259</td>\n",
       "      <td>1.0</td>\n",
       "      <td>853.576719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>427.321089</td>\n",
       "      <td>0.365768</td>\n",
       "      <td>227.0</td>\n",
       "      <td>5.792249</td>\n",
       "      <td>1.567324</td>\n",
       "      <td>5.016526</td>\n",
       "      <td>0.050924</td>\n",
       "      <td>302.300000</td>\n",
       "      <td>1.392429</td>\n",
       "      <td>1.061703</td>\n",
       "      <td>-1.083384</td>\n",
       "      <td>0.728745</td>\n",
       "      <td>110.255895</td>\n",
       "      <td>146.875255</td>\n",
       "      <td>6.371550</td>\n",
       "      <td>374.738070</td>\n",
       "      <td>80.348446</td>\n",
       "      <td>80.348446</td>\n",
       "      <td>145.529232</td>\n",
       "      <td>6.312909</td>\n",
       "      <td>374.975624</td>\n",
       "      <td>0.939157</td>\n",
       "      <td>39.723994</td>\n",
       "      <td>272.940037</td>\n",
       "      <td>9.189226</td>\n",
       "      <td>785.655518</td>\n",
       "      <td>37.307059</td>\n",
       "      <td>37.307059</td>\n",
       "      <td>271.933258</td>\n",
       "      <td>9.155256</td>\n",
       "      <td>785.775448</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 60 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1         2         3          4          5    6  \\\n",
       "0      62.346819  208.003436  0.020533  0.024944  18.819444  42.663128  1.0   \n",
       "1      62.346819  208.003436  0.020533  0.024944  18.819444  42.663128  1.0   \n",
       "2      62.346819  208.003436  0.020533  0.024944  18.819444  42.663128  1.0   \n",
       "3      62.346819  208.003436  0.020533  0.024944  18.819444  42.663128  1.0   \n",
       "4      62.346819  208.003436  0.020533  0.024944  18.819444  42.663128  1.0   \n",
       "...          ...         ...       ...       ...        ...        ...  ...   \n",
       "7995  227.002988  295.707652  0.010698  0.027413  82.645020  17.658259  1.0   \n",
       "7996  227.002988  295.707652  0.010698  0.027413  82.645020  17.658259  1.0   \n",
       "7997  227.002988  295.707652  0.010698  0.027413  82.645020  17.658259  1.0   \n",
       "7998  227.002988  295.707652  0.010698  0.027413  82.645020  17.658259  1.0   \n",
       "7999  227.002988  295.707652  0.010698  0.027413  82.645020  17.658259  1.0   \n",
       "\n",
       "               7    8           9        10     11        12        13  \\\n",
       "0     732.288395  1.0  469.290044  0.036390   62.3  8.285670  1.678860   \n",
       "1     473.807821  1.0  682.449602  0.037553   62.2  6.304050  1.408511   \n",
       "2     900.055637  1.0  893.455418  0.015511  208.3  3.317409  1.304131   \n",
       "3     306.061520  1.0  387.123464  0.081118   62.4  8.130715  1.680750   \n",
       "4     611.271481  1.0  470.678625  0.043269   62.4  8.112951  1.669590   \n",
       "...          ...  ...         ...       ...    ...       ...       ...   \n",
       "7995  739.315511  1.0  320.164171  0.810251  227.1  5.955234  1.614085   \n",
       "7996  315.056388  1.0  955.733028  0.778914  227.1  5.846152  1.604307   \n",
       "7997  825.670525  1.0  416.316746  0.392901  227.0  5.720511  1.550430   \n",
       "7998  649.504305  1.0  343.395226  0.667726  227.0  5.558074  1.511400   \n",
       "7999  853.576719  1.0  427.321089  0.365768  227.0  5.792249  1.567324   \n",
       "\n",
       "             14        15          16          17         18          19  \\\n",
       "0     12.199542  0.077772  208.100000    3.321399   1.291597    1.055578   \n",
       "1     11.360424  0.077981  208.100000    3.215684   1.265030    1.132055   \n",
       "2      0.765970  1.000099   22.415223  952.238465  30.112858  994.948496   \n",
       "3     10.952507  0.241797  208.500000    3.232120   1.313286    0.218982   \n",
       "4     11.349660  0.094189  208.300000    3.334917   1.305788    0.818104   \n",
       "...         ...       ...         ...         ...        ...         ...   \n",
       "7995   4.617579  0.936557  233.483456  269.580098   9.101260  777.529216   \n",
       "7996   4.294153  0.877040  256.684120  206.270145   7.436043  614.143711   \n",
       "7997   5.102091  0.053255  302.800000    1.491456   1.072172   -1.106293   \n",
       "7998   5.362551  0.084570  302.100000  367.906940  11.933460  903.806963   \n",
       "7999   5.016526  0.050924  302.300000    1.392429   1.061703   -1.083384   \n",
       "\n",
       "              20          21          22         23          24          25  \\\n",
       "0       0.970291   50.389497  353.396089  11.517543  887.431640   48.892481   \n",
       "1       0.844457   49.881039  189.391803   7.090905  540.854766   42.122382   \n",
       "2      22.417446   22.417446  921.020446  29.125669  994.954680    0.999922   \n",
       "3       0.913739   84.606953  233.474654   8.078741  710.988133   77.308657   \n",
       "4       0.999246   50.226717  773.283513  24.472135  992.110533   50.188837   \n",
       "...          ...         ...         ...        ...         ...         ...   \n",
       "7995  218.670632  218.670632  260.609075   8.800788  777.611577    0.667817   \n",
       "7996  225.122162  225.122162  204.931433   7.390423  613.533329    0.940453   \n",
       "7997    0.783496  115.088094  161.558070   6.519259  436.104103   90.171079   \n",
       "7998    0.974940  175.636801  395.519228  12.827796  903.142022  171.235331   \n",
       "7999    0.728745  110.255895  146.875255   6.371550  374.738070   80.348446   \n",
       "\n",
       "              26          27         28          29         30         31  \\\n",
       "0      48.892481  357.444026  11.649530  887.224665   0.900127  28.908205   \n",
       "1      42.122382  188.929868   7.073497  540.957119   0.956998  31.945800   \n",
       "2      22.264137  477.666714  21.360747  494.937548  22.262395  22.262395   \n",
       "3      77.308657  230.815485   7.987224  711.180320   0.724451  61.952396   \n",
       "4      50.188837  741.716481  23.473399  992.135108   0.999297  37.040093   \n",
       "...          ...         ...        ...         ...        ...        ...   \n",
       "7995   48.860549  136.984261   6.483044  340.747136  32.629894  32.629894   \n",
       "7996   35.855883  275.305103   9.255789  789.781285  33.720774  33.720774   \n",
       "7997   90.171079  160.518134   6.477050  436.323107   0.977166  41.489814   \n",
       "7998  171.235331  391.288854  12.690817  903.218944   0.791740  59.651483   \n",
       "7999   80.348446  145.529232   6.312909  374.975624   0.939157  39.723994   \n",
       "\n",
       "              32         33          34         35         36          37  \\\n",
       "0     236.794175   8.316594  671.664158  26.021061  26.021061  245.048963   \n",
       "1     314.973439  10.407146  842.448885  30.572066  30.572066  315.966464   \n",
       "2     471.141840  20.998106  494.964056   0.000000   0.000000    0.000000   \n",
       "3     115.614670   5.655271  271.639590  44.881473  44.881473  136.766349   \n",
       "4     786.538157  24.889629  992.402600  37.014062  37.014062  710.634156   \n",
       "...          ...        ...         ...        ...        ...         ...   \n",
       "7995  135.822030   6.428241  340.895343   0.000000   0.000000    0.000000   \n",
       "7996  274.103507   9.215484  789.861916   0.000000   0.000000    0.000000   \n",
       "7997  388.334066  12.566214  911.607984  40.542454  40.542454  382.365099   \n",
       "7998  223.107106   8.817297  460.540479  47.228468  47.228468  227.033053   \n",
       "7999  272.940037   9.189226  785.655518  37.307059  37.307059  271.933258   \n",
       "\n",
       "             38          39   40   41   42   43   44   45   46   47   48   49  \\\n",
       "0      8.606972  670.635833  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     10.439829  842.425164  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2      0.000000    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3      5.862931  349.742017  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     22.488347  992.467940  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "...         ...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "7995   0.000000    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7996   0.000000    0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7997  12.373180  911.791538  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7998   8.972035  460.426707  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "7999   9.155256  785.775448  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "       50   51   52   53   54   55   56   57   58   59  \n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "7995  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7996  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7997  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7998  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "7999  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[8000 rows x 60 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeatureData_trn1 = pd.read_csv('Data/FeatureData_training.csv', sep=',').head(8000)\n",
    "FeatureData_trn1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeta(damping ratio)값 예측용 학습 레이블 + 특징데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>62.346819</td>\n",
       "      <td>63.096845</td>\n",
       "      <td>61.996900</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>211.889405</td>\n",
       "      <td>207.189640</td>\n",
       "      <td>0.011297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>62.346819</td>\n",
       "      <td>62.896855</td>\n",
       "      <td>61.896905</td>\n",
       "      <td>0.008019</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>210.789460</td>\n",
       "      <td>206.389680</td>\n",
       "      <td>0.010576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>62.346819</td>\n",
       "      <td>62.896855</td>\n",
       "      <td>63.496825</td>\n",
       "      <td>0.004812</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>208.789560</td>\n",
       "      <td>209.289535</td>\n",
       "      <td>0.001202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>62.346819</td>\n",
       "      <td>62.796860</td>\n",
       "      <td>61.696915</td>\n",
       "      <td>0.008821</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>209.089545</td>\n",
       "      <td>204.689765</td>\n",
       "      <td>0.010576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>62.346819</td>\n",
       "      <td>63.696815</td>\n",
       "      <td>62.196890</td>\n",
       "      <td>0.012029</td>\n",
       "      <td>208.003436</td>\n",
       "      <td>212.789360</td>\n",
       "      <td>207.989600</td>\n",
       "      <td>0.011538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7995</td>\n",
       "      <td>227.002988</td>\n",
       "      <td>227.388630</td>\n",
       "      <td>225.188740</td>\n",
       "      <td>0.004846</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>296.785160</td>\n",
       "      <td>289.585520</td>\n",
       "      <td>0.012174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7996</td>\n",
       "      <td>227.002988</td>\n",
       "      <td>227.488625</td>\n",
       "      <td>225.488725</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>297.385130</td>\n",
       "      <td>290.385480</td>\n",
       "      <td>0.011835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7997</td>\n",
       "      <td>227.002988</td>\n",
       "      <td>228.288585</td>\n",
       "      <td>226.288685</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>299.885005</td>\n",
       "      <td>293.085345</td>\n",
       "      <td>0.011497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7998</td>\n",
       "      <td>227.002988</td>\n",
       "      <td>228.988550</td>\n",
       "      <td>226.688665</td>\n",
       "      <td>0.005066</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>285.585720</td>\n",
       "      <td>294.785260</td>\n",
       "      <td>0.015555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7999</td>\n",
       "      <td>227.002988</td>\n",
       "      <td>228.188590</td>\n",
       "      <td>226.188690</td>\n",
       "      <td>0.004405</td>\n",
       "      <td>295.707652</td>\n",
       "      <td>299.485025</td>\n",
       "      <td>292.685365</td>\n",
       "      <td>0.011497</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0           1           2         3           4           5  \\\n",
       "0      62.346819   63.096845   61.996900  0.008821  208.003436  211.889405   \n",
       "1      62.346819   62.896855   61.896905  0.008019  208.003436  210.789460   \n",
       "2      62.346819   62.896855   63.496825  0.004812  208.003436  208.789560   \n",
       "3      62.346819   62.796860   61.696915  0.008821  208.003436  209.089545   \n",
       "4      62.346819   63.696815   62.196890  0.012029  208.003436  212.789360   \n",
       "...          ...         ...         ...       ...         ...         ...   \n",
       "7995  227.002988  227.388630  225.188740  0.004846  295.707652  296.785160   \n",
       "7996  227.002988  227.488625  225.488725  0.004405  295.707652  297.385130   \n",
       "7997  227.002988  228.288585  226.288685  0.004405  295.707652  299.885005   \n",
       "7998  227.002988  228.988550  226.688665  0.005066  295.707652  285.585720   \n",
       "7999  227.002988  228.188590  226.188690  0.004405  295.707652  299.485025   \n",
       "\n",
       "               6         7  \n",
       "0     207.189640  0.011297  \n",
       "1     206.389680  0.010576  \n",
       "2     209.289535  0.001202  \n",
       "3     204.689765  0.010576  \n",
       "4     207.989600  0.011538  \n",
       "...          ...       ...  \n",
       "7995  289.585520  0.012174  \n",
       "7996  290.385480  0.011835  \n",
       "7997  293.085345  0.011497  \n",
       "7998  294.785260  0.015555  \n",
       "7999  292.685365  0.011497  \n",
       "\n",
       "[8000 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FeatureData_trn2 = pd.read_csv('Data/Damping_training.csv', sep=',').head(8000)\n",
    "FeatureData_trn2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특징데이터 세트 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((8000, 50),\n",
       " (16000, 4),\n",
       " (8000, 1),\n",
       " (8000, 1),\n",
       " (8000, 1),\n",
       " (8000, 1),\n",
       " (16000, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData1   = np.array(FeatureData_trn1.iloc[:,10:])\n",
    "TrainData2 = np.array(FeatureData_trn2.iloc[:,:4])\n",
    "TrainData3 = np.array(FeatureData_trn2.iloc[:,4:])\n",
    "TrainData_zeta = np.concatenate([TrainData2, TrainData3], axis=0)\n",
    "\n",
    "TrainLabel_1 = np.array(FeatureData_trn1.iloc[:,0])[:, np.newaxis] # Wn1 - Feature1\n",
    "TrainLabel_2 = np.array(FeatureData_trn1.iloc[:,1])[:, np.newaxis] # Wn2 - Feature1\n",
    "TrainLabel_3 = np.array(FeatureData_trn1.iloc[:,4])[:, np.newaxis] # R1 - Feature1\n",
    "TrainLabel_4 = np.array(FeatureData_trn1.iloc[:,5])[:, np.newaxis] # R2 - Feature1\n",
    "\n",
    "TrainLabel_5 = np.array(FeatureData_trn1.iloc[:,2])[:, np.newaxis] # Zeta1 - Feature2\n",
    "TrainLabel_6 = np.array(FeatureData_trn1.iloc[:,3])[:, np.newaxis] # Zeta2 - Feature2\n",
    "TrainLabel_zeta = np.concatenate([TrainLabel_5, TrainLabel_6], axis=0)\n",
    "\n",
    "TrainData1.shape, TrainData_zeta.shape, TrainLabel_1.shape, TrainLabel_2.shape, TrainLabel_3.shape, TrainLabel_4.shape, TrainLabel_zeta.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터, 레이블 최종 지정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zeta 레이블에 대한 min-max 스케일러 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scalers/scaler_label_zeta_0410.save']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Scaler_label_zeta   = MinMaxScaler()\n",
    "TrainLabel_zeta_std = Scaler_label_zeta.fit_transform(TrainLabel_zeta)\n",
    "scaler_filename     = \"Scalers/scaler_label_zeta_0410.save\"\n",
    "joblib.dump(Scaler_label_zeta, scaler_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(777)\n",
    "\n",
    "Data_Trn  = TrainData1\n",
    "Label_Trn1 = TrainLabel_1\n",
    "Label_Trn2 = TrainLabel_2\n",
    "Label_Trn3 = TrainLabel_3\n",
    "Label_Trn4 = TrainLabel_4\n",
    "\n",
    "Data_Trn_zeta  = TrainData_zeta\n",
    "Label_Trn_zeta = TrainLabel_zeta_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN hyperparameter 조절에 따른 학습성능 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지정 iteration마다 학습과정 확인 함수(Class) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "EpochForPrint = 100\n",
    "\n",
    "class AccuracyPerEpoch(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keras.callbacks.Callback()\n",
    "        if epoch%EpochForPrint == 0:\n",
    "            print(\"[{} Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "                  .format(epoch, np.sqrt(logs['mse']), logs['mae'], logs['mape']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter 조합 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of case : 15\n"
     ]
    }
   ],
   "source": [
    "# 조정 하이퍼파라미터 : 학습율, 은닉층 뉴런 수\n",
    "Lr = [0.001, 0.005, 0.01]   # Learning Rates\n",
    "N1 = [30, 40, 50, 60, 70]   # Number of Neurons on Hidden Layer 1\n",
    "N2 = [10, 20, 30]           # Number of Neurons on Hidden Layer 2\n",
    "\n",
    "Model = ['Wn1', 'Wn2', 'R1', 'R2']\n",
    "\n",
    "# 고정 하이퍼파라미터 : 입력/출력층 뉴런 수, 학습 Epoch 수\n",
    "noOfNeuron_in  = 50\n",
    "noOfNeuron_out = 1\n",
    "Epoch          = 2000\n",
    "\n",
    "print('Number of case : %d'%(len(Lr)*len(N1)*len(N2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 1 - FFT 특징 기반 Wn1, Wn2, R1, R2 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "################## Model 1 (Predict :Wn1) ##################\n",
      "\n",
      "\n",
      "Trial No.1\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:73.40704,   MAE: 56.53463,  MAPE: 63.85%\n",
      "[200 Epochs]    RMSE:13.56700,   MAE: 4.55049,  MAPE: 6.67%\n",
      "[400 Epochs]    RMSE:12.97177,   MAE: 3.77799,  MAPE: 5.68%\n",
      "[600 Epochs]    RMSE:12.20107,   MAE: 3.08755,  MAPE: 4.68%\n",
      "[800 Epochs]    RMSE:11.77123,   MAE: 3.23404,  MAPE: 4.84%\n",
      "[1000 Epochs]    RMSE:10.89552,   MAE: 2.64660,  MAPE: 4.09%\n",
      "[1200 Epochs]    RMSE:11.06816,   MAE: 2.78884,  MAPE: 4.26%\n",
      "[1400 Epochs]    RMSE:9.88793,   MAE: 2.60037,  MAPE: 3.95%\n",
      "[1600 Epochs]    RMSE:9.42656,   MAE: 2.07710,  MAPE: 3.19%\n",
      "[1800 Epochs]    RMSE:9.42454,   MAE: 2.17153,  MAPE: 3.29%\n",
      "\n",
      "[Final Epochs]    RMSE:9.04424,   MAE: 1.93900,  MAPE: 2.96%\n",
      "\n",
      "\n",
      "Trial No.2\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:55.88117,   MAE: 42.65493,  MAPE: 52.08%\n",
      "[200 Epochs]    RMSE:13.71653,   MAE: 4.53971,  MAPE: 6.56%\n",
      "[400 Epochs]    RMSE:12.37975,   MAE: 3.60423,  MAPE: 5.48%\n",
      "[600 Epochs]    RMSE:11.53770,   MAE: 3.11155,  MAPE: 4.86%\n",
      "[800 Epochs]    RMSE:10.50381,   MAE: 2.50521,  MAPE: 3.97%\n",
      "[1000 Epochs]    RMSE:8.67247,   MAE: 2.19344,  MAPE: 3.08%\n",
      "[1200 Epochs]    RMSE:8.08931,   MAE: 2.15640,  MAPE: 3.08%\n",
      "[1400 Epochs]    RMSE:7.76725,   MAE: 1.96396,  MAPE: 2.84%\n",
      "[1600 Epochs]    RMSE:7.56038,   MAE: 1.77150,  MAPE: 2.58%\n",
      "[1800 Epochs]    RMSE:7.16200,   MAE: 1.65519,  MAPE: 2.31%\n",
      "\n",
      "[Final Epochs]    RMSE:6.90606,   MAE: 1.65923,  MAPE: 2.40%\n",
      "\n",
      "\n",
      "Trial No.3\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:49.45824,   MAE: 38.13894,  MAPE: 48.30%\n",
      "[200 Epochs]    RMSE:12.50080,   MAE: 3.38000,  MAPE: 5.76%\n",
      "[400 Epochs]    RMSE:11.42323,   MAE: 3.03644,  MAPE: 4.99%\n",
      "[600 Epochs]    RMSE:9.88659,   MAE: 2.38341,  MAPE: 3.50%\n",
      "[800 Epochs]    RMSE:9.31334,   MAE: 2.11898,  MAPE: 3.14%\n",
      "[1000 Epochs]    RMSE:8.54172,   MAE: 1.82319,  MAPE: 2.64%\n",
      "[1200 Epochs]    RMSE:7.91444,   MAE: 1.76803,  MAPE: 2.50%\n",
      "[1400 Epochs]    RMSE:7.65993,   MAE: 1.62066,  MAPE: 2.31%\n",
      "[1600 Epochs]    RMSE:7.12243,   MAE: 1.61992,  MAPE: 2.23%\n",
      "[1800 Epochs]    RMSE:7.39877,   MAE: 1.54858,  MAPE: 2.21%\n",
      "\n",
      "[Final Epochs]    RMSE:6.58537,   MAE: 1.51756,  MAPE: 2.07%\n",
      "\n",
      "\n",
      "Trial No.4\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:44.32883,   MAE: 32.98083,  MAPE: 41.12%\n",
      "[200 Epochs]    RMSE:12.99609,   MAE: 4.00974,  MAPE: 5.89%\n",
      "[400 Epochs]    RMSE:11.76085,   MAE: 3.86586,  MAPE: 5.64%\n",
      "[600 Epochs]    RMSE:10.57889,   MAE: 3.00264,  MAPE: 4.58%\n",
      "[800 Epochs]    RMSE:9.74390,   MAE: 2.42430,  MAPE: 3.73%\n",
      "[1000 Epochs]    RMSE:9.01247,   MAE: 2.13423,  MAPE: 3.16%\n",
      "[1200 Epochs]    RMSE:8.29139,   MAE: 1.85448,  MAPE: 2.66%\n",
      "[1400 Epochs]    RMSE:7.59849,   MAE: 1.94697,  MAPE: 2.72%\n",
      "[1600 Epochs]    RMSE:7.13921,   MAE: 1.83829,  MAPE: 2.63%\n",
      "[1800 Epochs]    RMSE:6.43546,   MAE: 1.53299,  MAPE: 2.16%\n",
      "\n",
      "[Final Epochs]    RMSE:6.26990,   MAE: 1.42508,  MAPE: 2.03%\n",
      "\n",
      "\n",
      "Trial No.5\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:113.16855,   MAE: 102.29888,  MAPE: 100.00%\n",
      "[200 Epochs]    RMSE:113.16856,   MAE: 102.29886,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:113.16856,   MAE: 102.29889,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:113.16856,   MAE: 102.29887,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:113.16855,   MAE: 102.29888,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:113.16855,   MAE: 102.29890,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:113.16856,   MAE: 102.29889,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:113.16854,   MAE: 102.29887,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:113.16856,   MAE: 102.29890,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:113.16855,   MAE: 102.29887,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:113.16856,   MAE: 102.29889,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.6\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:42.52291,   MAE: 25.55968,  MAPE: 32.55%\n",
      "[200 Epochs]    RMSE:12.37516,   MAE: 3.34364,  MAPE: 5.14%\n",
      "[400 Epochs]    RMSE:13.11239,   MAE: 3.86567,  MAPE: 5.74%\n",
      "[600 Epochs]    RMSE:11.62017,   MAE: 2.61646,  MAPE: 4.12%\n",
      "[800 Epochs]    RMSE:11.44718,   MAE: 2.73697,  MAPE: 4.22%\n",
      "[1000 Epochs]    RMSE:11.00727,   MAE: 2.78293,  MAPE: 4.30%\n",
      "[1200 Epochs]    RMSE:11.07440,   MAE: 2.53697,  MAPE: 4.05%\n",
      "[1400 Epochs]    RMSE:10.64906,   MAE: 2.41935,  MAPE: 3.78%\n",
      "[1600 Epochs]    RMSE:10.37988,   MAE: 2.37260,  MAPE: 3.74%\n",
      "[1800 Epochs]    RMSE:11.74679,   MAE: 2.59338,  MAPE: 4.14%\n",
      "\n",
      "[Final Epochs]    RMSE:10.29654,   MAE: 2.49187,  MAPE: 3.91%\n",
      "\n",
      "\n",
      "Trial No.7\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:38.76468,   MAE: 26.99121,  MAPE: 35.20%\n",
      "[200 Epochs]    RMSE:13.83873,   MAE: 3.93483,  MAPE: 6.23%\n",
      "[400 Epochs]    RMSE:12.78970,   MAE: 3.58564,  MAPE: 5.68%\n",
      "[600 Epochs]    RMSE:12.59628,   MAE: 3.49613,  MAPE: 5.48%\n",
      "[800 Epochs]    RMSE:11.97286,   MAE: 2.93291,  MAPE: 4.61%\n",
      "[1000 Epochs]    RMSE:11.82746,   MAE: 2.75500,  MAPE: 4.27%\n",
      "[1200 Epochs]    RMSE:11.61425,   MAE: 2.57991,  MAPE: 4.05%\n",
      "[1400 Epochs]    RMSE:11.59942,   MAE: 2.73780,  MAPE: 4.29%\n",
      "[1600 Epochs]    RMSE:11.55129,   MAE: 2.75306,  MAPE: 4.30%\n",
      "[1800 Epochs]    RMSE:11.21136,   MAE: 2.32367,  MAPE: 3.70%\n",
      "\n",
      "[Final Epochs]    RMSE:10.87875,   MAE: 2.50547,  MAPE: 3.76%\n",
      "\n",
      "\n",
      "Trial No.8\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:37.50897,   MAE: 24.57598,  MAPE: 31.55%\n",
      "[200 Epochs]    RMSE:11.67675,   MAE: 3.34684,  MAPE: 4.82%\n",
      "[400 Epochs]    RMSE:10.60441,   MAE: 3.66581,  MAPE: 4.95%\n",
      "[600 Epochs]    RMSE:10.74930,   MAE: 3.00699,  MAPE: 4.18%\n",
      "[800 Epochs]    RMSE:9.51877,   MAE: 2.35011,  MAPE: 3.19%\n",
      "[1000 Epochs]    RMSE:9.55874,   MAE: 2.55469,  MAPE: 3.44%\n",
      "[1200 Epochs]    RMSE:9.26558,   MAE: 2.67311,  MAPE: 3.59%\n",
      "[1400 Epochs]    RMSE:8.94701,   MAE: 2.01146,  MAPE: 2.88%\n",
      "[1600 Epochs]    RMSE:9.12197,   MAE: 1.96098,  MAPE: 2.87%\n",
      "[1800 Epochs]    RMSE:9.89434,   MAE: 2.25631,  MAPE: 3.47%\n",
      "\n",
      "[Final Epochs]    RMSE:9.10048,   MAE: 2.07390,  MAPE: 3.03%\n",
      "\n",
      "\n",
      "Trial No.9\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:41.31258,   MAE: 29.67139,  MAPE: 37.86%\n",
      "[200 Epochs]    RMSE:13.08694,   MAE: 3.38116,  MAPE: 5.60%\n",
      "[400 Epochs]    RMSE:12.41423,   MAE: 3.05011,  MAPE: 5.10%\n",
      "[600 Epochs]    RMSE:12.19878,   MAE: 3.11610,  MAPE: 5.03%\n",
      "[800 Epochs]    RMSE:11.75057,   MAE: 2.62797,  MAPE: 4.29%\n",
      "[1000 Epochs]    RMSE:11.82917,   MAE: 2.95501,  MAPE: 4.66%\n",
      "[1200 Epochs]    RMSE:11.35697,   MAE: 2.44572,  MAPE: 4.07%\n",
      "[1400 Epochs]    RMSE:11.42212,   MAE: 2.60779,  MAPE: 4.16%\n",
      "[1600 Epochs]    RMSE:11.60776,   MAE: 2.72870,  MAPE: 4.33%\n",
      "[1800 Epochs]    RMSE:11.45290,   MAE: 2.49232,  MAPE: 3.96%\n",
      "\n",
      "[Final Epochs]    RMSE:10.85417,   MAE: 2.31171,  MAPE: 3.70%\n",
      "\n",
      "\n",
      "Trial No.10\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:113.16855,   MAE: 102.29888,  MAPE: 100.00%\n",
      "[200 Epochs]    RMSE:113.16856,   MAE: 102.29886,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:113.16856,   MAE: 102.29889,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:113.16856,   MAE: 102.29887,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:113.16855,   MAE: 102.29888,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:113.16855,   MAE: 102.29890,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:113.16856,   MAE: 102.29889,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:113.16854,   MAE: 102.29887,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:113.16856,   MAE: 102.29890,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:113.16855,   MAE: 102.29887,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:113.16856,   MAE: 102.29889,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.11\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:41.88169,   MAE: 27.94682,  MAPE: 35.27%\n",
      "[200 Epochs]    RMSE:14.58348,   MAE: 5.04746,  MAPE: 7.61%\n",
      "[400 Epochs]    RMSE:13.21280,   MAE: 3.57607,  MAPE: 5.87%\n",
      "[600 Epochs]    RMSE:12.95575,   MAE: 3.09284,  MAPE: 5.19%\n",
      "[800 Epochs]    RMSE:13.02911,   MAE: 3.09278,  MAPE: 5.17%\n",
      "[1000 Epochs]    RMSE:13.23823,   MAE: 3.64605,  MAPE: 6.07%\n",
      "[1200 Epochs]    RMSE:13.17649,   MAE: 3.17321,  MAPE: 5.26%\n",
      "[1400 Epochs]    RMSE:13.99646,   MAE: 3.44165,  MAPE: 5.85%\n",
      "[1600 Epochs]    RMSE:12.79157,   MAE: 2.90994,  MAPE: 4.96%\n",
      "[1800 Epochs]    RMSE:13.36280,   MAE: 3.59268,  MAPE: 6.37%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Epochs]    RMSE:13.87662,   MAE: 3.26729,  MAPE: 5.41%\n",
      "\n",
      "\n",
      "Trial No.12\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:54.55771,   MAE: 36.74603,  MAPE: 44.66%\n",
      "[200 Epochs]    RMSE:13.93875,   MAE: 3.77374,  MAPE: 6.19%\n",
      "[400 Epochs]    RMSE:14.02235,   MAE: 4.34445,  MAPE: 6.99%\n",
      "[600 Epochs]    RMSE:13.58543,   MAE: 4.29679,  MAPE: 6.84%\n",
      "[800 Epochs]    RMSE:13.54524,   MAE: 3.92603,  MAPE: 6.30%\n",
      "[1000 Epochs]    RMSE:13.13322,   MAE: 3.52512,  MAPE: 5.77%\n",
      "[1200 Epochs]    RMSE:13.06232,   MAE: 3.71388,  MAPE: 5.98%\n",
      "[1400 Epochs]    RMSE:13.07068,   MAE: 3.48092,  MAPE: 5.80%\n",
      "[1600 Epochs]    RMSE:12.81986,   MAE: 3.33868,  MAPE: 5.52%\n",
      "[1800 Epochs]    RMSE:12.86919,   MAE: 3.14623,  MAPE: 5.43%\n",
      "\n",
      "[Final Epochs]    RMSE:12.90958,   MAE: 3.38687,  MAPE: 5.68%\n",
      "\n",
      "\n",
      "Trial No.13\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:113.15730,   MAE: 102.29679,  MAPE: 100.09%\n",
      "[200 Epochs]    RMSE:113.16856,   MAE: 102.29886,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:113.16856,   MAE: 102.29889,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:113.16856,   MAE: 102.29887,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:113.16855,   MAE: 102.29888,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:113.16855,   MAE: 102.29890,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:113.16856,   MAE: 102.29889,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:113.16854,   MAE: 102.29887,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:113.16856,   MAE: 102.29890,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:113.16855,   MAE: 102.29887,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:113.16856,   MAE: 102.29889,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.14\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:65.92932,   MAE: 46.55670,  MAPE: 52.62%\n",
      "[200 Epochs]    RMSE:14.32216,   MAE: 4.53460,  MAPE: 7.14%\n",
      "[400 Epochs]    RMSE:13.94146,   MAE: 3.34594,  MAPE: 5.71%\n",
      "[600 Epochs]    RMSE:13.27226,   MAE: 3.86362,  MAPE: 6.07%\n",
      "[800 Epochs]    RMSE:13.16599,   MAE: 3.79163,  MAPE: 5.97%\n",
      "[1000 Epochs]    RMSE:13.38153,   MAE: 3.26861,  MAPE: 5.49%\n",
      "[1200 Epochs]    RMSE:13.31353,   MAE: 3.16163,  MAPE: 5.37%\n",
      "[1400 Epochs]    RMSE:13.31653,   MAE: 3.38211,  MAPE: 5.66%\n",
      "[1600 Epochs]    RMSE:13.34532,   MAE: 3.46355,  MAPE: 5.68%\n",
      "[1800 Epochs]    RMSE:13.28388,   MAE: 3.62517,  MAPE: 5.94%\n",
      "\n",
      "[Final Epochs]    RMSE:13.43740,   MAE: 3.60687,  MAPE: 5.97%\n",
      "\n",
      "\n",
      "Trial No.15\n",
      "Prediction :Wn1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:115.04295,   MAE: 102.65327,  MAPE: 101.92%\n",
      "[200 Epochs]    RMSE:14.07393,   MAE: 4.01536,  MAPE: 6.36%\n",
      "[400 Epochs]    RMSE:14.15809,   MAE: 3.90080,  MAPE: 6.36%\n",
      "[600 Epochs]    RMSE:14.33640,   MAE: 3.66694,  MAPE: 6.25%\n",
      "[800 Epochs]    RMSE:14.14552,   MAE: 4.03840,  MAPE: 6.51%\n",
      "[1000 Epochs]    RMSE:13.99486,   MAE: 3.12831,  MAPE: 5.49%\n",
      "[1200 Epochs]    RMSE:14.28624,   MAE: 3.26010,  MAPE: 6.02%\n",
      "[1400 Epochs]    RMSE:13.98517,   MAE: 3.00624,  MAPE: 5.44%\n",
      "[1600 Epochs]    RMSE:14.16991,   MAE: 3.69175,  MAPE: 6.10%\n",
      "[1800 Epochs]    RMSE:13.93989,   MAE: 3.14053,  MAPE: 5.47%\n",
      "\n",
      "[Final Epochs]    RMSE:13.96537,   MAE: 3.08015,  MAPE: 5.45%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################## Model 2 (Predict :Wn2) ##################\n",
      "\n",
      "\n",
      "Trial No.1\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:79.03685,   MAE: 59.34188,  MAPE: 28.30%\n",
      "[200 Epochs]    RMSE:14.83106,   MAE: 4.74055,  MAPE: 2.22%\n",
      "[400 Epochs]    RMSE:13.19330,   MAE: 3.96059,  MAPE: 1.89%\n",
      "[600 Epochs]    RMSE:11.75177,   MAE: 3.71863,  MAPE: 1.80%\n",
      "[800 Epochs]    RMSE:11.01364,   MAE: 3.13134,  MAPE: 1.54%\n",
      "[1000 Epochs]    RMSE:10.15927,   MAE: 2.53520,  MAPE: 1.25%\n",
      "[1200 Epochs]    RMSE:9.80151,   MAE: 2.30863,  MAPE: 1.13%\n",
      "[1400 Epochs]    RMSE:9.62424,   MAE: 2.66264,  MAPE: 1.29%\n",
      "[1600 Epochs]    RMSE:8.82005,   MAE: 2.40693,  MAPE: 1.18%\n",
      "[1800 Epochs]    RMSE:8.76250,   MAE: 2.16312,  MAPE: 1.06%\n",
      "\n",
      "[Final Epochs]    RMSE:8.54088,   MAE: 2.09002,  MAPE: 1.02%\n",
      "\n",
      "\n",
      "Trial No.2\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:82.22503,   MAE: 60.44701,  MAPE: 28.76%\n",
      "[200 Epochs]    RMSE:15.05589,   MAE: 4.40424,  MAPE: 2.11%\n",
      "[400 Epochs]    RMSE:11.97825,   MAE: 3.43228,  MAPE: 1.68%\n",
      "[600 Epochs]    RMSE:11.24815,   MAE: 3.02303,  MAPE: 1.50%\n",
      "[800 Epochs]    RMSE:10.45358,   MAE: 2.94855,  MAPE: 1.43%\n",
      "[1000 Epochs]    RMSE:10.32176,   MAE: 2.36311,  MAPE: 1.17%\n",
      "[1200 Epochs]    RMSE:9.85823,   MAE: 2.31796,  MAPE: 1.15%\n",
      "[1400 Epochs]    RMSE:9.59718,   MAE: 2.21108,  MAPE: 1.09%\n",
      "[1600 Epochs]    RMSE:9.53041,   MAE: 2.52794,  MAPE: 1.24%\n",
      "[1800 Epochs]    RMSE:9.17421,   MAE: 2.05761,  MAPE: 1.02%\n",
      "\n",
      "[Final Epochs]    RMSE:8.80508,   MAE: 1.93006,  MAPE: 0.95%\n",
      "\n",
      "\n",
      "Trial No.3\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:70.54803,   MAE: 53.58416,  MAPE: 25.89%\n",
      "[200 Epochs]    RMSE:14.07250,   MAE: 5.36199,  MAPE: 2.53%\n",
      "[400 Epochs]    RMSE:11.54241,   MAE: 3.76659,  MAPE: 1.80%\n",
      "[600 Epochs]    RMSE:10.40485,   MAE: 3.07052,  MAPE: 1.48%\n",
      "[800 Epochs]    RMSE:9.77314,   MAE: 2.47242,  MAPE: 1.21%\n",
      "[1000 Epochs]    RMSE:8.96732,   MAE: 3.05483,  MAPE: 1.46%\n",
      "[1200 Epochs]    RMSE:8.43459,   MAE: 2.30081,  MAPE: 1.11%\n",
      "[1400 Epochs]    RMSE:7.98296,   MAE: 2.25655,  MAPE: 1.08%\n",
      "[1600 Epochs]    RMSE:7.62468,   MAE: 2.23007,  MAPE: 1.06%\n",
      "[1800 Epochs]    RMSE:7.08108,   MAE: 1.75384,  MAPE: 0.86%\n",
      "\n",
      "[Final Epochs]    RMSE:6.89552,   MAE: 1.77472,  MAPE: 0.86%\n",
      "\n",
      "\n",
      "Trial No.4\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:62.46870,   MAE: 47.57217,  MAPE: 23.17%\n",
      "[200 Epochs]    RMSE:14.81268,   MAE: 4.02860,  MAPE: 1.88%\n",
      "[400 Epochs]    RMSE:12.60686,   MAE: 3.87464,  MAPE: 1.83%\n",
      "[600 Epochs]    RMSE:11.35345,   MAE: 3.19783,  MAPE: 1.55%\n",
      "[800 Epochs]    RMSE:10.47018,   MAE: 2.78345,  MAPE: 1.35%\n",
      "[1000 Epochs]    RMSE:9.57561,   MAE: 2.37839,  MAPE: 1.16%\n",
      "[1200 Epochs]    RMSE:9.03609,   MAE: 2.34944,  MAPE: 1.14%\n",
      "[1400 Epochs]    RMSE:8.36047,   MAE: 1.95794,  MAPE: 0.95%\n",
      "[1600 Epochs]    RMSE:8.11134,   MAE: 2.07124,  MAPE: 1.01%\n",
      "[1800 Epochs]    RMSE:7.71333,   MAE: 1.99286,  MAPE: 0.97%\n",
      "\n",
      "[Final Epochs]    RMSE:7.18986,   MAE: 1.74258,  MAPE: 0.84%\n",
      "\n",
      "\n",
      "Trial No.5\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:120.89727,   MAE: 86.66579,  MAPE: 39.96%\n",
      "[200 Epochs]    RMSE:14.72262,   MAE: 4.42513,  MAPE: 2.15%\n",
      "[400 Epochs]    RMSE:12.64057,   MAE: 3.68368,  MAPE: 1.80%\n",
      "[600 Epochs]    RMSE:11.17491,   MAE: 3.17623,  MAPE: 1.55%\n",
      "[800 Epochs]    RMSE:10.62165,   MAE: 2.54458,  MAPE: 1.26%\n",
      "[1000 Epochs]    RMSE:10.12008,   MAE: 2.37999,  MAPE: 1.17%\n",
      "[1200 Epochs]    RMSE:9.73255,   MAE: 2.44534,  MAPE: 1.20%\n",
      "[1400 Epochs]    RMSE:9.34839,   MAE: 2.20576,  MAPE: 1.09%\n",
      "[1600 Epochs]    RMSE:9.04130,   MAE: 1.98246,  MAPE: 0.99%\n",
      "[1800 Epochs]    RMSE:8.61342,   MAE: 2.26140,  MAPE: 1.11%\n",
      "\n",
      "[Final Epochs]    RMSE:7.89842,   MAE: 2.00917,  MAPE: 1.00%\n",
      "\n",
      "\n",
      "Trial No.6\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:50.72900,   MAE: 33.94395,  MAPE: 16.61%\n",
      "[200 Epochs]    RMSE:14.98215,   MAE: 4.51186,  MAPE: 2.11%\n",
      "[400 Epochs]    RMSE:13.06341,   MAE: 4.14855,  MAPE: 1.97%\n",
      "[600 Epochs]    RMSE:11.93827,   MAE: 3.72794,  MAPE: 1.81%\n",
      "[800 Epochs]    RMSE:11.66696,   MAE: 3.60783,  MAPE: 1.74%\n",
      "[1000 Epochs]    RMSE:11.15312,   MAE: 3.11307,  MAPE: 1.54%\n",
      "[1200 Epochs]    RMSE:11.35934,   MAE: 3.53891,  MAPE: 1.72%\n",
      "[1400 Epochs]    RMSE:11.13564,   MAE: 4.15497,  MAPE: 2.01%\n",
      "[1600 Epochs]    RMSE:10.28144,   MAE: 2.85141,  MAPE: 1.39%\n",
      "[1800 Epochs]    RMSE:10.86900,   MAE: 2.92047,  MAPE: 1.45%\n",
      "\n",
      "[Final Epochs]    RMSE:10.28442,   MAE: 3.38494,  MAPE: 1.65%\n",
      "\n",
      "\n",
      "Trial No.7\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:96.99616,   MAE: 63.48298,  MAPE: 29.47%\n",
      "[200 Epochs]    RMSE:13.45222,   MAE: 4.34453,  MAPE: 2.07%\n",
      "[400 Epochs]    RMSE:12.97173,   MAE: 3.80396,  MAPE: 1.82%\n",
      "[600 Epochs]    RMSE:12.57018,   MAE: 3.24985,  MAPE: 1.59%\n",
      "[800 Epochs]    RMSE:12.49305,   MAE: 3.85392,  MAPE: 1.87%\n",
      "[1000 Epochs]    RMSE:11.93409,   MAE: 3.21707,  MAPE: 1.55%\n",
      "[1200 Epochs]    RMSE:12.36065,   MAE: 3.27973,  MAPE: 1.57%\n",
      "[1400 Epochs]    RMSE:11.43748,   MAE: 2.90525,  MAPE: 1.42%\n",
      "[1600 Epochs]    RMSE:11.21233,   MAE: 2.95758,  MAPE: 1.42%\n",
      "[1800 Epochs]    RMSE:12.00691,   MAE: 3.19718,  MAPE: 1.54%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Epochs]    RMSE:11.15584,   MAE: 2.88220,  MAPE: 1.39%\n",
      "\n",
      "\n",
      "Trial No.8\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:57.33074,   MAE: 37.93061,  MAPE: 18.31%\n",
      "[200 Epochs]    RMSE:14.24326,   MAE: 5.59332,  MAPE: 2.61%\n",
      "[400 Epochs]    RMSE:12.76040,   MAE: 3.81323,  MAPE: 1.80%\n",
      "[600 Epochs]    RMSE:12.86946,   MAE: 3.73099,  MAPE: 1.79%\n",
      "[800 Epochs]    RMSE:11.69031,   MAE: 3.19939,  MAPE: 1.54%\n",
      "[1000 Epochs]    RMSE:11.15176,   MAE: 3.25006,  MAPE: 1.54%\n",
      "[1200 Epochs]    RMSE:11.02784,   MAE: 3.39780,  MAPE: 1.62%\n",
      "[1400 Epochs]    RMSE:10.97285,   MAE: 3.23256,  MAPE: 1.54%\n",
      "[1600 Epochs]    RMSE:11.47858,   MAE: 3.26790,  MAPE: 1.55%\n",
      "[1800 Epochs]    RMSE:10.86662,   MAE: 2.75619,  MAPE: 1.31%\n",
      "\n",
      "[Final Epochs]    RMSE:11.17565,   MAE: 2.80938,  MAPE: 1.33%\n",
      "\n",
      "\n",
      "Trial No.9\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:59.88721,   MAE: 38.61362,  MAPE: 18.42%\n",
      "[200 Epochs]    RMSE:14.99881,   MAE: 5.56226,  MAPE: 2.59%\n",
      "[400 Epochs]    RMSE:12.99438,   MAE: 4.18191,  MAPE: 2.04%\n",
      "[600 Epochs]    RMSE:11.82657,   MAE: 3.46531,  MAPE: 1.71%\n",
      "[800 Epochs]    RMSE:11.67712,   MAE: 3.81667,  MAPE: 1.85%\n",
      "[1000 Epochs]    RMSE:11.08339,   MAE: 3.49670,  MAPE: 1.68%\n",
      "[1200 Epochs]    RMSE:12.00317,   MAE: 3.31894,  MAPE: 1.63%\n",
      "[1400 Epochs]    RMSE:11.54790,   MAE: 3.56482,  MAPE: 1.74%\n",
      "[1600 Epochs]    RMSE:10.62922,   MAE: 2.99921,  MAPE: 1.50%\n",
      "[1800 Epochs]    RMSE:10.40219,   MAE: 2.95629,  MAPE: 1.45%\n",
      "\n",
      "[Final Epochs]    RMSE:10.59147,   MAE: 2.95203,  MAPE: 1.45%\n",
      "\n",
      "\n",
      "Trial No.10\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:234.11595,   MAE: 228.42039,  MAPE: 100.00%\n",
      "[200 Epochs]    RMSE:234.11595,   MAE: 228.42038,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:234.11594,   MAE: 228.42035,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:234.11592,   MAE: 228.42038,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:234.11592,   MAE: 228.42041,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:234.11594,   MAE: 228.42035,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:234.11594,   MAE: 228.42036,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:234.11594,   MAE: 228.42038,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:234.11595,   MAE: 228.42036,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:234.11594,   MAE: 228.42038,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:234.11594,   MAE: 228.42038,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.11\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:70.22742,   MAE: 45.13828,  MAPE: 21.44%\n",
      "[200 Epochs]    RMSE:15.37278,   MAE: 5.19718,  MAPE: 2.43%\n",
      "[400 Epochs]    RMSE:13.08372,   MAE: 5.82834,  MAPE: 2.71%\n",
      "[600 Epochs]    RMSE:12.77844,   MAE: 4.47540,  MAPE: 2.11%\n",
      "[800 Epochs]    RMSE:14.41541,   MAE: 4.16244,  MAPE: 1.97%\n",
      "[1000 Epochs]    RMSE:13.44901,   MAE: 4.35875,  MAPE: 2.04%\n",
      "[1200 Epochs]    RMSE:12.96685,   MAE: 3.69352,  MAPE: 1.82%\n",
      "[1400 Epochs]    RMSE:12.53819,   MAE: 3.76860,  MAPE: 1.84%\n",
      "[1600 Epochs]    RMSE:12.43966,   MAE: 4.54584,  MAPE: 2.17%\n",
      "[1800 Epochs]    RMSE:14.33212,   MAE: 4.57937,  MAPE: 2.20%\n",
      "\n",
      "[Final Epochs]    RMSE:12.12120,   MAE: 3.90351,  MAPE: 1.87%\n",
      "\n",
      "\n",
      "Trial No.12\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:56.21840,   MAE: 37.72131,  MAPE: 18.00%\n",
      "[200 Epochs]    RMSE:16.12090,   MAE: 6.17006,  MAPE: 2.92%\n",
      "[400 Epochs]    RMSE:13.14377,   MAE: 5.15351,  MAPE: 2.44%\n",
      "[600 Epochs]    RMSE:12.32739,   MAE: 4.21241,  MAPE: 2.05%\n",
      "[800 Epochs]    RMSE:12.04099,   MAE: 4.42352,  MAPE: 2.14%\n",
      "[1000 Epochs]    RMSE:11.53370,   MAE: 3.51148,  MAPE: 1.70%\n",
      "[1200 Epochs]    RMSE:11.94311,   MAE: 4.45086,  MAPE: 2.18%\n",
      "[1400 Epochs]    RMSE:11.81945,   MAE: 3.84800,  MAPE: 1.89%\n",
      "[1600 Epochs]    RMSE:11.63411,   MAE: 3.49114,  MAPE: 1.73%\n",
      "[1800 Epochs]    RMSE:11.91174,   MAE: 3.52419,  MAPE: 1.70%\n",
      "\n",
      "[Final Epochs]    RMSE:10.99902,   MAE: 3.04970,  MAPE: 1.47%\n",
      "\n",
      "\n",
      "Trial No.13\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:72.85769,   MAE: 46.70607,  MAPE: 22.17%\n",
      "[200 Epochs]    RMSE:16.89987,   MAE: 6.38190,  MAPE: 2.93%\n",
      "[400 Epochs]    RMSE:14.12307,   MAE: 4.84546,  MAPE: 2.32%\n",
      "[600 Epochs]    RMSE:13.11233,   MAE: 4.68755,  MAPE: 2.28%\n",
      "[800 Epochs]    RMSE:12.59638,   MAE: 4.09977,  MAPE: 2.00%\n",
      "[1000 Epochs]    RMSE:13.71815,   MAE: 5.16482,  MAPE: 2.45%\n",
      "[1200 Epochs]    RMSE:12.61652,   MAE: 4.20710,  MAPE: 2.05%\n",
      "[1400 Epochs]    RMSE:12.17157,   MAE: 3.61790,  MAPE: 1.81%\n",
      "[1600 Epochs]    RMSE:12.11979,   MAE: 4.04061,  MAPE: 1.95%\n",
      "[1800 Epochs]    RMSE:11.74356,   MAE: 4.22520,  MAPE: 2.03%\n",
      "\n",
      "[Final Epochs]    RMSE:12.00789,   MAE: 4.84073,  MAPE: 2.31%\n",
      "\n",
      "\n",
      "Trial No.14\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:61.09096,   MAE: 40.54704,  MAPE: 19.49%\n",
      "[200 Epochs]    RMSE:14.86005,   MAE: 5.46027,  MAPE: 2.53%\n",
      "[400 Epochs]    RMSE:13.57272,   MAE: 4.88166,  MAPE: 2.32%\n",
      "[600 Epochs]    RMSE:13.18343,   MAE: 5.47477,  MAPE: 2.59%\n",
      "[800 Epochs]    RMSE:13.01087,   MAE: 5.33258,  MAPE: 2.49%\n",
      "[1000 Epochs]    RMSE:12.06409,   MAE: 3.80750,  MAPE: 1.80%\n",
      "[1200 Epochs]    RMSE:12.29776,   MAE: 3.94516,  MAPE: 1.88%\n",
      "[1400 Epochs]    RMSE:11.85338,   MAE: 3.97590,  MAPE: 1.90%\n",
      "[1600 Epochs]    RMSE:11.92453,   MAE: 3.67376,  MAPE: 1.75%\n",
      "[1800 Epochs]    RMSE:12.11799,   MAE: 4.29136,  MAPE: 2.04%\n",
      "\n",
      "[Final Epochs]    RMSE:11.96615,   MAE: 3.35306,  MAPE: 1.59%\n",
      "\n",
      "\n",
      "Trial No.15\n",
      "Prediction :Wn2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:54.91956,   MAE: 35.60590,  MAPE: 17.16%\n",
      "[200 Epochs]    RMSE:15.89635,   MAE: 5.98347,  MAPE: 2.82%\n",
      "[400 Epochs]    RMSE:12.98547,   MAE: 4.09104,  MAPE: 1.98%\n",
      "[600 Epochs]    RMSE:14.24481,   MAE: 5.33964,  MAPE: 2.59%\n",
      "[800 Epochs]    RMSE:12.96511,   MAE: 4.15939,  MAPE: 2.05%\n",
      "[1000 Epochs]    RMSE:12.58458,   MAE: 4.26798,  MAPE: 2.08%\n",
      "[1200 Epochs]    RMSE:12.32221,   MAE: 4.93790,  MAPE: 2.34%\n",
      "[1400 Epochs]    RMSE:12.02496,   MAE: 3.59178,  MAPE: 1.79%\n",
      "[1600 Epochs]    RMSE:12.23949,   MAE: 3.89054,  MAPE: 1.96%\n",
      "[1800 Epochs]    RMSE:12.00190,   MAE: 3.85077,  MAPE: 1.89%\n",
      "\n",
      "[Final Epochs]    RMSE:12.69050,   MAE: 4.19602,  MAPE: 2.13%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################## Model 3 (Predict :R1) ##################\n",
      "\n",
      "\n",
      "Trial No.1\n",
      "Prediction :R1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:35.27693,   MAE: 27.09031,  MAPE: 114.96%\n",
      "[200 Epochs]    RMSE:16.66200,   MAE: 12.65464,  MAPE: 45.32%\n",
      "[400 Epochs]    RMSE:14.57800,   MAE: 10.84936,  MAPE: 38.11%\n",
      "[600 Epochs]    RMSE:12.96460,   MAE: 9.42030,  MAPE: 32.72%\n",
      "[800 Epochs]    RMSE:11.54086,   MAE: 8.21615,  MAPE: 28.66%\n",
      "[1000 Epochs]    RMSE:10.14621,   MAE: 7.16607,  MAPE: 24.53%\n",
      "[1200 Epochs]    RMSE:9.43019,   MAE: 6.58907,  MAPE: 23.18%\n",
      "[1400 Epochs]    RMSE:8.58022,   MAE: 5.92640,  MAPE: 21.84%\n",
      "[1600 Epochs]    RMSE:8.53093,   MAE: 5.87613,  MAPE: 21.45%\n",
      "[1800 Epochs]    RMSE:7.80708,   MAE: 5.28907,  MAPE: 20.25%\n",
      "\n",
      "[Final Epochs]    RMSE:7.39128,   MAE: 4.95956,  MAPE: 19.30%\n",
      "\n",
      "\n",
      "Trial No.2\n",
      "Prediction :R1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.3\n",
      "Prediction :R1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:31.93917,   MAE: 24.95636,  MAPE: 102.47%\n",
      "[200 Epochs]    RMSE:15.93755,   MAE: 11.98877,  MAPE: 42.25%\n",
      "[400 Epochs]    RMSE:14.05335,   MAE: 10.30031,  MAPE: 35.23%\n",
      "[600 Epochs]    RMSE:12.52871,   MAE: 9.03953,  MAPE: 30.32%\n",
      "[800 Epochs]    RMSE:11.12579,   MAE: 7.90740,  MAPE: 26.01%\n",
      "[1000 Epochs]    RMSE:9.85214,   MAE: 6.94453,  MAPE: 23.44%\n",
      "[1200 Epochs]    RMSE:8.93156,   MAE: 6.30113,  MAPE: 21.85%\n",
      "[1400 Epochs]    RMSE:8.18576,   MAE: 5.73249,  MAPE: 20.87%\n",
      "[1600 Epochs]    RMSE:8.06617,   MAE: 5.59425,  MAPE: 20.22%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1800 Epochs]    RMSE:7.32269,   MAE: 5.00228,  MAPE: 18.65%\n",
      "\n",
      "[Final Epochs]    RMSE:7.31824,   MAE: 5.01100,  MAPE: 18.44%\n",
      "\n",
      "\n",
      "Trial No.4\n",
      "Prediction :R1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:34.90912,   MAE: 26.87611,  MAPE: 100.87%\n",
      "[200 Epochs]    RMSE:15.88309,   MAE: 11.80986,  MAPE: 41.23%\n",
      "[400 Epochs]    RMSE:14.17626,   MAE: 10.36166,  MAPE: 36.20%\n",
      "[600 Epochs]    RMSE:12.44250,   MAE: 8.95652,  MAPE: 31.05%\n",
      "[800 Epochs]    RMSE:11.21606,   MAE: 7.98849,  MAPE: 28.97%\n",
      "[1000 Epochs]    RMSE:9.69691,   MAE: 6.73723,  MAPE: 24.28%\n",
      "[1200 Epochs]    RMSE:9.00215,   MAE: 6.18704,  MAPE: 22.99%\n",
      "[1400 Epochs]    RMSE:8.61812,   MAE: 5.83916,  MAPE: 21.41%\n",
      "[1600 Epochs]    RMSE:8.62972,   MAE: 5.90016,  MAPE: 21.66%\n",
      "[1800 Epochs]    RMSE:7.84229,   MAE: 5.21857,  MAPE: 19.45%\n",
      "\n",
      "[Final Epochs]    RMSE:7.33428,   MAE: 4.90398,  MAPE: 18.79%\n",
      "\n",
      "\n",
      "Trial No.5\n",
      "Prediction :R1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:65.28053,   MAE: 53.53704,  MAPE: 125.37%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.6\n",
      "Prediction :R1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:57.07632,   MAE: 49.78532,  MAPE: 100.37%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.7\n",
      "Prediction :R1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:55.08558,   MAE: 47.08510,  MAPE: 103.59%\n",
      "[200 Epochs]    RMSE:14.10969,   MAE: 9.88181,  MAPE: 34.46%\n",
      "[400 Epochs]    RMSE:12.21050,   MAE: 8.14684,  MAPE: 28.84%\n",
      "[600 Epochs]    RMSE:10.42738,   MAE: 6.75634,  MAPE: 24.60%\n",
      "[800 Epochs]    RMSE:10.24236,   MAE: 6.72698,  MAPE: 24.93%\n",
      "[1000 Epochs]    RMSE:10.30435,   MAE: 6.82498,  MAPE: 24.81%\n",
      "[1200 Epochs]    RMSE:9.29482,   MAE: 6.13004,  MAPE: 23.42%\n",
      "[1400 Epochs]    RMSE:10.16753,   MAE: 6.76315,  MAPE: 26.00%\n",
      "[1600 Epochs]    RMSE:9.43451,   MAE: 6.09644,  MAPE: 23.16%\n",
      "[1800 Epochs]    RMSE:9.28793,   MAE: 5.99085,  MAPE: 22.41%\n",
      "\n",
      "[Final Epochs]    RMSE:8.47291,   MAE: 5.52235,  MAPE: 21.60%\n",
      "\n",
      "\n",
      "Trial No.8\n",
      "Prediction :R1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:51.64042,   MAE: 43.05510,  MAPE: 100.72%\n",
      "[200 Epochs]    RMSE:14.81012,   MAE: 10.51600,  MAPE: 35.62%\n",
      "[400 Epochs]    RMSE:12.07398,   MAE: 8.27590,  MAPE: 29.12%\n",
      "[600 Epochs]    RMSE:10.62248,   MAE: 7.20944,  MAPE: 25.69%\n",
      "[800 Epochs]    RMSE:10.32350,   MAE: 6.73430,  MAPE: 23.56%\n",
      "[1000 Epochs]    RMSE:9.68998,   MAE: 6.30407,  MAPE: 23.37%\n",
      "[1200 Epochs]    RMSE:8.46907,   MAE: 5.41260,  MAPE: 20.62%\n",
      "[1400 Epochs]    RMSE:8.32667,   MAE: 5.20626,  MAPE: 20.49%\n",
      "[1600 Epochs]    RMSE:8.28926,   MAE: 5.18894,  MAPE: 19.71%\n",
      "[1800 Epochs]    RMSE:7.81385,   MAE: 4.88530,  MAPE: 18.67%\n",
      "\n",
      "[Final Epochs]    RMSE:8.09163,   MAE: 4.94135,  MAPE: 19.42%\n",
      "\n",
      "\n",
      "Trial No.9\n",
      "Prediction :R1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:57.08776,   MAE: 49.77787,  MAPE: 101.29%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.10\n",
      "Prediction :R1\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:57.38658,   MAE: 49.84506,  MAPE: 102.05%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.11\n",
      "Prediction :R1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:57.43193,   MAE: 50.04183,  MAPE: 101.31%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.12\n",
      "Prediction :R1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:61.58981,   MAE: 51.68205,  MAPE: 106.69%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.13\n",
      "Prediction :R1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:56.79777,   MAE: 49.42467,  MAPE: 100.61%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.14\n",
      "Prediction :R1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:57.13657,   MAE: 49.88346,  MAPE: 100.21%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.15\n",
      "Prediction :R1\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:58.70344,   MAE: 50.42979,  MAPE: 103.12%\n",
      "[200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:57.13167,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:57.13168,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:57.13167,   MAE: 49.87186,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:57.13168,   MAE: 49.87187,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:57.13168,   MAE: 49.87188,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:57.13168,   MAE: 49.87185,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "################## Model 4 (Predict :R2) ##################\n",
      "\n",
      "\n",
      "Trial No.1\n",
      "Prediction :R2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:34.00785,   MAE: 26.34261,  MAPE: 95.46%\n",
      "[200 Epochs]    RMSE:15.20281,   MAE: 11.72280,  MAPE: 42.86%\n",
      "[400 Epochs]    RMSE:12.63228,   MAE: 9.49769,  MAPE: 31.94%\n",
      "[600 Epochs]    RMSE:10.88437,   MAE: 7.98502,  MAPE: 25.51%\n",
      "[800 Epochs]    RMSE:10.02680,   MAE: 7.29906,  MAPE: 23.09%\n",
      "[1000 Epochs]    RMSE:9.05323,   MAE: 6.42073,  MAPE: 20.09%\n",
      "[1200 Epochs]    RMSE:8.87449,   MAE: 6.30110,  MAPE: 19.31%\n",
      "[1400 Epochs]    RMSE:7.82735,   MAE: 5.35284,  MAPE: 16.32%\n",
      "[1600 Epochs]    RMSE:7.81508,   MAE: 5.36307,  MAPE: 16.33%\n",
      "[1800 Epochs]    RMSE:7.48020,   MAE: 5.07442,  MAPE: 15.58%\n",
      "\n",
      "[Final Epochs]    RMSE:7.15885,   MAE: 4.74223,  MAPE: 14.03%\n",
      "\n",
      "\n",
      "Trial No.2\n",
      "Prediction :R2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:61.45297,   MAE: 53.97767,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:61.45297,   MAE: 53.97765,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.3\n",
      "Prediction :R2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:61.45297,   MAE: 53.97767,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:61.45297,   MAE: 53.97765,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.4\n",
      "Prediction :R2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:32.89454,   MAE: 25.71537,  MAPE: 96.93%\n",
      "[200 Epochs]    RMSE:14.93698,   MAE: 11.22854,  MAPE: 40.92%\n",
      "[400 Epochs]    RMSE:12.93397,   MAE: 9.59557,  MAPE: 32.45%\n",
      "[600 Epochs]    RMSE:11.13118,   MAE: 8.11909,  MAPE: 27.16%\n",
      "[800 Epochs]    RMSE:9.68913,   MAE: 6.96151,  MAPE: 23.06%\n",
      "[1000 Epochs]    RMSE:9.23496,   MAE: 6.66379,  MAPE: 21.80%\n",
      "[1200 Epochs]    RMSE:8.13553,   MAE: 5.63558,  MAPE: 18.55%\n",
      "[1400 Epochs]    RMSE:7.61923,   MAE: 5.18935,  MAPE: 17.08%\n",
      "[1600 Epochs]    RMSE:7.35094,   MAE: 4.97253,  MAPE: 16.36%\n",
      "[1800 Epochs]    RMSE:7.26095,   MAE: 4.89923,  MAPE: 16.47%\n",
      "\n",
      "[Final Epochs]    RMSE:6.90947,   MAE: 4.61047,  MAPE: 15.52%\n",
      "\n",
      "\n",
      "Trial No.5\n",
      "Prediction :R2\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:29.12552,   MAE: 23.26823,  MAPE: 96.19%\n",
      "[200 Epochs]    RMSE:14.53128,   MAE: 10.90617,  MAPE: 40.52%\n",
      "[400 Epochs]    RMSE:12.30389,   MAE: 9.13973,  MAPE: 31.01%\n",
      "[600 Epochs]    RMSE:11.02974,   MAE: 8.09997,  MAPE: 26.49%\n",
      "[800 Epochs]    RMSE:9.80506,   MAE: 7.06101,  MAPE: 22.55%\n",
      "[1000 Epochs]    RMSE:9.35807,   MAE: 6.74023,  MAPE: 21.16%\n",
      "[1200 Epochs]    RMSE:8.38938,   MAE: 5.93727,  MAPE: 18.09%\n",
      "[1400 Epochs]    RMSE:8.24753,   MAE: 5.88011,  MAPE: 17.89%\n",
      "[1600 Epochs]    RMSE:7.51195,   MAE: 5.24402,  MAPE: 16.11%\n",
      "[1800 Epochs]    RMSE:7.84799,   MAE: 5.51268,  MAPE: 16.63%\n",
      "\n",
      "[Final Epochs]    RMSE:7.37656,   MAE: 5.09477,  MAPE: 15.22%\n",
      "\n",
      "\n",
      "Trial No.6\n",
      "Prediction :R2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:33.95290,   MAE: 26.54413,  MAPE: 95.41%\n",
      "[200 Epochs]    RMSE:14.23529,   MAE: 10.32674,  MAPE: 31.70%\n",
      "[400 Epochs]    RMSE:11.89899,   MAE: 8.40782,  MAPE: 24.50%\n",
      "[600 Epochs]    RMSE:10.01752,   MAE: 6.70054,  MAPE: 19.34%\n",
      "[800 Epochs]    RMSE:9.61596,   MAE: 6.32012,  MAPE: 18.80%\n",
      "[1000 Epochs]    RMSE:8.80569,   MAE: 5.62061,  MAPE: 16.84%\n",
      "[1200 Epochs]    RMSE:8.95929,   MAE: 5.75166,  MAPE: 16.95%\n",
      "[1400 Epochs]    RMSE:9.14066,   MAE: 5.85868,  MAPE: 17.47%\n",
      "[1600 Epochs]    RMSE:8.88002,   MAE: 5.78835,  MAPE: 16.92%\n",
      "[1800 Epochs]    RMSE:8.62938,   MAE: 5.51361,  MAPE: 17.12%\n",
      "\n",
      "[Final Epochs]    RMSE:9.13567,   MAE: 5.76115,  MAPE: 18.53%\n",
      "\n",
      "\n",
      "Trial No.7\n",
      "Prediction :R2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:28.96888,   MAE: 23.02912,  MAPE: 90.86%\n",
      "[200 Epochs]    RMSE:13.53918,   MAE: 9.97601,  MAPE: 32.40%\n",
      "[400 Epochs]    RMSE:11.65249,   MAE: 8.50784,  MAPE: 27.06%\n",
      "[600 Epochs]    RMSE:10.77287,   MAE: 7.72324,  MAPE: 24.38%\n",
      "[800 Epochs]    RMSE:10.14025,   MAE: 7.21818,  MAPE: 22.61%\n",
      "[1000 Epochs]    RMSE:9.78944,   MAE: 6.84175,  MAPE: 21.67%\n",
      "[1200 Epochs]    RMSE:9.38698,   MAE: 6.49615,  MAPE: 20.38%\n",
      "[1400 Epochs]    RMSE:8.86467,   MAE: 6.09450,  MAPE: 19.32%\n",
      "[1600 Epochs]    RMSE:8.32611,   MAE: 5.63109,  MAPE: 17.62%\n",
      "[1800 Epochs]    RMSE:8.19134,   MAE: 5.42958,  MAPE: 17.19%\n",
      "\n",
      "[Final Epochs]    RMSE:8.00726,   MAE: 5.27423,  MAPE: 17.13%\n",
      "\n",
      "\n",
      "Trial No.8\n",
      "Prediction :R2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:35.88528,   MAE: 26.79249,  MAPE: 93.37%\n",
      "[200 Epochs]    RMSE:12.97475,   MAE: 9.29768,  MAPE: 30.16%\n",
      "[400 Epochs]    RMSE:10.53043,   MAE: 7.34588,  MAPE: 23.07%\n",
      "[600 Epochs]    RMSE:9.51698,   MAE: 6.47177,  MAPE: 20.13%\n",
      "[800 Epochs]    RMSE:8.51473,   MAE: 5.68436,  MAPE: 18.04%\n",
      "[1000 Epochs]    RMSE:7.83504,   MAE: 5.06941,  MAPE: 16.34%\n",
      "[1200 Epochs]    RMSE:8.23649,   MAE: 5.37820,  MAPE: 17.57%\n",
      "[1400 Epochs]    RMSE:7.80206,   MAE: 5.07218,  MAPE: 16.93%\n",
      "[1600 Epochs]    RMSE:7.48143,   MAE: 4.79907,  MAPE: 16.65%\n",
      "[1800 Epochs]    RMSE:7.20941,   MAE: 4.45454,  MAPE: 15.89%\n",
      "\n",
      "[Final Epochs]    RMSE:7.12639,   MAE: 4.35505,  MAPE: 15.48%\n",
      "\n",
      "\n",
      "Trial No.9\n",
      "Prediction :R2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:61.50048,   MAE: 53.85104,  MAPE: 101.94%\n",
      "[200 Epochs]    RMSE:17.06591,   MAE: 12.87520,  MAPE: 40.68%\n",
      "[400 Epochs]    RMSE:14.91972,   MAE: 11.17424,  MAPE: 33.00%\n",
      "[600 Epochs]    RMSE:14.48462,   MAE: 10.76875,  MAPE: 31.54%\n",
      "[800 Epochs]    RMSE:13.81304,   MAE: 10.22583,  MAPE: 31.43%\n",
      "[1000 Epochs]    RMSE:12.75905,   MAE: 9.25774,  MAPE: 27.75%\n",
      "[1200 Epochs]    RMSE:12.84780,   MAE: 9.35391,  MAPE: 27.55%\n",
      "[1400 Epochs]    RMSE:12.94517,   MAE: 9.44798,  MAPE: 27.68%\n",
      "[1600 Epochs]    RMSE:12.78687,   MAE: 9.29753,  MAPE: 27.80%\n",
      "[1800 Epochs]    RMSE:12.51071,   MAE: 9.02436,  MAPE: 26.54%\n",
      "\n",
      "[Final Epochs]    RMSE:12.38130,   MAE: 8.91013,  MAPE: 25.39%\n",
      "\n",
      "\n",
      "Trial No.10\n",
      "Prediction :R2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:61.23087,   MAE: 53.70800,  MAPE: 100.71%\n",
      "[200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[800 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:61.45297,   MAE: 53.97767,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:61.45297,   MAE: 53.97765,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.11\n",
      "Prediction :R2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 30\n",
      "[0 Epochs]    RMSE:62.51928,   MAE: 54.65733,  MAPE: 104.27%\n",
      "[200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:61.45297,   MAE: 53.97767,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:61.45297,   MAE: 53.97765,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.12\n",
      "Prediction :R2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 40\n",
      "[0 Epochs]    RMSE:61.48227,   MAE: 54.00929,  MAPE: 100.42%\n",
      "[200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:61.45297,   MAE: 53.97767,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:61.45297,   MAE: 53.97765,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.13\n",
      "Prediction :R2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:64.51644,   MAE: 55.33812,  MAPE: 109.03%\n",
      "[200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:61.45297,   MAE: 53.97767,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:61.45297,   MAE: 53.97765,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.14\n",
      "Prediction :R2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "[0 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:61.45297,   MAE: 53.97767,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:61.45297,   MAE: 53.97765,  MAPE: 100.00%\n",
      "\n",
      "\n",
      "Trial No.15\n",
      "Prediction :R2\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "[0 Epochs]    RMSE:61.45258,   MAE: 53.97606,  MAPE: 99.99%\n",
      "[200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[400 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[600 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[800 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1000 Epochs]    RMSE:61.45297,   MAE: 53.97767,  MAPE: 100.00%\n",
      "[1200 Epochs]    RMSE:61.45297,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1400 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1600 Epochs]    RMSE:61.45298,   MAE: 53.97766,  MAPE: 100.00%\n",
      "[1800 Epochs]    RMSE:61.45296,   MAE: 53.97766,  MAPE: 100.00%\n",
      "\n",
      "[Final Epochs]    RMSE:61.45297,   MAE: 53.97765,  MAPE: 100.00%\n"
     ]
    }
   ],
   "source": [
    "for M in range(4):\n",
    "    \n",
    "    Tr_result_temp = np.zeros((len(Lr)*len(N1)*len(N2) , 7)) # *len(N2)\n",
    "    cnt = 0\n",
    "    \n",
    "    exec('Label_Trn = TrainLabel_%d'%(M+1))\n",
    "    print('\\n\\n\\n\\n################## Model %d (Predict :'%(M+1) + Model[M] + ') ##################')\n",
    "\n",
    "    for i in range(len(Lr)):\n",
    "        learningRate = Lr[i]\n",
    "\n",
    "        for j in range(len(N1)):\n",
    "            noOfNeuron1 = N1[j]\n",
    "            \n",
    "            for j in range(len(N1)):\n",
    "                noOfNeuron2 = N2[j]\n",
    "\n",
    "                print('\\n\\nTrial No.%d'%(cnt+1))\n",
    "                print('Prediction :' + Model[M])\n",
    "                print('Learning rate : {:.3}'.format(learningRate))\n",
    "                print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "\n",
    "                ################ 신경망 구조 재설계 ################\n",
    "\n",
    "                tf.keras.backend.clear_session()\n",
    "                def ANN_model(input_data):\n",
    "                    model = keras.Sequential()\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron_in,\n",
    "                                                 input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron2,                  activation = 'relu'))  # Hidden Layer 2\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron_out,               activation = 'relu' )) # Output Layer\n",
    "                    model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                                  loss=keras.losses.mean_absolute_error,\n",
    "                                  metrics=['mse','mae','mape'])\n",
    "                    return model\n",
    "                model = ANN_model(Data_Trn)\n",
    "\n",
    "                ################ 신경망 학습 ################\n",
    "\n",
    "                hist = model.fit(Data_Trn, Label_Trn, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100)\n",
    "                print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "                      .format(np.sqrt(hist.history['mse'][-1]), hist.history['mae'][-1], hist.history['mape'][-1]))\n",
    "\n",
    "                Tr_result_temp[cnt,0] = cnt+1\n",
    "                Tr_result_temp[cnt,1] = learningRate\n",
    "                Tr_result_temp[cnt,2] = noOfNeuron1\n",
    "                Tr_result_temp[cnt,3] = noOfNeuron2\n",
    "                Tr_result_temp[cnt,4] = np.sqrt(hist.history['mse'][-1])\n",
    "                Tr_result_temp[cnt,5] = hist.history['mae'][-1]\n",
    "                Tr_result_temp[cnt,6] = hist.history['mape'][-1]\n",
    "\n",
    "                cnt=cnt+1\n",
    "\n",
    "    Tr_result_temp_pd = pd.DataFrame(Tr_result_temp, columns=['Case', 'L.rate', 'Nr-HL1', 'Nr-HL2', 'RMSE', 'MAE', 'MAPE'])\n",
    "    Tr_result_temp_pd.to_csv('Information/Tr_result%d.csv'%(M+1), index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter 조합 설정 [Zeta1, Zeta2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of case : 15\n"
     ]
    }
   ],
   "source": [
    "# 조정 하이퍼파라미터 : 학습율, 은닉층 뉴런 수\n",
    "Lr = [0.001, 0.005, 0.01]   # Learning Rates\n",
    "N1 = [2, 4, 6, 8, 10]       # Number of Neurons on Hidden Layer 1\n",
    "\n",
    "# 고정 하이퍼파라미터 : 입력/출력층 뉴런 수, 학습 Epoch 수\n",
    "noOfNeuron_in  = 4\n",
    "noOfNeuron_out = 1\n",
    "Epoch          = 2000\n",
    "\n",
    "print('Number of case : %d'%(len(Lr)*len(N1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 2 - FRF 특징 기반 Zeta1, Zeta2 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Trial No.1\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 2\n",
      "[0 Epochs]    RMSE:140.04066,   MAE: 122.81072,  MAPE: 748061760.00%\n",
      "[200 Epochs]    RMSE:0.18298,   MAE: 0.12609,  MAPE: 599895.81%\n",
      "[400 Epochs]    RMSE:0.16284,   MAE: 0.10366,  MAPE: 385131.00%\n",
      "[600 Epochs]    RMSE:0.15940,   MAE: 0.10155,  MAPE: 377330.44%\n",
      "[800 Epochs]    RMSE:0.15542,   MAE: 0.09682,  MAPE: 366833.66%\n",
      "[1000 Epochs]    RMSE:0.15353,   MAE: 0.09463,  MAPE: 336823.78%\n",
      "[1200 Epochs]    RMSE:0.15207,   MAE: 0.09335,  MAPE: 329250.72%\n",
      "[1400 Epochs]    RMSE:0.14969,   MAE: 0.09099,  MAPE: 322876.62%\n",
      "[1600 Epochs]    RMSE:0.14518,   MAE: 0.08611,  MAPE: 313811.69%\n",
      "[1800 Epochs]    RMSE:0.14402,   MAE: 0.08420,  MAPE: 306830.16%\n",
      "\n",
      "[Final Epochs]    RMSE:0.14339,   MAE: 0.08527,  MAPE: 303074.88%\n",
      "\n",
      "\n",
      "Trial No.2\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 4\n",
      "[0 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.3\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 6\n",
      "[0 Epochs]    RMSE:4.95513,   MAE: 3.47263,  MAPE: 22509080.00%\n",
      "[200 Epochs]    RMSE:0.24129,   MAE: 0.18695,  MAPE: 974386.06%\n",
      "[400 Epochs]    RMSE:0.17463,   MAE: 0.12612,  MAPE: 207803.16%\n",
      "[600 Epochs]    RMSE:0.14777,   MAE: 0.10031,  MAPE: 68595.17%\n",
      "[800 Epochs]    RMSE:0.13737,   MAE: 0.08949,  MAPE: 48644.76%\n",
      "[1000 Epochs]    RMSE:0.13384,   MAE: 0.08658,  MAPE: 52968.52%\n",
      "[1200 Epochs]    RMSE:0.13016,   MAE: 0.08299,  MAPE: 37831.96%\n",
      "[1400 Epochs]    RMSE:0.12903,   MAE: 0.08233,  MAPE: 52467.57%\n",
      "[1600 Epochs]    RMSE:0.12653,   MAE: 0.07972,  MAPE: 44563.82%\n",
      "[1800 Epochs]    RMSE:0.12563,   MAE: 0.07893,  MAPE: 39028.85%\n",
      "\n",
      "[Final Epochs]    RMSE:0.12432,   MAE: 0.07763,  MAPE: 36760.51%\n",
      "\n",
      "\n",
      "Trial No.4\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 8\n",
      "[0 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.5\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 10\n",
      "[0 Epochs]    RMSE:0.37449,   MAE: 0.27159,  MAPE: 422606.75%\n",
      "[200 Epochs]    RMSE:0.17293,   MAE: 0.11511,  MAPE: 299014.50%\n",
      "[400 Epochs]    RMSE:0.18136,   MAE: 0.10252,  MAPE: 223527.86%\n",
      "[600 Epochs]    RMSE:0.17384,   MAE: 0.09309,  MAPE: 223405.53%\n",
      "[800 Epochs]    RMSE:0.17182,   MAE: 0.08737,  MAPE: 242818.34%\n",
      "[1000 Epochs]    RMSE:0.16975,   MAE: 0.08385,  MAPE: 209723.77%\n",
      "[1200 Epochs]    RMSE:0.11462,   MAE: 0.06398,  MAPE: 132908.58%\n",
      "[1400 Epochs]    RMSE:0.11684,   MAE: 0.05748,  MAPE: 148274.89%\n",
      "[1600 Epochs]    RMSE:0.11227,   MAE: 0.06018,  MAPE: 150452.88%\n",
      "[1800 Epochs]    RMSE:0.10913,   MAE: 0.05761,  MAPE: 154530.61%\n",
      "\n",
      "[Final Epochs]    RMSE:0.10529,   MAE: 0.05143,  MAPE: 115237.35%\n",
      "\n",
      "\n",
      "Trial No.6\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 2\n",
      "[0 Epochs]    RMSE:54.93160,   MAE: 22.42455,  MAPE: 136349600.00%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.7\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 4\n",
      "[0 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.8\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 6\n",
      "[0 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.9\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 8\n",
      "[0 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.10\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 10\n",
      "[0 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.11\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 2\n",
      "[0 Epochs]    RMSE:0.58497,   MAE: 0.50224,  MAPE: 27634.50%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.12\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 4\n",
      "[0 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.13\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 6\n",
      "[0 Epochs]    RMSE:3.00786,   MAE: 0.85816,  MAPE: 2689088.75%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.14\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 8\n",
      "[0 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "\n",
      "Trial No.15\n",
      "Prediction : Zeta\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 10\n",
      "[0 Epochs]    RMSE:1.34812,   MAE: 0.64476,  MAPE: 1387522.88%\n",
      "[200 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[400 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[600 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1000 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1200 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1400 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1600 Epochs]    RMSE:0.58592,   MAE: 0.50335,  MAPE: 99.38%\n",
      "[1800 Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.58591,   MAE: 0.50335,  MAPE: 99.38%\n"
     ]
    }
   ],
   "source": [
    "Tr_result_temp_zeta = np.zeros((len(Lr)*len(N1) , 6)) # *len(N2)\n",
    "cnt = 0\n",
    "\n",
    "Label_Trn = TrainLabel_zeta\n",
    "\n",
    "for i in range(len(Lr)):\n",
    "    learningRate = Lr[i]\n",
    "\n",
    "    for j in range(len(N1)):\n",
    "        noOfNeuron1 = N1[j]\n",
    "\n",
    "        print('\\n\\nTrial No.%d'%(cnt+1))\n",
    "        print('Prediction : Zeta')\n",
    "        print('Learning rate : {:.3}'.format(learningRate))\n",
    "        print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "\n",
    "        ################ 신경망 구조 재설계 ################\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        def ANN_model(input_data):\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron_in,\n",
    "                                         input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron_out,               activation = 'relu' )) # Output Layer\n",
    "            model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                          loss=keras.losses.mean_absolute_error,\n",
    "                          metrics=['mse','mae','mape'])\n",
    "            return model\n",
    "        model = ANN_model(Data_Trn_zeta)\n",
    "\n",
    "        ################ 신경망 학습 ################\n",
    "\n",
    "        hist = model.fit(Data_Trn_zeta, Label_Trn_zeta, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100)\n",
    "        print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "              .format(np.sqrt(hist.history['mse'][-1]), hist.history['mae'][-1], hist.history['mape'][-1]))\n",
    "\n",
    "        Tr_result_temp_zeta[cnt,0] = cnt+1\n",
    "        Tr_result_temp_zeta[cnt,1] = learningRate\n",
    "        Tr_result_temp_zeta[cnt,2] = noOfNeuron1\n",
    "        Tr_result_temp_zeta[cnt,3] = np.sqrt(hist.history['mse'][-1])\n",
    "        Tr_result_temp_zeta[cnt,4] = hist.history['mae'][-1]\n",
    "        Tr_result_temp_zeta[cnt,5] = hist.history['mape'][-1]\n",
    "\n",
    "        cnt=cnt+1\n",
    "\n",
    "Tr_result_temp_zeta_pd = pd.DataFrame(Tr_result_temp_zeta, columns=['Case', 'L.rate', 'Nr-HL1', 'RMSE', 'MAE', 'MAPE'])\n",
    "Tr_result_temp_zeta_pd.to_csv('Information/Tr_result_zeta.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Wn1, Wn2, R1, R2] 최고성능 모델 재학습 및 모델 & 히스토리 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Prediction :R2\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 50\n",
      "[0 Epochs]    RMSE:35.77019,   MAE: 27.47791,  MAPE: 105.59%\n",
      "[200 Epochs]    RMSE:14.07487,   MAE: 10.33123,  MAPE: 33.87%\n",
      "[400 Epochs]    RMSE:11.09676,   MAE: 7.69100,  MAPE: 24.36%\n",
      "[600 Epochs]    RMSE:10.09634,   MAE: 6.78893,  MAPE: 20.98%\n",
      "[800 Epochs]    RMSE:9.32039,   MAE: 6.07312,  MAPE: 18.69%\n",
      "[1000 Epochs]    RMSE:9.66276,   MAE: 6.29410,  MAPE: 19.12%\n",
      "[1200 Epochs]    RMSE:9.21049,   MAE: 5.98573,  MAPE: 19.09%\n",
      "[1400 Epochs]    RMSE:8.43672,   MAE: 5.48943,  MAPE: 17.02%\n",
      "[1600 Epochs]    RMSE:8.49681,   MAE: 5.46639,  MAPE: 16.47%\n",
      "[1800 Epochs]    RMSE:8.18230,   MAE: 5.32142,  MAPE: 16.12%\n",
      "[2000 Epochs]    RMSE:8.06462,   MAE: 5.13005,  MAPE: 16.05%\n",
      "[2200 Epochs]    RMSE:7.86232,   MAE: 4.99284,  MAPE: 15.74%\n",
      "[2400 Epochs]    RMSE:8.17376,   MAE: 5.27540,  MAPE: 17.18%\n",
      "[2600 Epochs]    RMSE:8.03275,   MAE: 5.14656,  MAPE: 15.40%\n",
      "[2800 Epochs]    RMSE:7.70762,   MAE: 4.99720,  MAPE: 15.54%\n",
      "[3000 Epochs]    RMSE:7.96175,   MAE: 5.24073,  MAPE: 15.93%\n",
      "[3200 Epochs]    RMSE:7.65801,   MAE: 4.84677,  MAPE: 15.22%\n",
      "[3400 Epochs]    RMSE:8.17080,   MAE: 5.28378,  MAPE: 16.31%\n",
      "[3600 Epochs]    RMSE:7.65544,   MAE: 4.84973,  MAPE: 14.98%\n",
      "[3800 Epochs]    RMSE:7.73979,   MAE: 5.02802,  MAPE: 15.43%\n",
      "[4000 Epochs]    RMSE:7.59236,   MAE: 4.94587,  MAPE: 15.04%\n",
      "[4200 Epochs]    RMSE:7.56257,   MAE: 4.86508,  MAPE: 15.07%\n",
      "[4400 Epochs]    RMSE:7.35457,   MAE: 4.65742,  MAPE: 14.38%\n",
      "[4600 Epochs]    RMSE:7.56939,   MAE: 4.82918,  MAPE: 14.81%\n",
      "[4800 Epochs]    RMSE:7.32966,   MAE: 4.56160,  MAPE: 14.78%\n",
      "\n",
      "[Final Epochs]    RMSE:7.13043,   MAE: 4.46137,  MAPE: 14.11%\n"
     ]
    }
   ],
   "source": [
    "for M in range(3,4):\n",
    "\n",
    "    Tr_result_temp = pd.read_csv('Information/Tr_result%d.csv'%(M+1))\n",
    "    learningRate   = Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,1]\n",
    "    noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,2])\n",
    "    noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,3])\n",
    "    Epoch          = 5000\n",
    "    \n",
    "    print('\\n\\n\\nPrediction :' + Model[M])\n",
    "    print('Learning rate : {:.3}'.format(learningRate))\n",
    "    print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "    \n",
    "    exec('Label_Trn = TrainLabel_%d'%(M+1))\n",
    "    \n",
    "    ################ 신경망 구조 재설계 ################\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    def ANN_model(input_data):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron_in,\n",
    "                                     input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron2,                  activation = 'relu'))  # Hidden Layer 2\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron_out,               activation = 'relu' )) # Output Layer\n",
    "        model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                      loss=keras.losses.mean_absolute_error,\n",
    "                      metrics=['mse','mae','mape'])\n",
    "        return model\n",
    "    model = ANN_model(Data_Trn)\n",
    "\n",
    "    ################ 신경망 학습 ################\n",
    "\n",
    "    BestModel_temp = model.fit(Data_Trn, Label_Trn, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100)\n",
    "    print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "          .format(np.sqrt(BestModel_temp.history['mse'][-1]), BestModel_temp.history['mae'][-1], BestModel_temp.history['mape'][-1]))\n",
    "    \n",
    "    # 모델 저장\n",
    "    model.save('MLmodels/BestModel_2DOF_0410_M%d.h5'%(M+1))\n",
    "    \n",
    "    # 히스토리 저장\n",
    "    RMSE  = np.sqrt(np.array(BestModel_temp.history['mse'])[:, np.newaxis])\n",
    "    MAE   = np.array(BestModel_temp.history['mae'])[:, np.newaxis]\n",
    "    MAPE  = np.array(BestModel_temp.history['mape'])[:, np.newaxis]\n",
    "\n",
    "    History_temp = pd.DataFrame(np.concatenate([RMSE,MAE,MAPE],axis=1))\n",
    "    History_temp.to_csv(\"./MLmodels/BestModel_2DOF_0410_M%d_history.csv\"%(M+1), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42.66312757],\n",
       "       [42.66312757],\n",
       "       [42.66312757],\n",
       "       ...,\n",
       "       [17.65825948],\n",
       "       [17.65825948],\n",
       "       [17.65825948]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Label_Trn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.summary of <tensorflow.python.keras.engine.sequential.Sequential object at 0x000001B897DAD888>>"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Zeta1, Zeta2] 최고성능 모델 재학습 및 모델 & 히스토리 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Prediction: Zeta, Try 1\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 10\n",
      "[0 Epochs]    RMSE:15.60267,   MAE: 10.06429,  MAPE: 57665172.00%\n",
      "[100 Epochs]    RMSE:0.19664,   MAE: 0.14921,  MAPE: 290622.09%\n",
      "[200 Epochs]    RMSE:0.12157,   MAE: 0.07424,  MAPE: 222010.30%\n",
      "[300 Epochs]    RMSE:0.11600,   MAE: 0.06663,  MAPE: 227779.84%\n",
      "[400 Epochs]    RMSE:0.11603,   MAE: 0.06681,  MAPE: 253632.50%\n",
      "[500 Epochs]    RMSE:0.12022,   MAE: 0.07243,  MAPE: 205273.16%\n",
      "[600 Epochs]    RMSE:0.11620,   MAE: 0.06728,  MAPE: 244139.81%\n",
      "[700 Epochs]    RMSE:0.11613,   MAE: 0.06724,  MAPE: 235316.09%\n",
      "[800 Epochs]    RMSE:0.11655,   MAE: 0.06763,  MAPE: 270509.09%\n",
      "[900 Epochs]    RMSE:0.12389,   MAE: 0.07812,  MAPE: 254739.52%\n",
      "[1000 Epochs]    RMSE:0.11481,   MAE: 0.06560,  MAPE: 251920.42%\n",
      "[1100 Epochs]    RMSE:0.11512,   MAE: 0.06613,  MAPE: 266487.50%\n",
      "[1200 Epochs]    RMSE:0.11359,   MAE: 0.06384,  MAPE: 218287.06%\n",
      "[1300 Epochs]    RMSE:0.11321,   MAE: 0.06319,  MAPE: 228280.72%\n",
      "[1400 Epochs]    RMSE:0.11352,   MAE: 0.06404,  MAPE: 244305.41%\n",
      "[1500 Epochs]    RMSE:0.11535,   MAE: 0.06658,  MAPE: 237692.50%\n",
      "[1600 Epochs]    RMSE:0.11611,   MAE: 0.06787,  MAPE: 175851.03%\n",
      "[1700 Epochs]    RMSE:0.11147,   MAE: 0.06044,  MAPE: 236965.69%\n",
      "[1800 Epochs]    RMSE:0.11289,   MAE: 0.06310,  MAPE: 218451.69%\n",
      "[1900 Epochs]    RMSE:0.11469,   MAE: 0.06549,  MAPE: 213531.16%\n",
      "[2000 Epochs]    RMSE:0.11087,   MAE: 0.05981,  MAPE: 213891.86%\n",
      "[2100 Epochs]    RMSE:0.11156,   MAE: 0.06112,  MAPE: 226415.41%\n",
      "[2200 Epochs]    RMSE:0.11235,   MAE: 0.06228,  MAPE: 199749.28%\n",
      "[2300 Epochs]    RMSE:0.11104,   MAE: 0.06011,  MAPE: 205770.95%\n",
      "[2400 Epochs]    RMSE:0.11205,   MAE: 0.06209,  MAPE: 204526.80%\n",
      "[2500 Epochs]    RMSE:0.11364,   MAE: 0.06444,  MAPE: 194038.12%\n",
      "[2600 Epochs]    RMSE:0.11051,   MAE: 0.05962,  MAPE: 222150.11%\n",
      "[2700 Epochs]    RMSE:0.11152,   MAE: 0.06125,  MAPE: 185398.73%\n",
      "[2800 Epochs]    RMSE:0.11006,   MAE: 0.05886,  MAPE: 194722.59%\n",
      "[2900 Epochs]    RMSE:0.11227,   MAE: 0.06230,  MAPE: 178332.48%\n",
      "\n",
      "[Final Epochs]    RMSE:0.11048,   MAE: 0.05973,  MAPE: 194406.75%\n"
     ]
    }
   ],
   "source": [
    "Repeat = 1\n",
    "trial  = 1\n",
    "noOfNeuron_in = 4\n",
    "\n",
    "while Repeat == 1:\n",
    "\n",
    "    Tr_result_temp = pd.read_csv('Information/Tr_result_zeta.csv')\n",
    "    learningRate   = Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,1]\n",
    "    noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,2])\n",
    "    Epoch          = 3000\n",
    "\n",
    "    print('\\n\\nPrediction: Zeta, Try %d'%(trial))\n",
    "    print('Learning rate : {:.3}'.format(learningRate))\n",
    "    print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "\n",
    "    ################ 신경망 구조 재설계 ################\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    def ANN_model(input_data):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron_in,\n",
    "                                     input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron_out,               activation = 'relu' )) # Output Layer\n",
    "        model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                      loss=keras.losses.mean_absolute_error,\n",
    "                      metrics=['mse','mae','mape'])\n",
    "        return model\n",
    "    model = ANN_model(Data_Trn_zeta)\n",
    "\n",
    "    ################ 신경망 학습 ################\n",
    "\n",
    "    BestModel_temp = model.fit(Data_Trn_zeta, Label_Trn_zeta, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100)\n",
    "    print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "          .format(np.sqrt(BestModel_temp.history['mse'][-1]), BestModel_temp.history['mae'][-1], BestModel_temp.history['mape'][-1]))\n",
    "\n",
    "    if BestModel_temp.history['mae'][-1] < 0.07:\n",
    "        break\n",
    "    \n",
    "    trial += 1\n",
    "    \n",
    "# 모델 저장\n",
    "model.save('MLmodels/BestModel_2DOF_0410_zeta.h5')\n",
    "\n",
    "# 히스토리 저장\n",
    "RMSE  = np.sqrt(np.array(BestModel_temp.history['mse'])[:, np.newaxis])\n",
    "MAE   = np.array(BestModel_temp.history['mae'])[:, np.newaxis]\n",
    "MAPE  = np.array(BestModel_temp.history['mape'])[:, np.newaxis]\n",
    "\n",
    "History_temp = pd.DataFrame(np.concatenate([RMSE,MAE,MAPE],axis=1))\n",
    "History_temp.to_csv(\"./MLmodels/BestModel_2DOF_0410_zeta_history.csv\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
