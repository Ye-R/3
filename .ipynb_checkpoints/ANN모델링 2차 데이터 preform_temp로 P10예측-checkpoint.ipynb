{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sb\n",
    "import scipy.stats       as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "tf.random.set_seed(777)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "스케일러 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>P10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DP 0</td>\n",
       "      <td>80</td>\n",
       "      <td>120.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.002414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DP 1</td>\n",
       "      <td>80</td>\n",
       "      <td>80.2</td>\n",
       "      <td>105.4</td>\n",
       "      <td>103.8</td>\n",
       "      <td>114.2</td>\n",
       "      <td>82.2</td>\n",
       "      <td>99.8</td>\n",
       "      <td>100.6</td>\n",
       "      <td>0.002639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DP 2</td>\n",
       "      <td>80</td>\n",
       "      <td>80.6</td>\n",
       "      <td>83.8</td>\n",
       "      <td>97.0</td>\n",
       "      <td>105.8</td>\n",
       "      <td>86.2</td>\n",
       "      <td>113.4</td>\n",
       "      <td>81.8</td>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DP 3</td>\n",
       "      <td>80</td>\n",
       "      <td>81.0</td>\n",
       "      <td>93.8</td>\n",
       "      <td>115.0</td>\n",
       "      <td>118.6</td>\n",
       "      <td>105.4</td>\n",
       "      <td>98.2</td>\n",
       "      <td>98.6</td>\n",
       "      <td>0.002549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>DP 4</td>\n",
       "      <td>80</td>\n",
       "      <td>81.4</td>\n",
       "      <td>107.8</td>\n",
       "      <td>87.4</td>\n",
       "      <td>98.6</td>\n",
       "      <td>108.2</td>\n",
       "      <td>87.8</td>\n",
       "      <td>91.8</td>\n",
       "      <td>0.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>DP 96</td>\n",
       "      <td>80</td>\n",
       "      <td>118.2</td>\n",
       "      <td>108.2</td>\n",
       "      <td>116.6</td>\n",
       "      <td>117.0</td>\n",
       "      <td>106.2</td>\n",
       "      <td>94.6</td>\n",
       "      <td>82.6</td>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>DP 97</td>\n",
       "      <td>80</td>\n",
       "      <td>118.6</td>\n",
       "      <td>109.8</td>\n",
       "      <td>80.6</td>\n",
       "      <td>109.8</td>\n",
       "      <td>107.0</td>\n",
       "      <td>99.4</td>\n",
       "      <td>94.2</td>\n",
       "      <td>0.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>DP 98</td>\n",
       "      <td>80</td>\n",
       "      <td>119.0</td>\n",
       "      <td>104.6</td>\n",
       "      <td>109.8</td>\n",
       "      <td>111.0</td>\n",
       "      <td>89.4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.002611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>DP 99</td>\n",
       "      <td>80</td>\n",
       "      <td>119.4</td>\n",
       "      <td>80.6</td>\n",
       "      <td>100.2</td>\n",
       "      <td>119.4</td>\n",
       "      <td>109.8</td>\n",
       "      <td>109.4</td>\n",
       "      <td>89.8</td>\n",
       "      <td>0.002535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>DP 100</td>\n",
       "      <td>80</td>\n",
       "      <td>119.8</td>\n",
       "      <td>109.4</td>\n",
       "      <td>80.2</td>\n",
       "      <td>94.6</td>\n",
       "      <td>119.4</td>\n",
       "      <td>107.4</td>\n",
       "      <td>116.6</td>\n",
       "      <td>0.002706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>101 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name  P1     P2     P3     P4     P5     P6     P7     P8       P10\n",
       "0      DP 0  80  120.0  110.0  100.0   98.0   85.0   80.0   80.0  0.002414\n",
       "1      DP 1  80   80.2  105.4  103.8  114.2   82.2   99.8  100.6  0.002639\n",
       "2      DP 2  80   80.6   83.8   97.0  105.8   86.2  113.4   81.8  0.002597\n",
       "3      DP 3  80   81.0   93.8  115.0  118.6  105.4   98.2   98.6  0.002549\n",
       "4      DP 4  80   81.4  107.8   87.4   98.6  108.2   87.8   91.8  0.002536\n",
       "..      ...  ..    ...    ...    ...    ...    ...    ...    ...       ...\n",
       "96    DP 96  80  118.2  108.2  116.6  117.0  106.2   94.6   82.6  0.002395\n",
       "97    DP 97  80  118.6  109.8   80.6  109.8  107.0   99.4   94.2  0.002536\n",
       "98    DP 98  80  119.0  104.6  109.8  111.0   89.4   93.0   97.0  0.002611\n",
       "99    DP 99  80  119.4   80.6  100.2  119.4  109.8  109.4   89.8  0.002535\n",
       "100  DP 100  80  119.8  109.4   80.2   94.6  119.4  107.4  116.6  0.002706\n",
       "\n",
       "[101 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputdata = pd.read_csv('./input-test1.csv',skiprows = 6, sep=',')\n",
    "inputdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range (100):\n",
    "    temp_data = pd.read_csv('./test1/dp%d-preform-temp.csv'%(i+1),skiprows = 4, sep=',')\n",
    "    s = \"temp_dp%d = temp_data\"%(i+1)\n",
    "    exec(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training, label 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Curve Length on Polyline 1 [ m ]</th>\n",
       "      <th>TEMPERATURE [ K ]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>389.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002953</td>\n",
       "      <td>389.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.005916</td>\n",
       "      <td>389.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.008878</td>\n",
       "      <td>389.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.011840</td>\n",
       "      <td>389.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.093458</td>\n",
       "      <td>392.513092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.096063</td>\n",
       "      <td>384.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.098668</td>\n",
       "      <td>374.220978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.101273</td>\n",
       "      <td>363.863098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.104965</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Curve Length on Polyline 1 [ m ]  TEMPERATURE [ K ]\n",
       "0                           0.000000         389.750000\n",
       "1                           0.002953         389.750000\n",
       "2                           0.005916         389.750000\n",
       "3                           0.008878         389.750000\n",
       "4                           0.011840         389.750000\n",
       "..                               ...                ...\n",
       "32                          0.093458         392.513092\n",
       "33                          0.096063         384.500000\n",
       "34                          0.098668         374.220978\n",
       "35                          0.101273         363.863098\n",
       "36                          0.104965         353.150024\n",
       "\n",
       "[37 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dp100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData_ = np.zeros((100,37))\n",
    "for i in range (100):\n",
    "    exec(\"TrainData_[i,:] = temp_dp%d.iloc[:,1]\"%(i+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.657806</td>\n",
       "      <td>373.540253</td>\n",
       "      <td>...</td>\n",
       "      <td>377.957092</td>\n",
       "      <td>378.389252</td>\n",
       "      <td>374.274780</td>\n",
       "      <td>367.468018</td>\n",
       "      <td>360.661255</td>\n",
       "      <td>354.408600</td>\n",
       "      <td>353.307526</td>\n",
       "      <td>353.255890</td>\n",
       "      <td>353.203827</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.949982</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>358.591217</td>\n",
       "      <td>363.235382</td>\n",
       "      <td>...</td>\n",
       "      <td>361.841492</td>\n",
       "      <td>358.276031</td>\n",
       "      <td>356.407104</td>\n",
       "      <td>355.542755</td>\n",
       "      <td>354.678406</td>\n",
       "      <td>353.884430</td>\n",
       "      <td>353.622620</td>\n",
       "      <td>353.467651</td>\n",
       "      <td>353.311493</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.703918</td>\n",
       "      <td>371.645111</td>\n",
       "      <td>...</td>\n",
       "      <td>374.806030</td>\n",
       "      <td>369.079712</td>\n",
       "      <td>364.778473</td>\n",
       "      <td>361.321045</td>\n",
       "      <td>357.863647</td>\n",
       "      <td>354.687683</td>\n",
       "      <td>353.937683</td>\n",
       "      <td>353.679413</td>\n",
       "      <td>353.419159</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.489075</td>\n",
       "      <td>363.901215</td>\n",
       "      <td>...</td>\n",
       "      <td>373.390411</td>\n",
       "      <td>378.900635</td>\n",
       "      <td>376.471191</td>\n",
       "      <td>369.340302</td>\n",
       "      <td>362.209381</td>\n",
       "      <td>355.658997</td>\n",
       "      <td>354.252747</td>\n",
       "      <td>353.891174</td>\n",
       "      <td>353.526825</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>366.413361</td>\n",
       "      <td>364.708527</td>\n",
       "      <td>...</td>\n",
       "      <td>366.850708</td>\n",
       "      <td>360.800262</td>\n",
       "      <td>357.939240</td>\n",
       "      <td>356.966858</td>\n",
       "      <td>355.994476</td>\n",
       "      <td>355.101227</td>\n",
       "      <td>354.567841</td>\n",
       "      <td>354.102966</td>\n",
       "      <td>353.634521</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>357.132751</td>\n",
       "      <td>358.896362</td>\n",
       "      <td>...</td>\n",
       "      <td>384.462769</td>\n",
       "      <td>382.193848</td>\n",
       "      <td>383.046509</td>\n",
       "      <td>385.747620</td>\n",
       "      <td>388.448730</td>\n",
       "      <td>390.929901</td>\n",
       "      <td>383.239716</td>\n",
       "      <td>373.373932</td>\n",
       "      <td>363.432404</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.949188</td>\n",
       "      <td>368.713409</td>\n",
       "      <td>...</td>\n",
       "      <td>372.129425</td>\n",
       "      <td>380.016632</td>\n",
       "      <td>384.442932</td>\n",
       "      <td>386.819885</td>\n",
       "      <td>389.196869</td>\n",
       "      <td>391.380310</td>\n",
       "      <td>383.554779</td>\n",
       "      <td>373.585693</td>\n",
       "      <td>363.540070</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>369.689087</td>\n",
       "      <td>369.101227</td>\n",
       "      <td>...</td>\n",
       "      <td>379.676941</td>\n",
       "      <td>378.272400</td>\n",
       "      <td>380.192993</td>\n",
       "      <td>384.082550</td>\n",
       "      <td>387.972137</td>\n",
       "      <td>391.545074</td>\n",
       "      <td>383.869873</td>\n",
       "      <td>373.797455</td>\n",
       "      <td>363.647736</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.949982</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>365.208466</td>\n",
       "      <td>368.089050</td>\n",
       "      <td>...</td>\n",
       "      <td>361.013123</td>\n",
       "      <td>355.718994</td>\n",
       "      <td>360.332489</td>\n",
       "      <td>370.812744</td>\n",
       "      <td>381.292999</td>\n",
       "      <td>390.920074</td>\n",
       "      <td>384.184937</td>\n",
       "      <td>374.009216</td>\n",
       "      <td>363.755432</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>388.689911</td>\n",
       "      <td>387.337799</td>\n",
       "      <td>...</td>\n",
       "      <td>371.729431</td>\n",
       "      <td>379.616608</td>\n",
       "      <td>384.314362</td>\n",
       "      <td>387.123505</td>\n",
       "      <td>389.932678</td>\n",
       "      <td>392.513092</td>\n",
       "      <td>384.500000</td>\n",
       "      <td>374.220978</td>\n",
       "      <td>363.863098</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5   \\\n",
       "0   373.750000  373.750000  373.750000  373.750000  373.750000  373.750000   \n",
       "1   354.950012  354.950012  354.950012  354.950012  354.950012  354.950012   \n",
       "2   371.750000  371.750000  371.750000  371.750000  371.750000  371.750000   \n",
       "3   364.950012  364.950012  364.950012  364.950012  364.950012  364.950012   \n",
       "4   367.750000  367.750000  367.750000  367.750000  367.750000  367.750000   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "95  355.750000  355.750000  355.750000  355.750000  355.750000  355.750000   \n",
       "96  367.350006  367.350006  367.350006  367.350006  367.350006  367.350006   \n",
       "97  370.149994  370.149994  370.149994  370.149994  370.149994  370.149994   \n",
       "98  362.950012  362.950012  362.950012  362.950012  362.950012  362.950012   \n",
       "99  389.750000  389.750000  389.750000  389.750000  389.750000  389.750000   \n",
       "\n",
       "            6           7           8           9   ...          27  \\\n",
       "0   373.750000  373.750000  373.657806  373.540253  ...  377.957092   \n",
       "1   354.949982  354.950012  358.591217  363.235382  ...  361.841492   \n",
       "2   371.750000  371.750000  371.703918  371.645111  ...  374.806030   \n",
       "3   364.950012  364.950012  364.489075  363.901215  ...  373.390411   \n",
       "4   367.750000  367.750000  366.413361  364.708527  ...  366.850708   \n",
       "..         ...         ...         ...         ...  ...         ...   \n",
       "95  355.750000  355.750000  357.132751  358.896362  ...  384.462769   \n",
       "96  367.350006  367.350006  367.949188  368.713409  ...  372.129425   \n",
       "97  370.149994  370.149994  369.689087  369.101227  ...  379.676941   \n",
       "98  362.949982  362.950012  365.208466  368.089050  ...  361.013123   \n",
       "99  389.750000  389.750000  388.689911  387.337799  ...  371.729431   \n",
       "\n",
       "            28          29          30          31          32          33  \\\n",
       "0   378.389252  374.274780  367.468018  360.661255  354.408600  353.307526   \n",
       "1   358.276031  356.407104  355.542755  354.678406  353.884430  353.622620   \n",
       "2   369.079712  364.778473  361.321045  357.863647  354.687683  353.937683   \n",
       "3   378.900635  376.471191  369.340302  362.209381  355.658997  354.252747   \n",
       "4   360.800262  357.939240  356.966858  355.994476  355.101227  354.567841   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "95  382.193848  383.046509  385.747620  388.448730  390.929901  383.239716   \n",
       "96  380.016632  384.442932  386.819885  389.196869  391.380310  383.554779   \n",
       "97  378.272400  380.192993  384.082550  387.972137  391.545074  383.869873   \n",
       "98  355.718994  360.332489  370.812744  381.292999  390.920074  384.184937   \n",
       "99  379.616608  384.314362  387.123505  389.932678  392.513092  384.500000   \n",
       "\n",
       "            34          35          36  \n",
       "0   353.255890  353.203827  353.149994  \n",
       "1   353.467651  353.311493  353.149994  \n",
       "2   353.679413  353.419159  353.149994  \n",
       "3   353.891174  353.526825  353.149994  \n",
       "4   354.102966  353.634521  353.149994  \n",
       "..         ...         ...         ...  \n",
       "95  373.373932  363.432404  353.150024  \n",
       "96  373.585693  363.540070  353.150024  \n",
       "97  373.797455  363.647736  353.150024  \n",
       "98  374.009216  363.755432  353.150024  \n",
       "99  374.220978  363.863098  353.150024  \n",
       "\n",
       "[100 rows x 37 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData = pd.DataFrame(TrainData_)\n",
    "TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainLabel_ = inputdata.iloc[1:,9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.657806</td>\n",
       "      <td>373.540253</td>\n",
       "      <td>...</td>\n",
       "      <td>377.957092</td>\n",
       "      <td>378.389252</td>\n",
       "      <td>374.274780</td>\n",
       "      <td>367.468018</td>\n",
       "      <td>360.661255</td>\n",
       "      <td>354.408600</td>\n",
       "      <td>353.307526</td>\n",
       "      <td>353.255890</td>\n",
       "      <td>353.203827</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.949982</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>358.591217</td>\n",
       "      <td>363.235382</td>\n",
       "      <td>...</td>\n",
       "      <td>361.841492</td>\n",
       "      <td>358.276031</td>\n",
       "      <td>356.407104</td>\n",
       "      <td>355.542755</td>\n",
       "      <td>354.678406</td>\n",
       "      <td>353.884430</td>\n",
       "      <td>353.622620</td>\n",
       "      <td>353.467651</td>\n",
       "      <td>353.311493</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.703918</td>\n",
       "      <td>371.645111</td>\n",
       "      <td>...</td>\n",
       "      <td>374.806030</td>\n",
       "      <td>369.079712</td>\n",
       "      <td>364.778473</td>\n",
       "      <td>361.321045</td>\n",
       "      <td>357.863647</td>\n",
       "      <td>354.687683</td>\n",
       "      <td>353.937683</td>\n",
       "      <td>353.679413</td>\n",
       "      <td>353.419159</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.489075</td>\n",
       "      <td>363.901215</td>\n",
       "      <td>...</td>\n",
       "      <td>373.390411</td>\n",
       "      <td>378.900635</td>\n",
       "      <td>376.471191</td>\n",
       "      <td>369.340302</td>\n",
       "      <td>362.209381</td>\n",
       "      <td>355.658997</td>\n",
       "      <td>354.252747</td>\n",
       "      <td>353.891174</td>\n",
       "      <td>353.526825</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>366.413361</td>\n",
       "      <td>364.708527</td>\n",
       "      <td>...</td>\n",
       "      <td>366.850708</td>\n",
       "      <td>360.800262</td>\n",
       "      <td>357.939240</td>\n",
       "      <td>356.966858</td>\n",
       "      <td>355.994476</td>\n",
       "      <td>355.101227</td>\n",
       "      <td>354.567841</td>\n",
       "      <td>354.102966</td>\n",
       "      <td>353.634521</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>355.750000</td>\n",
       "      <td>357.132751</td>\n",
       "      <td>358.896362</td>\n",
       "      <td>...</td>\n",
       "      <td>384.462769</td>\n",
       "      <td>382.193848</td>\n",
       "      <td>383.046509</td>\n",
       "      <td>385.747620</td>\n",
       "      <td>388.448730</td>\n",
       "      <td>390.929901</td>\n",
       "      <td>383.239716</td>\n",
       "      <td>373.373932</td>\n",
       "      <td>363.432404</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.350006</td>\n",
       "      <td>367.949188</td>\n",
       "      <td>368.713409</td>\n",
       "      <td>...</td>\n",
       "      <td>372.129425</td>\n",
       "      <td>380.016632</td>\n",
       "      <td>384.442932</td>\n",
       "      <td>386.819885</td>\n",
       "      <td>389.196869</td>\n",
       "      <td>391.380310</td>\n",
       "      <td>383.554779</td>\n",
       "      <td>373.585693</td>\n",
       "      <td>363.540070</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>370.149994</td>\n",
       "      <td>369.689087</td>\n",
       "      <td>369.101227</td>\n",
       "      <td>...</td>\n",
       "      <td>379.676941</td>\n",
       "      <td>378.272400</td>\n",
       "      <td>380.192993</td>\n",
       "      <td>384.082550</td>\n",
       "      <td>387.972137</td>\n",
       "      <td>391.545074</td>\n",
       "      <td>383.869873</td>\n",
       "      <td>373.797455</td>\n",
       "      <td>363.647736</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>362.949982</td>\n",
       "      <td>362.950012</td>\n",
       "      <td>365.208466</td>\n",
       "      <td>368.089050</td>\n",
       "      <td>...</td>\n",
       "      <td>361.013123</td>\n",
       "      <td>355.718994</td>\n",
       "      <td>360.332489</td>\n",
       "      <td>370.812744</td>\n",
       "      <td>381.292999</td>\n",
       "      <td>390.920074</td>\n",
       "      <td>384.184937</td>\n",
       "      <td>374.009216</td>\n",
       "      <td>363.755432</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>389.750000</td>\n",
       "      <td>388.689911</td>\n",
       "      <td>387.337799</td>\n",
       "      <td>...</td>\n",
       "      <td>371.729431</td>\n",
       "      <td>379.616608</td>\n",
       "      <td>384.314362</td>\n",
       "      <td>387.123505</td>\n",
       "      <td>389.932678</td>\n",
       "      <td>392.513092</td>\n",
       "      <td>384.500000</td>\n",
       "      <td>374.220978</td>\n",
       "      <td>363.863098</td>\n",
       "      <td>353.150024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5   \\\n",
       "0   373.750000  373.750000  373.750000  373.750000  373.750000  373.750000   \n",
       "1   354.950012  354.950012  354.950012  354.950012  354.950012  354.950012   \n",
       "2   371.750000  371.750000  371.750000  371.750000  371.750000  371.750000   \n",
       "3   364.950012  364.950012  364.950012  364.950012  364.950012  364.950012   \n",
       "4   367.750000  367.750000  367.750000  367.750000  367.750000  367.750000   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "95  355.750000  355.750000  355.750000  355.750000  355.750000  355.750000   \n",
       "96  367.350006  367.350006  367.350006  367.350006  367.350006  367.350006   \n",
       "97  370.149994  370.149994  370.149994  370.149994  370.149994  370.149994   \n",
       "98  362.950012  362.950012  362.950012  362.950012  362.950012  362.950012   \n",
       "99  389.750000  389.750000  389.750000  389.750000  389.750000  389.750000   \n",
       "\n",
       "            6           7           8           9   ...          27  \\\n",
       "0   373.750000  373.750000  373.657806  373.540253  ...  377.957092   \n",
       "1   354.949982  354.950012  358.591217  363.235382  ...  361.841492   \n",
       "2   371.750000  371.750000  371.703918  371.645111  ...  374.806030   \n",
       "3   364.950012  364.950012  364.489075  363.901215  ...  373.390411   \n",
       "4   367.750000  367.750000  366.413361  364.708527  ...  366.850708   \n",
       "..         ...         ...         ...         ...  ...         ...   \n",
       "95  355.750000  355.750000  357.132751  358.896362  ...  384.462769   \n",
       "96  367.350006  367.350006  367.949188  368.713409  ...  372.129425   \n",
       "97  370.149994  370.149994  369.689087  369.101227  ...  379.676941   \n",
       "98  362.949982  362.950012  365.208466  368.089050  ...  361.013123   \n",
       "99  389.750000  389.750000  388.689911  387.337799  ...  371.729431   \n",
       "\n",
       "            28          29          30          31          32          33  \\\n",
       "0   378.389252  374.274780  367.468018  360.661255  354.408600  353.307526   \n",
       "1   358.276031  356.407104  355.542755  354.678406  353.884430  353.622620   \n",
       "2   369.079712  364.778473  361.321045  357.863647  354.687683  353.937683   \n",
       "3   378.900635  376.471191  369.340302  362.209381  355.658997  354.252747   \n",
       "4   360.800262  357.939240  356.966858  355.994476  355.101227  354.567841   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "95  382.193848  383.046509  385.747620  388.448730  390.929901  383.239716   \n",
       "96  380.016632  384.442932  386.819885  389.196869  391.380310  383.554779   \n",
       "97  378.272400  380.192993  384.082550  387.972137  391.545074  383.869873   \n",
       "98  355.718994  360.332489  370.812744  381.292999  390.920074  384.184937   \n",
       "99  379.616608  384.314362  387.123505  389.932678  392.513092  384.500000   \n",
       "\n",
       "            34          35          36  \n",
       "0   353.255890  353.203827  353.149994  \n",
       "1   353.467651  353.311493  353.149994  \n",
       "2   353.679413  353.419159  353.149994  \n",
       "3   353.891174  353.526825  353.149994  \n",
       "4   354.102966  353.634521  353.149994  \n",
       "..         ...         ...         ...  \n",
       "95  373.373932  363.432404  353.150024  \n",
       "96  373.585693  363.540070  353.150024  \n",
       "97  373.797455  363.647736  353.150024  \n",
       "98  374.009216  363.755432  353.150024  \n",
       "99  374.220978  363.863098  353.150024  \n",
       "\n",
       "[100 rows x 37 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_rows',10)\n",
    "TrainData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.002529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.002536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.002611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.002706</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          P10\n",
       "1    0.002639\n",
       "2    0.002597\n",
       "3    0.002549\n",
       "4    0.002536\n",
       "5    0.002529\n",
       "..        ...\n",
       "96   0.002395\n",
       "97   0.002536\n",
       "98   0.002611\n",
       "99   0.002535\n",
       "100  0.002706\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(TrainLabel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.002615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.002395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.002551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.002612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.002691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.002751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              P10\n",
       "count  100.000000\n",
       "mean     0.002615\n",
       "std      0.000085\n",
       "min      0.002395\n",
       "25%      0.002551\n",
       "50%      0.002612\n",
       "75%      0.002691\n",
       "max      0.002751"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(TrainLabel_).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = np.max(TrainLabel_)\n",
    "min_value = np.min(TrainLabel_)\n",
    "\n",
    "dist_value = max_value - min_value\n",
    "\n",
    "TrainLabel = pd.DataFrame(((TrainLabel_ - min_value)/dist_value)+0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.184604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.068196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.931607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.897109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.875775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.896182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.106091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.894975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.373488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          P10\n",
       "1    1.184604\n",
       "2    1.068196\n",
       "3    0.931607\n",
       "4    0.897109\n",
       "5    0.875775\n",
       "..        ...\n",
       "96   0.500000\n",
       "97   0.896182\n",
       "98   1.106091\n",
       "99   0.894975\n",
       "100  1.373488\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"Display.max_rows\",10)\n",
    "pd.DataFrame(TrainLabel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANN hyperparameter 조절에 따른 학습성능 확인 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 지정 iteration마다 학습과정 확인 함수(Class) 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EpochForPrint = 100\n",
    "\n",
    "class AccuracyPerEpoch(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        keras.callbacks.Callback()\n",
    "        if epoch%EpochForPrint == 0:\n",
    "            print(\"[{} Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "                  .format(epoch, np.sqrt(logs['mse']), logs['mae'], logs['mape']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Hyperparameter 조합 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of case : 45\n"
     ]
    }
   ],
   "source": [
    "# 조정 하이퍼파라미터 : 학습율, 은닉층 뉴런 수\n",
    "Lr = [0.001, 0.005, 0.01]   # Learning Rates\n",
    "N1 = [30, 40, 50, 60, 70]   # Number of Neurons on Hidden Layer 1\n",
    "N2 = [10, 20, 30]           # Number of Neurons on Hidden Layer 2\n",
    "\n",
    "Model = ['thickness']\n",
    "\n",
    "# 고정 하이퍼파라미터 : 입력/출력층 뉴런 수, 학습 Epoch 수\n",
    "noOfNeuron_in  = 50\n",
    "noOfNeuron_out = 1\n",
    "Epoch          = 5000\n",
    "\n",
    "print('Number of case : %d'%(len(Lr)*len(N1)*len(N2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 학습 1 - FFT 특징 기반 Wn1, Wn2, R1, R2 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "################## Model 1 (Predict :thickness) ##################\n",
      "\n",
      "\n",
      "Trial No.1\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 30\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:371.65851,   MAE: 371.55945,  MAPE: 35198.29%\n",
      "[100 Epochs]    RMSE:3.87188,   MAE: 3.17100,  MAPE: 313.41%\n",
      "[200 Epochs]    RMSE:2.19916,   MAE: 1.70945,  MAPE: 163.51%\n",
      "[300 Epochs]    RMSE:1.55199,   MAE: 1.21022,  MAPE: 116.42%\n",
      "[400 Epochs]    RMSE:1.90073,   MAE: 1.67766,  MAPE: 160.75%\n",
      "[500 Epochs]    RMSE:2.18001,   MAE: 1.96019,  MAPE: 194.40%\n",
      "[600 Epochs]    RMSE:1.84949,   MAE: 1.66269,  MAPE: 165.10%\n",
      "[700 Epochs]    RMSE:1.55971,   MAE: 1.40632,  MAPE: 138.83%\n",
      "[800 Epochs]    RMSE:1.58495,   MAE: 1.47276,  MAPE: 142.93%\n",
      "[900 Epochs]    RMSE:1.38897,   MAE: 1.29462,  MAPE: 126.61%\n",
      "[1000 Epochs]    RMSE:1.22834,   MAE: 1.15812,  MAPE: 111.78%\n",
      "[1100 Epochs]    RMSE:0.91920,   MAE: 0.84121,  MAPE: 80.98%\n",
      "[1200 Epochs]    RMSE:1.02823,   MAE: 0.97269,  MAPE: 92.43%\n",
      "[1300 Epochs]    RMSE:0.91377,   MAE: 0.85725,  MAPE: 81.04%\n",
      "[1400 Epochs]    RMSE:0.73848,   MAE: 0.67526,  MAPE: 63.24%\n",
      "[1500 Epochs]    RMSE:0.92165,   MAE: 0.87396,  MAPE: 81.53%\n",
      "[1600 Epochs]    RMSE:0.74909,   MAE: 0.68631,  MAPE: 62.80%\n",
      "[1700 Epochs]    RMSE:0.81383,   MAE: 0.75992,  MAPE: 69.99%\n",
      "[1800 Epochs]    RMSE:0.30128,   MAE: 0.25310,  MAPE: 24.63%\n",
      "[1900 Epochs]    RMSE:0.77367,   MAE: 0.73892,  MAPE: 71.47%\n",
      "[2000 Epochs]    RMSE:0.57089,   MAE: 0.53407,  MAPE: 51.53%\n",
      "[2100 Epochs]    RMSE:0.38532,   MAE: 0.35489,  MAPE: 34.67%\n",
      "[2200 Epochs]    RMSE:0.27941,   MAE: 0.24484,  MAPE: 24.78%\n",
      "[2300 Epochs]    RMSE:1.91403,   MAE: 1.90807,  MAPE: 181.75%\n",
      "[2400 Epochs]    RMSE:1.96191,   MAE: 1.94744,  MAPE: 180.27%\n",
      "[2500 Epochs]    RMSE:0.16197,   MAE: 0.12964,  MAPE: 11.90%\n",
      "[2600 Epochs]    RMSE:0.41945,   MAE: 0.39943,  MAPE: 36.05%\n",
      "[2700 Epochs]    RMSE:0.39627,   MAE: 0.35657,  MAPE: 31.16%\n",
      "[2800 Epochs]    RMSE:0.36254,   MAE: 0.32100,  MAPE: 27.76%\n",
      "[2900 Epochs]    RMSE:0.27599,   MAE: 0.24524,  MAPE: 24.89%\n",
      "[3000 Epochs]    RMSE:0.77718,   MAE: 0.76361,  MAPE: 73.89%\n",
      "[3100 Epochs]    RMSE:1.14837,   MAE: 1.13703,  MAPE: 109.75%\n",
      "[3200 Epochs]    RMSE:0.31081,   MAE: 0.28280,  MAPE: 29.02%\n",
      "[3300 Epochs]    RMSE:0.38660,   MAE: 0.35156,  MAPE: 36.12%\n",
      "[3400 Epochs]    RMSE:0.32810,   MAE: 0.29151,  MAPE: 30.27%\n",
      "[3500 Epochs]    RMSE:0.35537,   MAE: 0.32368,  MAPE: 33.16%\n",
      "[3600 Epochs]    RMSE:0.34652,   MAE: 0.31427,  MAPE: 32.24%\n",
      "[3700 Epochs]    RMSE:0.35044,   MAE: 0.31934,  MAPE: 32.64%\n",
      "[3800 Epochs]    RMSE:0.21065,   MAE: 0.18468,  MAPE: 18.92%\n",
      "[3900 Epochs]    RMSE:0.27412,   MAE: 0.25089,  MAPE: 22.26%\n",
      "[4000 Epochs]    RMSE:0.51694,   MAE: 0.50507,  MAPE: 49.12%\n",
      "[4100 Epochs]    RMSE:0.20220,   MAE: 0.18192,  MAPE: 18.19%\n",
      "[4200 Epochs]    RMSE:0.12191,   MAE: 0.10174,  MAPE: 10.44%\n",
      "[4300 Epochs]    RMSE:0.24772,   MAE: 0.22180,  MAPE: 22.54%\n",
      "[4400 Epochs]    RMSE:0.28566,   MAE: 0.25486,  MAPE: 26.37%\n",
      "[4500 Epochs]    RMSE:0.33140,   MAE: 0.30484,  MAPE: 31.07%\n",
      "[4600 Epochs]    RMSE:0.31789,   MAE: 0.29096,  MAPE: 29.65%\n",
      "[4700 Epochs]    RMSE:0.31713,   MAE: 0.29167,  MAPE: 29.55%\n",
      "[4800 Epochs]    RMSE:0.30716,   MAE: 0.27994,  MAPE: 28.46%\n",
      "[4900 Epochs]    RMSE:0.26712,   MAE: 0.23675,  MAPE: 24.32%\n",
      "\n",
      "[Final Epochs]    RMSE:0.19605,   MAE: 0.15990,  MAPE: 13.50%\n",
      "\n",
      "\n",
      "Trial No.2\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 30\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:352.93603,   MAE: 352.88562,  MAPE: 33233.14%\n",
      "[100 Epochs]    RMSE:0.55730,   MAE: 0.43225,  MAPE: 40.15%\n",
      "[200 Epochs]    RMSE:0.45460,   MAE: 0.35285,  MAPE: 33.14%\n",
      "[300 Epochs]    RMSE:0.38430,   MAE: 0.30185,  MAPE: 28.90%\n",
      "[400 Epochs]    RMSE:0.32778,   MAE: 0.25877,  MAPE: 24.95%\n",
      "[500 Epochs]    RMSE:0.37315,   MAE: 0.31217,  MAPE: 28.68%\n",
      "[600 Epochs]    RMSE:0.33445,   MAE: 0.27975,  MAPE: 25.60%\n",
      "[700 Epochs]    RMSE:0.19016,   MAE: 0.15287,  MAPE: 14.33%\n",
      "[800 Epochs]    RMSE:0.30047,   MAE: 0.26546,  MAPE: 26.62%\n",
      "[900 Epochs]    RMSE:0.25517,   MAE: 0.21762,  MAPE: 19.29%\n",
      "[1000 Epochs]    RMSE:0.23247,   MAE: 0.19622,  MAPE: 17.24%\n",
      "[1100 Epochs]    RMSE:0.39541,   MAE: 0.37154,  MAPE: 33.37%\n",
      "[1200 Epochs]    RMSE:0.38675,   MAE: 0.35807,  MAPE: 32.15%\n",
      "[1300 Epochs]    RMSE:0.34219,   MAE: 0.30979,  MAPE: 27.61%\n",
      "[1400 Epochs]    RMSE:0.32688,   MAE: 0.29315,  MAPE: 25.99%\n",
      "[1500 Epochs]    RMSE:0.39752,   MAE: 0.37056,  MAPE: 33.16%\n",
      "[1600 Epochs]    RMSE:0.33134,   MAE: 0.29887,  MAPE: 26.36%\n",
      "[1700 Epochs]    RMSE:0.29697,   MAE: 0.26116,  MAPE: 22.87%\n",
      "[1800 Epochs]    RMSE:0.26705,   MAE: 0.22976,  MAPE: 20.02%\n",
      "[1900 Epochs]    RMSE:0.28937,   MAE: 0.25622,  MAPE: 22.52%\n",
      "[2000 Epochs]    RMSE:0.26461,   MAE: 0.23000,  MAPE: 20.10%\n",
      "[2100 Epochs]    RMSE:0.22029,   MAE: 0.18391,  MAPE: 15.90%\n",
      "[2200 Epochs]    RMSE:0.24153,   MAE: 0.20682,  MAPE: 18.04%\n",
      "[2300 Epochs]    RMSE:0.27591,   MAE: 0.24690,  MAPE: 21.76%\n",
      "[2400 Epochs]    RMSE:0.22251,   MAE: 0.18780,  MAPE: 16.34%\n",
      "[2500 Epochs]    RMSE:0.13413,   MAE: 0.11363,  MAPE: 11.80%\n",
      "[2600 Epochs]    RMSE:0.16899,   MAE: 0.14466,  MAPE: 14.47%\n",
      "[2700 Epochs]    RMSE:0.12523,   MAE: 0.10293,  MAPE: 10.36%\n",
      "[2800 Epochs]    RMSE:0.26019,   MAE: 0.24255,  MAPE: 24.16%\n",
      "[2900 Epochs]    RMSE:0.11391,   MAE: 0.08827,  MAPE: 8.43%\n",
      "[3000 Epochs]    RMSE:0.12953,   MAE: 0.09349,  MAPE: 8.35%\n",
      "[3100 Epochs]    RMSE:0.11274,   MAE: 0.09007,  MAPE: 9.15%\n",
      "[3200 Epochs]    RMSE:0.11820,   MAE: 0.08528,  MAPE: 7.72%\n",
      "[3300 Epochs]    RMSE:0.55130,   MAE: 0.53990,  MAPE: 49.55%\n",
      "[3400 Epochs]    RMSE:0.20841,   MAE: 0.18370,  MAPE: 18.90%\n",
      "[3500 Epochs]    RMSE:0.15805,   MAE: 0.13367,  MAPE: 13.79%\n",
      "[3600 Epochs]    RMSE:0.13063,   MAE: 0.09847,  MAPE: 8.82%\n",
      "[3700 Epochs]    RMSE:0.11690,   MAE: 0.08517,  MAPE: 7.91%\n",
      "[3800 Epochs]    RMSE:0.22941,   MAE: 0.20551,  MAPE: 18.45%\n",
      "[3900 Epochs]    RMSE:0.16788,   MAE: 0.14116,  MAPE: 14.90%\n",
      "[4000 Epochs]    RMSE:0.13812,   MAE: 0.11572,  MAPE: 12.09%\n",
      "[4100 Epochs]    RMSE:0.11389,   MAE: 0.09652,  MAPE: 9.67%\n",
      "[4200 Epochs]    RMSE:0.10745,   MAE: 0.08603,  MAPE: 8.65%\n",
      "[4300 Epochs]    RMSE:0.10393,   MAE: 0.07356,  MAPE: 6.95%\n",
      "[4400 Epochs]    RMSE:0.10066,   MAE: 0.07480,  MAPE: 7.28%\n",
      "[4500 Epochs]    RMSE:0.15496,   MAE: 0.12499,  MAPE: 11.02%\n",
      "[4600 Epochs]    RMSE:0.21725,   MAE: 0.19777,  MAPE: 20.02%\n",
      "[4700 Epochs]    RMSE:0.10621,   MAE: 0.08271,  MAPE: 8.28%\n",
      "[4800 Epochs]    RMSE:0.21273,   MAE: 0.18671,  MAPE: 19.45%\n",
      "[4900 Epochs]    RMSE:0.14272,   MAE: 0.11255,  MAPE: 9.88%\n",
      "\n",
      "[Final Epochs]    RMSE:0.10739,   MAE: 0.07872,  MAPE: 7.49%\n",
      "\n",
      "\n",
      "Trial No.3\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 30\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:106.67250,   MAE: 106.59550,  MAPE: 10075.81%\n",
      "[100 Epochs]    RMSE:2.28533,   MAE: 1.84253,  MAPE: 176.18%\n",
      "[200 Epochs]    RMSE:1.50836,   MAE: 1.22777,  MAPE: 112.71%\n",
      "[300 Epochs]    RMSE:0.99989,   MAE: 0.79379,  MAPE: 74.12%\n",
      "[400 Epochs]    RMSE:1.67459,   MAE: 1.34595,  MAPE: 128.83%\n",
      "[500 Epochs]    RMSE:1.16750,   MAE: 0.91352,  MAPE: 88.07%\n",
      "[600 Epochs]    RMSE:0.65237,   MAE: 0.52216,  MAPE: 50.14%\n",
      "[700 Epochs]    RMSE:1.78325,   MAE: 1.69683,  MAPE: 157.41%\n",
      "[800 Epochs]    RMSE:1.87679,   MAE: 1.80621,  MAPE: 166.65%\n",
      "[900 Epochs]    RMSE:1.89744,   MAE: 1.83648,  MAPE: 177.03%\n",
      "[1000 Epochs]    RMSE:0.68330,   MAE: 0.58520,  MAPE: 52.22%\n",
      "[1100 Epochs]    RMSE:1.09601,   MAE: 1.04133,  MAPE: 94.35%\n",
      "[1200 Epochs]    RMSE:1.31790,   MAE: 1.28070,  MAPE: 124.62%\n",
      "[1300 Epochs]    RMSE:0.22773,   MAE: 0.18926,  MAPE: 17.50%\n",
      "[1400 Epochs]    RMSE:0.18517,   MAE: 0.14572,  MAPE: 15.00%\n",
      "[1500 Epochs]    RMSE:0.57788,   MAE: 0.55813,  MAPE: 50.57%\n",
      "[1600 Epochs]    RMSE:0.53780,   MAE: 0.51240,  MAPE: 45.72%\n",
      "[1700 Epochs]    RMSE:0.47072,   MAE: 0.43861,  MAPE: 38.69%\n",
      "[1800 Epochs]    RMSE:0.41835,   MAE: 0.38212,  MAPE: 33.43%\n",
      "[1900 Epochs]    RMSE:0.38685,   MAE: 0.34907,  MAPE: 30.35%\n",
      "[2000 Epochs]    RMSE:0.39305,   MAE: 0.35880,  MAPE: 31.35%\n",
      "[2100 Epochs]    RMSE:0.34927,   MAE: 0.31356,  MAPE: 27.20%\n",
      "[2200 Epochs]    RMSE:0.34122,   MAE: 0.30779,  MAPE: 26.70%\n",
      "[2300 Epochs]    RMSE:0.27698,   MAE: 0.24255,  MAPE: 20.87%\n",
      "[2400 Epochs]    RMSE:0.30451,   MAE: 0.27463,  MAPE: 23.89%\n",
      "[2500 Epochs]    RMSE:0.12603,   MAE: 0.09611,  MAPE: 9.66%\n",
      "[2600 Epochs]    RMSE:0.17133,   MAE: 0.13906,  MAPE: 12.62%\n",
      "[2700 Epochs]    RMSE:0.11502,   MAE: 0.08478,  MAPE: 8.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2800 Epochs]    RMSE:0.26559,   MAE: 0.24173,  MAPE: 21.69%\n",
      "[2900 Epochs]    RMSE:0.17710,   MAE: 0.14703,  MAPE: 13.27%\n",
      "[3000 Epochs]    RMSE:0.14369,   MAE: 0.11880,  MAPE: 12.32%\n",
      "[3100 Epochs]    RMSE:0.11252,   MAE: 0.08150,  MAPE: 8.10%\n",
      "[3200 Epochs]    RMSE:0.19839,   MAE: 0.16981,  MAPE: 17.63%\n",
      "[3300 Epochs]    RMSE:0.15344,   MAE: 0.12737,  MAPE: 13.43%\n",
      "[3400 Epochs]    RMSE:0.14651,   MAE: 0.12287,  MAPE: 12.86%\n",
      "[3500 Epochs]    RMSE:0.15559,   MAE: 0.12978,  MAPE: 13.57%\n",
      "[3600 Epochs]    RMSE:0.11310,   MAE: 0.08167,  MAPE: 8.40%\n",
      "[3700 Epochs]    RMSE:0.11225,   MAE: 0.08040,  MAPE: 8.28%\n",
      "[3800 Epochs]    RMSE:0.10885,   MAE: 0.07831,  MAPE: 8.03%\n",
      "[3900 Epochs]    RMSE:0.21805,   MAE: 0.19184,  MAPE: 19.76%\n",
      "[4000 Epochs]    RMSE:0.10924,   MAE: 0.07543,  MAPE: 7.53%\n",
      "[4100 Epochs]    RMSE:0.11430,   MAE: 0.08019,  MAPE: 7.70%\n",
      "[4200 Epochs]    RMSE:0.10907,   MAE: 0.07453,  MAPE: 7.44%\n",
      "[4300 Epochs]    RMSE:0.14304,   MAE: 0.11043,  MAPE: 10.02%\n",
      "[4400 Epochs]    RMSE:0.14423,   MAE: 0.12355,  MAPE: 12.58%\n",
      "[4500 Epochs]    RMSE:0.10492,   MAE: 0.07354,  MAPE: 7.44%\n",
      "[4600 Epochs]    RMSE:0.12117,   MAE: 0.09614,  MAPE: 9.94%\n",
      "[4700 Epochs]    RMSE:0.10748,   MAE: 0.07459,  MAPE: 7.37%\n",
      "[4800 Epochs]    RMSE:0.13278,   MAE: 0.09920,  MAPE: 9.12%\n",
      "[4900 Epochs]    RMSE:0.10823,   MAE: 0.07658,  MAPE: 7.43%\n",
      "\n",
      "[Final Epochs]    RMSE:0.10408,   MAE: 0.07412,  MAPE: 7.59%\n",
      "\n",
      "\n",
      "Trial No.4\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 40\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:148.58535,   MAE: 148.47647,  MAPE: 14069.05%\n",
      "[100 Epochs]    RMSE:4.02154,   MAE: 3.17160,  MAPE: 307.87%\n",
      "[200 Epochs]    RMSE:3.07717,   MAE: 2.42126,  MAPE: 231.10%\n",
      "[300 Epochs]    RMSE:2.68135,   MAE: 2.15045,  MAPE: 207.88%\n",
      "[400 Epochs]    RMSE:2.07843,   MAE: 1.63579,  MAPE: 154.39%\n",
      "[500 Epochs]    RMSE:1.70480,   MAE: 1.35656,  MAPE: 127.90%\n",
      "[600 Epochs]    RMSE:1.14387,   MAE: 0.91321,  MAPE: 86.50%\n",
      "[700 Epochs]    RMSE:1.36808,   MAE: 1.12609,  MAPE: 106.04%\n",
      "[800 Epochs]    RMSE:1.31198,   MAE: 1.12122,  MAPE: 105.58%\n",
      "[900 Epochs]    RMSE:1.14167,   MAE: 0.97844,  MAPE: 92.15%\n",
      "[1000 Epochs]    RMSE:1.75341,   MAE: 1.63445,  MAPE: 154.88%\n",
      "[1100 Epochs]    RMSE:1.50590,   MAE: 1.30955,  MAPE: 125.01%\n",
      "[1200 Epochs]    RMSE:1.31309,   MAE: 1.12226,  MAPE: 104.90%\n",
      "[1300 Epochs]    RMSE:1.16922,   MAE: 0.98521,  MAPE: 91.00%\n",
      "[1400 Epochs]    RMSE:1.07272,   MAE: 0.90333,  MAPE: 83.43%\n",
      "[1500 Epochs]    RMSE:1.06324,   MAE: 0.90680,  MAPE: 83.91%\n",
      "[1600 Epochs]    RMSE:0.87382,   MAE: 0.73077,  MAPE: 67.30%\n",
      "[1700 Epochs]    RMSE:0.59477,   MAE: 0.50172,  MAPE: 46.49%\n",
      "[1800 Epochs]    RMSE:0.93024,   MAE: 0.80603,  MAPE: 74.63%\n",
      "[1900 Epochs]    RMSE:0.75738,   MAE: 0.64089,  MAPE: 59.70%\n",
      "[2000 Epochs]    RMSE:0.35756,   MAE: 0.29151,  MAPE: 28.25%\n",
      "[2100 Epochs]    RMSE:0.69259,   MAE: 0.65045,  MAPE: 61.38%\n",
      "[2200 Epochs]    RMSE:0.98436,   MAE: 0.92690,  MAPE: 89.17%\n",
      "[2300 Epochs]    RMSE:0.71719,   MAE: 0.63269,  MAPE: 60.90%\n",
      "[2400 Epochs]    RMSE:0.51830,   MAE: 0.43129,  MAPE: 41.15%\n",
      "[2500 Epochs]    RMSE:0.59258,   MAE: 0.50355,  MAPE: 48.20%\n",
      "[2600 Epochs]    RMSE:0.49988,   MAE: 0.41961,  MAPE: 40.21%\n",
      "[2700 Epochs]    RMSE:0.45980,   MAE: 0.39067,  MAPE: 37.55%\n",
      "[2800 Epochs]    RMSE:0.55362,   MAE: 0.49213,  MAPE: 47.42%\n",
      "[2900 Epochs]    RMSE:0.48614,   MAE: 0.42627,  MAPE: 41.17%\n",
      "[3000 Epochs]    RMSE:0.35641,   MAE: 0.30120,  MAPE: 29.08%\n",
      "[3100 Epochs]    RMSE:0.46732,   MAE: 0.41226,  MAPE: 39.40%\n",
      "[3200 Epochs]    RMSE:0.35929,   MAE: 0.30086,  MAPE: 29.24%\n",
      "[3300 Epochs]    RMSE:0.41219,   MAE: 0.36668,  MAPE: 35.42%\n",
      "[3400 Epochs]    RMSE:0.27398,   MAE: 0.23046,  MAPE: 22.19%\n",
      "[3500 Epochs]    RMSE:0.30963,   MAE: 0.26476,  MAPE: 24.00%\n",
      "[3600 Epochs]    RMSE:0.13865,   MAE: 0.11007,  MAPE: 10.15%\n",
      "[3700 Epochs]    RMSE:0.33026,   MAE: 0.29586,  MAPE: 29.14%\n",
      "[3800 Epochs]    RMSE:0.36852,   MAE: 0.34030,  MAPE: 32.98%\n",
      "[3900 Epochs]    RMSE:0.23047,   MAE: 0.19552,  MAPE: 19.21%\n",
      "[4000 Epochs]    RMSE:0.19559,   MAE: 0.17166,  MAPE: 15.72%\n",
      "[4100 Epochs]    RMSE:0.27537,   MAE: 0.24927,  MAPE: 24.39%\n",
      "[4200 Epochs]    RMSE:0.25828,   MAE: 0.23261,  MAPE: 22.84%\n",
      "[4300 Epochs]    RMSE:0.18081,   MAE: 0.15637,  MAPE: 15.66%\n",
      "[4400 Epochs]    RMSE:0.22331,   MAE: 0.20323,  MAPE: 19.99%\n",
      "[4500 Epochs]    RMSE:0.23288,   MAE: 0.21587,  MAPE: 21.15%\n",
      "[4600 Epochs]    RMSE:0.11304,   MAE: 0.09791,  MAPE: 9.79%\n",
      "[4700 Epochs]    RMSE:0.16943,   MAE: 0.15641,  MAPE: 15.62%\n",
      "[4800 Epochs]    RMSE:0.13448,   MAE: 0.11801,  MAPE: 11.68%\n",
      "[4900 Epochs]    RMSE:0.06896,   MAE: 0.04837,  MAPE: 4.78%\n",
      "\n",
      "[Final Epochs]    RMSE:0.08614,   MAE: 0.06538,  MAPE: 6.16%\n",
      "\n",
      "\n",
      "Trial No.5\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 40\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:83.28685,   MAE: 83.13096,  MAPE: 7763.43%\n",
      "[100 Epochs]    RMSE:3.44047,   MAE: 2.76463,  MAPE: 265.30%\n",
      "[200 Epochs]    RMSE:1.67137,   MAE: 1.30706,  MAPE: 125.19%\n",
      "[300 Epochs]    RMSE:12.56017,   MAE: 12.49537,  MAPE: 1171.56%\n",
      "[400 Epochs]    RMSE:7.05919,   MAE: 6.95048,  MAPE: 647.51%\n",
      "[500 Epochs]    RMSE:3.46025,   MAE: 3.25245,  MAPE: 314.66%\n",
      "[600 Epochs]    RMSE:3.44884,   MAE: 3.25151,  MAPE: 314.76%\n",
      "[700 Epochs]    RMSE:4.65011,   MAE: 4.51563,  MAPE: 417.70%\n",
      "[800 Epochs]    RMSE:2.12577,   MAE: 1.91235,  MAPE: 187.08%\n",
      "[900 Epochs]    RMSE:2.85356,   MAE: 2.68520,  MAPE: 259.68%\n",
      "[1000 Epochs]    RMSE:3.52369,   MAE: 3.40209,  MAPE: 314.73%\n",
      "[1100 Epochs]    RMSE:1.67924,   MAE: 1.50390,  MAPE: 146.64%\n",
      "[1200 Epochs]    RMSE:2.06975,   MAE: 1.91851,  MAPE: 185.63%\n",
      "[1300 Epochs]    RMSE:2.65039,   MAE: 2.52592,  MAPE: 233.17%\n",
      "[1400 Epochs]    RMSE:1.30765,   MAE: 1.13612,  MAPE: 113.43%\n",
      "[1500 Epochs]    RMSE:1.67435,   MAE: 1.53875,  MAPE: 150.66%\n",
      "[1600 Epochs]    RMSE:2.08228,   MAE: 1.98494,  MAPE: 182.32%\n",
      "[1700 Epochs]    RMSE:0.95038,   MAE: 0.79714,  MAPE: 79.28%\n",
      "[1800 Epochs]    RMSE:1.41771,   MAE: 1.29773,  MAPE: 126.41%\n",
      "[1900 Epochs]    RMSE:1.84301,   MAE: 1.76112,  MAPE: 162.08%\n",
      "[2000 Epochs]    RMSE:0.94242,   MAE: 0.81798,  MAPE: 80.41%\n",
      "[2100 Epochs]    RMSE:1.16051,   MAE: 1.06257,  MAPE: 103.29%\n",
      "[2200 Epochs]    RMSE:1.65801,   MAE: 1.59504,  MAPE: 147.17%\n",
      "[2300 Epochs]    RMSE:0.75593,   MAE: 0.65100,  MAPE: 64.12%\n",
      "[2400 Epochs]    RMSE:1.02682,   MAE: 0.94378,  MAPE: 91.64%\n",
      "[2500 Epochs]    RMSE:1.33281,   MAE: 1.27681,  MAPE: 117.76%\n",
      "[2600 Epochs]    RMSE:0.47584,   MAE: 0.38359,  MAPE: 38.32%\n",
      "[2700 Epochs]    RMSE:0.23066,   MAE: 0.18346,  MAPE: 18.15%\n",
      "[2800 Epochs]    RMSE:0.29976,   MAE: 0.26620,  MAPE: 26.16%\n",
      "[2900 Epochs]    RMSE:0.62184,   MAE: 0.60130,  MAPE: 57.75%\n",
      "[3000 Epochs]    RMSE:0.24812,   MAE: 0.21053,  MAPE: 20.65%\n",
      "[3100 Epochs]    RMSE:0.47279,   MAE: 0.42585,  MAPE: 42.15%\n",
      "[3200 Epochs]    RMSE:0.62325,   MAE: 0.59246,  MAPE: 56.73%\n",
      "[3300 Epochs]    RMSE:0.60225,   MAE: 0.56905,  MAPE: 54.44%\n",
      "[3400 Epochs]    RMSE:0.51616,   MAE: 0.48240,  MAPE: 46.80%\n",
      "[3500 Epochs]    RMSE:0.20729,   MAE: 0.16114,  MAPE: 14.79%\n",
      "[3600 Epochs]    RMSE:0.69678,   MAE: 0.67550,  MAPE: 62.10%\n",
      "[3700 Epochs]    RMSE:0.49697,   MAE: 0.47311,  MAPE: 43.41%\n",
      "[3800 Epochs]    RMSE:0.30531,   MAE: 0.27706,  MAPE: 27.61%\n",
      "[3900 Epochs]    RMSE:0.79115,   MAE: 0.77471,  MAPE: 71.42%\n",
      "[4000 Epochs]    RMSE:0.39982,   MAE: 0.36287,  MAPE: 33.06%\n",
      "[4100 Epochs]    RMSE:0.26747,   MAE: 0.22080,  MAPE: 20.22%\n",
      "[4200 Epochs]    RMSE:0.15948,   MAE: 0.12078,  MAPE: 11.54%\n",
      "[4300 Epochs]    RMSE:0.20756,   MAE: 0.17050,  MAPE: 15.33%\n",
      "[4400 Epochs]    RMSE:0.22097,   MAE: 0.18605,  MAPE: 16.64%\n",
      "[4500 Epochs]    RMSE:0.26809,   MAE: 0.24271,  MAPE: 21.63%\n",
      "[4600 Epochs]    RMSE:0.13021,   MAE: 0.10224,  MAPE: 10.34%\n",
      "[4700 Epochs]    RMSE:0.15624,   MAE: 0.11735,  MAPE: 10.71%\n",
      "[4800 Epochs]    RMSE:0.72564,   MAE: 0.71528,  MAPE: 66.15%\n",
      "[4900 Epochs]    RMSE:0.29379,   MAE: 0.26844,  MAPE: 26.78%\n",
      "\n",
      "[Final Epochs]    RMSE:0.17450,   MAE: 0.15091,  MAPE: 15.27%\n",
      "\n",
      "\n",
      "Trial No.6\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 40\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:18.94240,   MAE: 18.72754,  MAPE: 1722.51%\n",
      "[100 Epochs]    RMSE:1.74694,   MAE: 1.39779,  MAPE: 137.58%\n",
      "[200 Epochs]    RMSE:1.24556,   MAE: 0.99347,  MAPE: 92.48%\n",
      "[300 Epochs]    RMSE:1.67355,   MAE: 1.40724,  MAPE: 132.84%\n",
      "[400 Epochs]    RMSE:2.04563,   MAE: 1.82514,  MAPE: 171.20%\n",
      "[500 Epochs]    RMSE:1.77030,   MAE: 1.55237,  MAPE: 146.53%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600 Epochs]    RMSE:1.28440,   MAE: 1.05534,  MAPE: 98.99%\n",
      "[700 Epochs]    RMSE:1.39122,   MAE: 1.19427,  MAPE: 111.84%\n",
      "[800 Epochs]    RMSE:1.29223,   MAE: 1.11230,  MAPE: 103.65%\n",
      "[900 Epochs]    RMSE:0.79960,   MAE: 0.62878,  MAPE: 58.24%\n",
      "[1000 Epochs]    RMSE:0.51218,   MAE: 0.40040,  MAPE: 36.33%\n",
      "[1100 Epochs]    RMSE:0.59629,   MAE: 0.50980,  MAPE: 48.84%\n",
      "[1200 Epochs]    RMSE:1.32445,   MAE: 1.25076,  MAPE: 116.96%\n",
      "[1300 Epochs]    RMSE:0.88407,   MAE: 0.78276,  MAPE: 72.41%\n",
      "[1400 Epochs]    RMSE:0.82868,   MAE: 0.73478,  MAPE: 68.64%\n",
      "[1500 Epochs]    RMSE:0.70174,   MAE: 0.62055,  MAPE: 57.88%\n",
      "[1600 Epochs]    RMSE:0.67744,   MAE: 0.59685,  MAPE: 54.99%\n",
      "[1700 Epochs]    RMSE:0.41045,   MAE: 0.35187,  MAPE: 33.27%\n",
      "[1800 Epochs]    RMSE:0.64186,   MAE: 0.57592,  MAPE: 54.48%\n",
      "[1900 Epochs]    RMSE:0.27972,   MAE: 0.23781,  MAPE: 23.03%\n",
      "[2000 Epochs]    RMSE:0.65147,   MAE: 0.59888,  MAPE: 55.86%\n",
      "[2100 Epochs]    RMSE:0.26130,   MAE: 0.21727,  MAPE: 21.33%\n",
      "[2200 Epochs]    RMSE:0.66850,   MAE: 0.62726,  MAPE: 59.10%\n",
      "[2300 Epochs]    RMSE:0.36446,   MAE: 0.30288,  MAPE: 28.78%\n",
      "[2400 Epochs]    RMSE:0.52521,   MAE: 0.48415,  MAPE: 45.96%\n",
      "[2500 Epochs]    RMSE:0.19362,   MAE: 0.15303,  MAPE: 14.61%\n",
      "[2600 Epochs]    RMSE:0.24788,   MAE: 0.21398,  MAPE: 19.69%\n",
      "[2700 Epochs]    RMSE:0.64477,   MAE: 0.56959,  MAPE: 49.31%\n",
      "[2800 Epochs]    RMSE:0.48516,   MAE: 0.42956,  MAPE: 38.87%\n",
      "[2900 Epochs]    RMSE:0.37998,   MAE: 0.32258,  MAPE: 28.98%\n",
      "[3000 Epochs]    RMSE:0.35066,   MAE: 0.28674,  MAPE: 25.33%\n",
      "[3100 Epochs]    RMSE:0.23368,   MAE: 0.17506,  MAPE: 15.66%\n",
      "[3200 Epochs]    RMSE:0.22225,   MAE: 0.17035,  MAPE: 15.35%\n",
      "[3300 Epochs]    RMSE:0.19748,   MAE: 0.14737,  MAPE: 13.20%\n",
      "[3400 Epochs]    RMSE:0.16944,   MAE: 0.14564,  MAPE: 14.36%\n",
      "[3500 Epochs]    RMSE:0.22714,   MAE: 0.20004,  MAPE: 17.89%\n",
      "[3600 Epochs]    RMSE:0.11396,   MAE: 0.08472,  MAPE: 7.78%\n",
      "[3700 Epochs]    RMSE:0.11348,   MAE: 0.08399,  MAPE: 7.65%\n",
      "[3800 Epochs]    RMSE:0.10049,   MAE: 0.07302,  MAPE: 6.79%\n",
      "[3900 Epochs]    RMSE:0.13654,   MAE: 0.10870,  MAPE: 9.85%\n",
      "[4000 Epochs]    RMSE:0.12906,   MAE: 0.09779,  MAPE: 8.73%\n",
      "[4100 Epochs]    RMSE:0.12534,   MAE: 0.09479,  MAPE: 8.66%\n",
      "[4200 Epochs]    RMSE:0.10955,   MAE: 0.07989,  MAPE: 7.29%\n",
      "[4300 Epochs]    RMSE:0.14900,   MAE: 0.13235,  MAPE: 12.89%\n",
      "[4400 Epochs]    RMSE:0.09676,   MAE: 0.07282,  MAPE: 7.06%\n",
      "[4500 Epochs]    RMSE:0.14352,   MAE: 0.11358,  MAPE: 10.17%\n",
      "[4600 Epochs]    RMSE:0.09294,   MAE: 0.06812,  MAPE: 6.52%\n",
      "[4700 Epochs]    RMSE:0.21980,   MAE: 0.19449,  MAPE: 17.75%\n",
      "[4800 Epochs]    RMSE:0.12513,   MAE: 0.10265,  MAPE: 9.21%\n",
      "[4900 Epochs]    RMSE:0.08657,   MAE: 0.06653,  MAPE: 6.58%\n",
      "\n",
      "[Final Epochs]    RMSE:0.08022,   MAE: 0.06212,  MAPE: 5.99%\n",
      "\n",
      "\n",
      "Trial No.7\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 50\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:69.62235,   MAE: 69.48357,  MAPE: 6601.42%\n",
      "[100 Epochs]    RMSE:2.88731,   MAE: 2.40616,  MAPE: 229.02%\n",
      "[200 Epochs]    RMSE:1.62064,   MAE: 1.35453,  MAPE: 131.74%\n",
      "[300 Epochs]    RMSE:1.16223,   MAE: 0.93656,  MAPE: 91.44%\n",
      "[400 Epochs]    RMSE:2.38175,   MAE: 2.29995,  MAPE: 218.90%\n",
      "[500 Epochs]    RMSE:1.41277,   MAE: 1.28160,  MAPE: 123.97%\n",
      "[600 Epochs]    RMSE:1.36873,   MAE: 1.25009,  MAPE: 121.55%\n",
      "[700 Epochs]    RMSE:1.17947,   MAE: 1.06613,  MAPE: 103.85%\n",
      "[800 Epochs]    RMSE:1.13604,   MAE: 1.03818,  MAPE: 100.69%\n",
      "[900 Epochs]    RMSE:0.91482,   MAE: 0.81513,  MAPE: 79.23%\n",
      "[1000 Epochs]    RMSE:0.95769,   MAE: 0.87411,  MAPE: 84.38%\n",
      "[1100 Epochs]    RMSE:0.76886,   MAE: 0.68035,  MAPE: 65.74%\n",
      "[1200 Epochs]    RMSE:0.87234,   MAE: 0.80417,  MAPE: 76.94%\n",
      "[1300 Epochs]    RMSE:0.70117,   MAE: 0.62594,  MAPE: 59.77%\n",
      "[1400 Epochs]    RMSE:0.68701,   MAE: 0.61704,  MAPE: 58.66%\n",
      "[1500 Epochs]    RMSE:0.67472,   MAE: 0.61011,  MAPE: 57.71%\n",
      "[1600 Epochs]    RMSE:0.57528,   MAE: 0.50645,  MAPE: 47.74%\n",
      "[1700 Epochs]    RMSE:0.65528,   MAE: 0.60181,  MAPE: 56.34%\n",
      "[1800 Epochs]    RMSE:0.54073,   MAE: 0.47938,  MAPE: 44.61%\n",
      "[1900 Epochs]    RMSE:0.61701,   MAE: 0.56849,  MAPE: 52.80%\n",
      "[2000 Epochs]    RMSE:0.48003,   MAE: 0.42077,  MAPE: 38.70%\n",
      "[2100 Epochs]    RMSE:0.59053,   MAE: 0.54573,  MAPE: 50.39%\n",
      "[2200 Epochs]    RMSE:0.58695,   MAE: 0.54368,  MAPE: 49.76%\n",
      "[2300 Epochs]    RMSE:0.41288,   MAE: 0.35352,  MAPE: 31.77%\n",
      "[2400 Epochs]    RMSE:0.45628,   MAE: 0.40945,  MAPE: 37.11%\n",
      "[2500 Epochs]    RMSE:0.81494,   MAE: 0.79950,  MAPE: 76.74%\n",
      "[2600 Epochs]    RMSE:0.29944,   MAE: 0.26781,  MAPE: 26.32%\n",
      "[2700 Epochs]    RMSE:0.68353,   MAE: 0.65920,  MAPE: 60.41%\n",
      "[2800 Epochs]    RMSE:0.28296,   MAE: 0.23636,  MAPE: 22.15%\n",
      "[2900 Epochs]    RMSE:0.44708,   MAE: 0.42213,  MAPE: 38.69%\n",
      "[3000 Epochs]    RMSE:0.14361,   MAE: 0.11688,  MAPE: 11.04%\n",
      "[3100 Epochs]    RMSE:0.41103,   MAE: 0.38742,  MAPE: 34.73%\n",
      "[3200 Epochs]    RMSE:0.59914,   MAE: 0.58124,  MAPE: 56.86%\n",
      "[3300 Epochs]    RMSE:0.13064,   MAE: 0.10371,  MAPE: 10.17%\n",
      "[3400 Epochs]    RMSE:0.48880,   MAE: 0.47141,  MAPE: 46.21%\n",
      "[3500 Epochs]    RMSE:0.32489,   MAE: 0.30013,  MAPE: 26.83%\n",
      "[3600 Epochs]    RMSE:0.26335,   MAE: 0.23260,  MAPE: 20.47%\n",
      "[3700 Epochs]    RMSE:0.19377,   MAE: 0.15696,  MAPE: 13.96%\n",
      "[3800 Epochs]    RMSE:0.21621,   MAE: 0.18248,  MAPE: 16.04%\n",
      "[3900 Epochs]    RMSE:0.32075,   MAE: 0.30077,  MAPE: 29.50%\n",
      "[4000 Epochs]    RMSE:0.35676,   MAE: 0.33557,  MAPE: 33.39%\n",
      "[4100 Epochs]    RMSE:0.28654,   MAE: 0.25928,  MAPE: 25.99%\n",
      "[4200 Epochs]    RMSE:0.26090,   MAE: 0.23106,  MAPE: 23.38%\n",
      "[4300 Epochs]    RMSE:0.27999,   MAE: 0.25636,  MAPE: 25.74%\n",
      "[4400 Epochs]    RMSE:0.30311,   MAE: 0.27940,  MAPE: 28.12%\n",
      "[4500 Epochs]    RMSE:0.12341,   MAE: 0.10082,  MAPE: 9.89%\n",
      "[4600 Epochs]    RMSE:0.10366,   MAE: 0.08179,  MAPE: 8.36%\n",
      "[4700 Epochs]    RMSE:0.23891,   MAE: 0.21503,  MAPE: 21.69%\n",
      "[4800 Epochs]    RMSE:0.22109,   MAE: 0.19811,  MAPE: 20.10%\n",
      "[4900 Epochs]    RMSE:0.20447,   MAE: 0.17777,  MAPE: 18.39%\n",
      "\n",
      "[Final Epochs]    RMSE:0.24803,   MAE: 0.22656,  MAPE: 23.02%\n",
      "\n",
      "\n",
      "Trial No.8\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 50\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:6.61599,   MAE: 6.52460,  MAPE: 596.81%\n",
      "[100 Epochs]    RMSE:0.54743,   MAE: 0.44569,  MAPE: 44.17%\n",
      "[200 Epochs]    RMSE:0.43595,   MAE: 0.36048,  MAPE: 32.81%\n",
      "[300 Epochs]    RMSE:0.53949,   MAE: 0.48729,  MAPE: 44.06%\n",
      "[400 Epochs]    RMSE:0.40866,   MAE: 0.36414,  MAPE: 32.60%\n",
      "[500 Epochs]    RMSE:0.39576,   MAE: 0.35724,  MAPE: 31.59%\n",
      "[600 Epochs]    RMSE:0.33535,   MAE: 0.29796,  MAPE: 25.86%\n",
      "[700 Epochs]    RMSE:0.33050,   MAE: 0.29416,  MAPE: 25.28%\n",
      "[800 Epochs]    RMSE:0.53620,   MAE: 0.51771,  MAPE: 51.01%\n",
      "[900 Epochs]    RMSE:0.60337,   MAE: 0.56882,  MAPE: 49.91%\n",
      "[1000 Epochs]    RMSE:0.26977,   MAE: 0.19875,  MAPE: 22.22%\n",
      "[1100 Epochs]    RMSE:0.40206,   MAE: 0.38097,  MAPE: 37.18%\n",
      "[1200 Epochs]    RMSE:1.18776,   MAE: 1.17912,  MAPE: 108.94%\n",
      "[1300 Epochs]    RMSE:0.38927,   MAE: 0.34997,  MAPE: 30.05%\n",
      "[1400 Epochs]    RMSE:0.36544,   MAE: 0.32424,  MAPE: 28.00%\n",
      "[1500 Epochs]    RMSE:0.34545,   MAE: 0.30301,  MAPE: 26.15%\n",
      "[1600 Epochs]    RMSE:0.30239,   MAE: 0.25893,  MAPE: 22.39%\n",
      "[1700 Epochs]    RMSE:0.31250,   MAE: 0.26869,  MAPE: 23.06%\n",
      "[1800 Epochs]    RMSE:0.13724,   MAE: 0.10927,  MAPE: 10.32%\n",
      "[1900 Epochs]    RMSE:0.15737,   MAE: 0.13048,  MAPE: 13.07%\n",
      "[2000 Epochs]    RMSE:0.21709,   MAE: 0.18294,  MAPE: 16.07%\n",
      "[2100 Epochs]    RMSE:0.17891,   MAE: 0.14219,  MAPE: 12.53%\n",
      "[2200 Epochs]    RMSE:0.15429,   MAE: 0.13056,  MAPE: 13.25%\n",
      "[2300 Epochs]    RMSE:0.22054,   MAE: 0.18843,  MAPE: 16.66%\n",
      "[2400 Epochs]    RMSE:0.16237,   MAE: 0.14055,  MAPE: 14.04%\n",
      "[2500 Epochs]    RMSE:0.28740,   MAE: 0.26213,  MAPE: 23.00%\n",
      "[2600 Epochs]    RMSE:0.12608,   MAE: 0.10619,  MAPE: 10.55%\n",
      "[2700 Epochs]    RMSE:0.13621,   MAE: 0.11557,  MAPE: 11.66%\n",
      "[2800 Epochs]    RMSE:0.11418,   MAE: 0.08313,  MAPE: 7.46%\n",
      "[2900 Epochs]    RMSE:0.44476,   MAE: 0.43154,  MAPE: 42.13%\n",
      "[3000 Epochs]    RMSE:0.24271,   MAE: 0.21234,  MAPE: 21.26%\n",
      "[3100 Epochs]    RMSE:0.09837,   MAE: 0.07309,  MAPE: 6.88%\n",
      "[3200 Epochs]    RMSE:0.15674,   MAE: 0.12457,  MAPE: 10.94%\n",
      "[3300 Epochs]    RMSE:0.11086,   MAE: 0.07947,  MAPE: 7.27%\n",
      "[3400 Epochs]    RMSE:0.11163,   MAE: 0.09199,  MAPE: 9.21%\n",
      "[3500 Epochs]    RMSE:0.09485,   MAE: 0.07147,  MAPE: 6.88%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3600 Epochs]    RMSE:0.11467,   MAE: 0.09192,  MAPE: 9.02%\n",
      "[3700 Epochs]    RMSE:0.10797,   MAE: 0.08097,  MAPE: 7.68%\n",
      "[3800 Epochs]    RMSE:0.14011,   MAE: 0.11816,  MAPE: 11.91%\n",
      "[3900 Epochs]    RMSE:0.14673,   MAE: 0.12567,  MAPE: 12.68%\n",
      "[4000 Epochs]    RMSE:0.12372,   MAE: 0.10014,  MAPE: 10.23%\n",
      "[4100 Epochs]    RMSE:0.10756,   MAE: 0.07603,  MAPE: 7.16%\n",
      "[4200 Epochs]    RMSE:0.11056,   MAE: 0.08512,  MAPE: 8.43%\n",
      "[4300 Epochs]    RMSE:0.10903,   MAE: 0.07679,  MAPE: 7.16%\n",
      "[4400 Epochs]    RMSE:0.11448,   MAE: 0.09074,  MAPE: 9.10%\n",
      "[4500 Epochs]    RMSE:0.22920,   MAE: 0.21240,  MAPE: 21.11%\n",
      "[4600 Epochs]    RMSE:0.32607,   MAE: 0.31099,  MAPE: 30.60%\n",
      "[4700 Epochs]    RMSE:0.13258,   MAE: 0.09402,  MAPE: 8.32%\n",
      "[4800 Epochs]    RMSE:0.10940,   MAE: 0.07232,  MAPE: 6.64%\n",
      "[4900 Epochs]    RMSE:0.12959,   MAE: 0.10974,  MAPE: 10.83%\n",
      "\n",
      "[Final Epochs]    RMSE:0.22248,   MAE: 0.20510,  MAPE: 20.77%\n",
      "\n",
      "\n",
      "Trial No.9\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 50\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:143.17974,   MAE: 143.11906,  MAPE: 13451.99%\n",
      "[100 Epochs]    RMSE:2.32485,   MAE: 1.82562,  MAPE: 166.13%\n",
      "[200 Epochs]    RMSE:2.02567,   MAE: 1.73163,  MAPE: 166.35%\n",
      "[300 Epochs]    RMSE:2.48540,   MAE: 2.29568,  MAPE: 210.72%\n",
      "[400 Epochs]    RMSE:1.59525,   MAE: 1.40260,  MAPE: 127.94%\n",
      "[500 Epochs]    RMSE:4.65604,   MAE: 4.55685,  MAPE: 436.74%\n",
      "[600 Epochs]    RMSE:4.60250,   MAE: 4.51283,  MAPE: 416.52%\n",
      "[700 Epochs]    RMSE:2.38139,   MAE: 2.21194,  MAPE: 217.42%\n",
      "[800 Epochs]    RMSE:2.75749,   MAE: 2.62654,  MAPE: 256.34%\n",
      "[900 Epochs]    RMSE:2.77043,   MAE: 2.65521,  MAPE: 242.54%\n",
      "[1000 Epochs]    RMSE:1.29179,   MAE: 1.18311,  MAPE: 109.80%\n",
      "[1100 Epochs]    RMSE:1.25243,   MAE: 1.15324,  MAPE: 106.71%\n",
      "[1200 Epochs]    RMSE:0.83992,   MAE: 0.74230,  MAPE: 70.81%\n",
      "[1300 Epochs]    RMSE:1.12189,   MAE: 1.07577,  MAPE: 100.56%\n",
      "[1400 Epochs]    RMSE:0.97001,   MAE: 0.90089,  MAPE: 82.58%\n",
      "[1500 Epochs]    RMSE:0.83644,   MAE: 0.76282,  MAPE: 69.97%\n",
      "[1600 Epochs]    RMSE:0.72999,   MAE: 0.63835,  MAPE: 58.11%\n",
      "[1700 Epochs]    RMSE:0.87314,   MAE: 0.80431,  MAPE: 73.52%\n",
      "[1800 Epochs]    RMSE:0.88880,   MAE: 0.82832,  MAPE: 75.76%\n",
      "[1900 Epochs]    RMSE:0.90668,   MAE: 0.84561,  MAPE: 76.60%\n",
      "[2000 Epochs]    RMSE:0.72643,   MAE: 0.65823,  MAPE: 59.37%\n",
      "[2100 Epochs]    RMSE:0.61676,   MAE: 0.55063,  MAPE: 49.97%\n",
      "[2200 Epochs]    RMSE:0.65110,   MAE: 0.59339,  MAPE: 54.29%\n",
      "[2300 Epochs]    RMSE:0.62441,   MAE: 0.56839,  MAPE: 51.53%\n",
      "[2400 Epochs]    RMSE:0.61649,   MAE: 0.56217,  MAPE: 49.90%\n",
      "[2500 Epochs]    RMSE:0.56289,   MAE: 0.51432,  MAPE: 48.22%\n",
      "[2600 Epochs]    RMSE:0.79064,   MAE: 0.76607,  MAPE: 70.34%\n",
      "[2700 Epochs]    RMSE:0.38555,   MAE: 0.33354,  MAPE: 32.98%\n",
      "[2800 Epochs]    RMSE:0.27392,   MAE: 0.24388,  MAPE: 22.31%\n",
      "[2900 Epochs]    RMSE:0.55087,   MAE: 0.52218,  MAPE: 50.61%\n",
      "[3000 Epochs]    RMSE:0.27187,   MAE: 0.23559,  MAPE: 21.30%\n",
      "[3100 Epochs]    RMSE:0.18068,   MAE: 0.15069,  MAPE: 13.51%\n",
      "[3200 Epochs]    RMSE:0.45549,   MAE: 0.43040,  MAPE: 40.17%\n",
      "[3300 Epochs]    RMSE:0.27486,   MAE: 0.24434,  MAPE: 22.29%\n",
      "[3400 Epochs]    RMSE:0.13230,   MAE: 0.09848,  MAPE: 8.92%\n",
      "[3500 Epochs]    RMSE:0.33626,   MAE: 0.31092,  MAPE: 30.99%\n",
      "[3600 Epochs]    RMSE:0.30351,   MAE: 0.27631,  MAPE: 27.78%\n",
      "[3700 Epochs]    RMSE:0.24796,   MAE: 0.21739,  MAPE: 22.36%\n",
      "[3800 Epochs]    RMSE:0.11532,   MAE: 0.09456,  MAPE: 9.60%\n",
      "[3900 Epochs]    RMSE:0.44167,   MAE: 0.41715,  MAPE: 41.81%\n",
      "[4000 Epochs]    RMSE:0.17875,   MAE: 0.15714,  MAPE: 16.05%\n",
      "[4100 Epochs]    RMSE:0.09753,   MAE: 0.06626,  MAPE: 5.92%\n",
      "[4200 Epochs]    RMSE:0.10302,   MAE: 0.07036,  MAPE: 6.22%\n",
      "[4300 Epochs]    RMSE:0.10219,   MAE: 0.07467,  MAPE: 6.76%\n",
      "[4400 Epochs]    RMSE:0.15473,   MAE: 0.14223,  MAPE: 14.04%\n",
      "[4500 Epochs]    RMSE:0.19469,   MAE: 0.17164,  MAPE: 15.07%\n",
      "[4600 Epochs]    RMSE:0.08843,   MAE: 0.06025,  MAPE: 5.60%\n",
      "[4700 Epochs]    RMSE:0.18600,   MAE: 0.16477,  MAPE: 16.89%\n",
      "[4800 Epochs]    RMSE:0.10863,   MAE: 0.07863,  MAPE: 7.03%\n",
      "[4900 Epochs]    RMSE:0.10947,   MAE: 0.08759,  MAPE: 7.79%\n",
      "\n",
      "[Final Epochs]    RMSE:0.29548,   MAE: 0.28063,  MAPE: 27.70%\n",
      "\n",
      "\n",
      "Trial No.10\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:118.91472,   MAE: 118.86221,  MAPE: 11263.03%\n",
      "[100 Epochs]    RMSE:2.97371,   MAE: 2.50711,  MAPE: 256.65%\n",
      "[200 Epochs]    RMSE:4.71835,   MAE: 4.51979,  MAPE: 440.00%\n",
      "[300 Epochs]    RMSE:4.65502,   MAE: 4.46271,  MAPE: 434.94%\n",
      "[400 Epochs]    RMSE:6.10346,   MAE: 5.94684,  MAPE: 545.70%\n",
      "[500 Epochs]    RMSE:2.82718,   MAE: 2.53996,  MAPE: 254.24%\n",
      "[600 Epochs]    RMSE:3.43341,   MAE: 3.22074,  MAPE: 318.24%\n",
      "[700 Epochs]    RMSE:4.46607,   MAE: 4.30266,  MAPE: 391.04%\n",
      "[800 Epochs]    RMSE:1.71713,   MAE: 1.45604,  MAPE: 147.65%\n",
      "[900 Epochs]    RMSE:0.66404,   MAE: 0.54360,  MAPE: 48.23%\n",
      "[1000 Epochs]    RMSE:4.22047,   MAE: 4.17639,  MAPE: 390.40%\n",
      "[1100 Epochs]    RMSE:1.68175,   MAE: 1.56808,  MAPE: 143.63%\n",
      "[1200 Epochs]    RMSE:1.56321,   MAE: 1.45348,  MAPE: 132.66%\n",
      "[1300 Epochs]    RMSE:0.79691,   MAE: 0.73277,  MAPE: 69.62%\n",
      "[1400 Epochs]    RMSE:1.35031,   MAE: 1.27793,  MAPE: 124.64%\n",
      "[1500 Epochs]    RMSE:1.24778,   MAE: 1.16510,  MAPE: 114.46%\n",
      "[1600 Epochs]    RMSE:1.25933,   MAE: 1.17427,  MAPE: 115.75%\n",
      "[1700 Epochs]    RMSE:2.24544,   MAE: 2.21480,  MAPE: 205.39%\n",
      "[1800 Epochs]    RMSE:2.63029,   MAE: 2.60167,  MAPE: 249.70%\n",
      "[1900 Epochs]    RMSE:1.14392,   MAE: 1.05511,  MAPE: 94.45%\n",
      "[2000 Epochs]    RMSE:0.60019,   MAE: 0.50849,  MAPE: 49.38%\n",
      "[2100 Epochs]    RMSE:1.31519,   MAE: 1.28041,  MAPE: 123.66%\n",
      "[2200 Epochs]    RMSE:1.00645,   MAE: 0.95903,  MAPE: 90.86%\n",
      "[2300 Epochs]    RMSE:0.91602,   MAE: 0.86565,  MAPE: 81.36%\n",
      "[2400 Epochs]    RMSE:0.81971,   MAE: 0.76426,  MAPE: 71.16%\n",
      "[2500 Epochs]    RMSE:0.72679,   MAE: 0.66306,  MAPE: 61.10%\n",
      "[2600 Epochs]    RMSE:1.32388,   MAE: 1.30087,  MAPE: 122.30%\n",
      "[2700 Epochs]    RMSE:1.79514,   MAE: 1.78168,  MAPE: 168.20%\n",
      "[2800 Epochs]    RMSE:0.70921,   MAE: 0.66949,  MAPE: 63.76%\n",
      "[2900 Epochs]    RMSE:0.29818,   MAE: 0.24701,  MAPE: 23.14%\n",
      "[3000 Epochs]    RMSE:0.75406,   MAE: 0.74166,  MAPE: 68.62%\n",
      "[3100 Epochs]    RMSE:1.87488,   MAE: 1.77401,  MAPE: 170.25%\n",
      "[3200 Epochs]    RMSE:0.34312,   MAE: 0.27322,  MAPE: 25.86%\n",
      "[3300 Epochs]    RMSE:1.48383,   MAE: 1.46532,  MAPE: 138.26%\n",
      "[3400 Epochs]    RMSE:0.27143,   MAE: 0.22505,  MAPE: 20.17%\n",
      "[3500 Epochs]    RMSE:0.67723,   MAE: 0.65165,  MAPE: 61.75%\n",
      "[3600 Epochs]    RMSE:0.19520,   MAE: 0.16247,  MAPE: 15.82%\n",
      "[3700 Epochs]    RMSE:0.18107,   MAE: 0.14814,  MAPE: 13.38%\n",
      "[3800 Epochs]    RMSE:0.19627,   MAE: 0.16669,  MAPE: 16.57%\n",
      "[3900 Epochs]    RMSE:0.15439,   MAE: 0.12891,  MAPE: 12.96%\n",
      "[4000 Epochs]    RMSE:0.35331,   MAE: 0.33210,  MAPE: 30.30%\n",
      "[4100 Epochs]    RMSE:0.32596,   MAE: 0.29617,  MAPE: 27.35%\n",
      "[4200 Epochs]    RMSE:0.35543,   MAE: 0.33092,  MAPE: 30.20%\n",
      "[4300 Epochs]    RMSE:0.29634,   MAE: 0.26668,  MAPE: 24.01%\n",
      "[4400 Epochs]    RMSE:0.11298,   MAE: 0.08848,  MAPE: 8.70%\n",
      "[4500 Epochs]    RMSE:0.68566,   MAE: 0.67221,  MAPE: 64.12%\n",
      "[4600 Epochs]    RMSE:0.28750,   MAE: 0.25185,  MAPE: 23.05%\n",
      "[4700 Epochs]    RMSE:0.12280,   MAE: 0.09850,  MAPE: 9.14%\n",
      "[4800 Epochs]    RMSE:0.10721,   MAE: 0.07957,  MAPE: 7.83%\n",
      "[4900 Epochs]    RMSE:0.26393,   MAE: 0.24766,  MAPE: 24.43%\n",
      "\n",
      "[Final Epochs]    RMSE:0.19296,   MAE: 0.16275,  MAPE: 14.27%\n",
      "\n",
      "\n",
      "Trial No.11\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:59.85593,   MAE: 59.81634,  MAPE: 5671.38%\n",
      "[100 Epochs]    RMSE:0.80980,   MAE: 0.66345,  MAPE: 62.45%\n",
      "[200 Epochs]    RMSE:0.56738,   MAE: 0.46761,  MAPE: 45.69%\n",
      "[300 Epochs]    RMSE:1.07255,   MAE: 0.99686,  MAPE: 90.85%\n",
      "[400 Epochs]    RMSE:0.77381,   MAE: 0.68884,  MAPE: 62.23%\n",
      "[500 Epochs]    RMSE:0.58770,   MAE: 0.50252,  MAPE: 45.22%\n",
      "[600 Epochs]    RMSE:0.69789,   MAE: 0.62969,  MAPE: 56.34%\n",
      "[700 Epochs]    RMSE:0.58825,   MAE: 0.52053,  MAPE: 46.25%\n",
      "[800 Epochs]    RMSE:0.57849,   MAE: 0.51616,  MAPE: 45.62%\n",
      "[900 Epochs]    RMSE:0.60066,   MAE: 0.54466,  MAPE: 48.02%\n",
      "[1000 Epochs]    RMSE:0.53249,   MAE: 0.47635,  MAPE: 41.67%\n",
      "[1100 Epochs]    RMSE:0.22403,   MAE: 0.17392,  MAPE: 17.84%\n",
      "[1200 Epochs]    RMSE:0.43488,   MAE: 0.39045,  MAPE: 34.34%\n",
      "[1300 Epochs]    RMSE:0.44456,   MAE: 0.40267,  MAPE: 35.28%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1400 Epochs]    RMSE:0.38932,   MAE: 0.34636,  MAPE: 30.10%\n",
      "[1500 Epochs]    RMSE:0.34613,   MAE: 0.30500,  MAPE: 26.38%\n",
      "[1600 Epochs]    RMSE:0.46293,   MAE: 0.42410,  MAPE: 36.74%\n",
      "[1700 Epochs]    RMSE:0.38519,   MAE: 0.34443,  MAPE: 29.47%\n",
      "[1800 Epochs]    RMSE:0.38668,   MAE: 0.34619,  MAPE: 29.53%\n",
      "[1900 Epochs]    RMSE:0.33961,   MAE: 0.30124,  MAPE: 25.69%\n",
      "[2000 Epochs]    RMSE:0.37140,   MAE: 0.33289,  MAPE: 28.27%\n",
      "[2100 Epochs]    RMSE:0.41300,   MAE: 0.38037,  MAPE: 32.84%\n",
      "[2200 Epochs]    RMSE:0.19727,   MAE: 0.16144,  MAPE: 16.66%\n",
      "[2300 Epochs]    RMSE:0.14672,   MAE: 0.10976,  MAPE: 10.78%\n",
      "[2400 Epochs]    RMSE:0.50507,   MAE: 0.48811,  MAPE: 44.13%\n",
      "[2500 Epochs]    RMSE:0.32829,   MAE: 0.30441,  MAPE: 26.58%\n",
      "[2600 Epochs]    RMSE:0.30856,   MAE: 0.28281,  MAPE: 24.52%\n",
      "[2700 Epochs]    RMSE:0.31876,   MAE: 0.29341,  MAPE: 25.47%\n",
      "[2800 Epochs]    RMSE:0.26760,   MAE: 0.24024,  MAPE: 20.66%\n",
      "[2900 Epochs]    RMSE:0.26378,   MAE: 0.23522,  MAPE: 20.08%\n",
      "[3000 Epochs]    RMSE:0.14361,   MAE: 0.11832,  MAPE: 12.35%\n",
      "[3100 Epochs]    RMSE:0.11726,   MAE: 0.09483,  MAPE: 8.99%\n",
      "[3200 Epochs]    RMSE:0.10999,   MAE: 0.08535,  MAPE: 9.13%\n",
      "[3300 Epochs]    RMSE:0.18408,   MAE: 0.16427,  MAPE: 16.72%\n",
      "[3400 Epochs]    RMSE:0.18438,   MAE: 0.16269,  MAPE: 14.10%\n",
      "[3500 Epochs]    RMSE:0.29484,   MAE: 0.27874,  MAPE: 24.71%\n",
      "[3600 Epochs]    RMSE:0.21721,   MAE: 0.19679,  MAPE: 17.09%\n",
      "[3700 Epochs]    RMSE:0.26277,   MAE: 0.23668,  MAPE: 20.14%\n",
      "[3800 Epochs]    RMSE:0.12277,   MAE: 0.09686,  MAPE: 10.46%\n",
      "[3900 Epochs]    RMSE:0.22968,   MAE: 0.20938,  MAPE: 21.38%\n",
      "[4000 Epochs]    RMSE:0.17651,   MAE: 0.14244,  MAPE: 15.49%\n",
      "[4100 Epochs]    RMSE:0.13768,   MAE: 0.11813,  MAPE: 10.45%\n",
      "[4200 Epochs]    RMSE:0.11735,   MAE: 0.09870,  MAPE: 8.89%\n",
      "[4300 Epochs]    RMSE:0.09979,   MAE: 0.07636,  MAPE: 8.29%\n",
      "[4400 Epochs]    RMSE:0.12838,   MAE: 0.10713,  MAPE: 9.70%\n",
      "[4500 Epochs]    RMSE:0.13594,   MAE: 0.11658,  MAPE: 10.39%\n",
      "[4600 Epochs]    RMSE:0.09898,   MAE: 0.07723,  MAPE: 7.34%\n",
      "[4700 Epochs]    RMSE:0.21899,   MAE: 0.19567,  MAPE: 20.32%\n",
      "[4800 Epochs]    RMSE:0.10180,   MAE: 0.08279,  MAPE: 7.58%\n",
      "[4900 Epochs]    RMSE:0.10988,   MAE: 0.08948,  MAPE: 9.51%\n",
      "\n",
      "[Final Epochs]    RMSE:0.12108,   MAE: 0.10167,  MAPE: 10.61%\n",
      "\n",
      "\n",
      "Trial No.12\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:94.03047,   MAE: 93.95306,  MAPE: 8913.04%\n",
      "[100 Epochs]    RMSE:1.18853,   MAE: 0.93521,  MAPE: 88.83%\n",
      "[200 Epochs]    RMSE:2.95173,   MAE: 2.75586,  MAPE: 256.51%\n",
      "[300 Epochs]    RMSE:1.15875,   MAE: 0.91511,  MAPE: 87.00%\n",
      "[400 Epochs]    RMSE:0.78358,   MAE: 0.66802,  MAPE: 63.12%\n",
      "[500 Epochs]    RMSE:0.69290,   MAE: 0.59093,  MAPE: 56.81%\n",
      "[600 Epochs]    RMSE:0.73890,   MAE: 0.65009,  MAPE: 62.27%\n",
      "[700 Epochs]    RMSE:0.66478,   MAE: 0.57986,  MAPE: 54.67%\n",
      "[800 Epochs]    RMSE:1.00614,   MAE: 0.90629,  MAPE: 90.55%\n",
      "[900 Epochs]    RMSE:0.94905,   MAE: 0.84063,  MAPE: 82.45%\n",
      "[1000 Epochs]    RMSE:0.96747,   MAE: 0.89209,  MAPE: 86.58%\n",
      "[1100 Epochs]    RMSE:0.38274,   MAE: 0.31771,  MAPE: 30.55%\n",
      "[1200 Epochs]    RMSE:2.17818,   MAE: 2.16514,  MAPE: 206.65%\n",
      "[1300 Epochs]    RMSE:0.52684,   MAE: 0.47017,  MAPE: 42.10%\n",
      "[1400 Epochs]    RMSE:0.64039,   MAE: 0.57323,  MAPE: 50.26%\n",
      "[1500 Epochs]    RMSE:0.59482,   MAE: 0.52640,  MAPE: 46.69%\n",
      "[1600 Epochs]    RMSE:0.60004,   MAE: 0.56084,  MAPE: 50.72%\n",
      "[1700 Epochs]    RMSE:0.56877,   MAE: 0.50784,  MAPE: 45.09%\n",
      "[1800 Epochs]    RMSE:0.19372,   MAE: 0.15813,  MAPE: 14.74%\n",
      "[1900 Epochs]    RMSE:0.26798,   MAE: 0.23341,  MAPE: 23.19%\n",
      "[2000 Epochs]    RMSE:0.42835,   MAE: 0.39591,  MAPE: 36.71%\n",
      "[2100 Epochs]    RMSE:0.57492,   MAE: 0.54377,  MAPE: 49.04%\n",
      "[2200 Epochs]    RMSE:0.23214,   MAE: 0.20029,  MAPE: 17.96%\n",
      "[2300 Epochs]    RMSE:0.54734,   MAE: 0.49045,  MAPE: 42.31%\n",
      "[2400 Epochs]    RMSE:0.14262,   MAE: 0.10881,  MAPE: 10.86%\n",
      "[2500 Epochs]    RMSE:0.11939,   MAE: 0.09193,  MAPE: 8.88%\n",
      "[2600 Epochs]    RMSE:0.19155,   MAE: 0.16243,  MAPE: 14.98%\n",
      "[2700 Epochs]    RMSE:0.28320,   MAE: 0.24536,  MAPE: 21.51%\n",
      "[2800 Epochs]    RMSE:0.19436,   MAE: 0.16808,  MAPE: 15.03%\n",
      "[2900 Epochs]    RMSE:0.14100,   MAE: 0.11184,  MAPE: 10.17%\n",
      "[3000 Epochs]    RMSE:0.18409,   MAE: 0.15141,  MAPE: 13.49%\n",
      "[3100 Epochs]    RMSE:0.22434,   MAE: 0.20318,  MAPE: 18.57%\n",
      "[3200 Epochs]    RMSE:0.24486,   MAE: 0.21742,  MAPE: 19.37%\n",
      "[3300 Epochs]    RMSE:0.26713,   MAE: 0.25127,  MAPE: 24.25%\n",
      "[3400 Epochs]    RMSE:0.46461,   MAE: 0.44702,  MAPE: 43.69%\n",
      "[3500 Epochs]    RMSE:0.09535,   MAE: 0.06730,  MAPE: 6.35%\n",
      "[3600 Epochs]    RMSE:0.13571,   MAE: 0.10851,  MAPE: 11.33%\n",
      "[3700 Epochs]    RMSE:0.18737,   MAE: 0.17006,  MAPE: 16.93%\n",
      "[3800 Epochs]    RMSE:0.08277,   MAE: 0.05541,  MAPE: 5.38%\n",
      "[3900 Epochs]    RMSE:0.11283,   MAE: 0.09714,  MAPE: 9.29%\n",
      "[4000 Epochs]    RMSE:0.12567,   MAE: 0.11046,  MAPE: 10.79%\n",
      "[4100 Epochs]    RMSE:0.11273,   MAE: 0.09366,  MAPE: 9.56%\n",
      "[4200 Epochs]    RMSE:0.12031,   MAE: 0.10619,  MAPE: 10.37%\n",
      "[4300 Epochs]    RMSE:0.15061,   MAE: 0.13312,  MAPE: 11.72%\n",
      "[4400 Epochs]    RMSE:0.07480,   MAE: 0.05354,  MAPE: 5.35%\n",
      "[4500 Epochs]    RMSE:0.15616,   MAE: 0.14582,  MAPE: 14.30%\n",
      "[4600 Epochs]    RMSE:0.10233,   MAE: 0.08789,  MAPE: 8.82%\n",
      "[4700 Epochs]    RMSE:0.09480,   MAE: 0.07912,  MAPE: 7.73%\n",
      "[4800 Epochs]    RMSE:0.07231,   MAE: 0.05302,  MAPE: 4.98%\n",
      "[4900 Epochs]    RMSE:0.10032,   MAE: 0.08702,  MAPE: 8.47%\n",
      "\n",
      "[Final Epochs]    RMSE:0.06786,   MAE: 0.04747,  MAPE: 4.67%\n",
      "\n",
      "\n",
      "Trial No.13\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:117.09511,   MAE: 117.04450,  MAPE: 11065.14%\n",
      "[100 Epochs]    RMSE:2.36074,   MAE: 1.94512,  MAPE: 176.13%\n",
      "[200 Epochs]    RMSE:1.68471,   MAE: 1.35011,  MAPE: 123.99%\n",
      "[300 Epochs]    RMSE:1.26096,   MAE: 1.01294,  MAPE: 93.70%\n",
      "[400 Epochs]    RMSE:2.44762,   MAE: 2.20974,  MAPE: 205.89%\n",
      "[500 Epochs]    RMSE:2.11365,   MAE: 1.86944,  MAPE: 178.35%\n",
      "[600 Epochs]    RMSE:2.30201,   MAE: 2.07567,  MAPE: 198.41%\n",
      "[700 Epochs]    RMSE:2.21182,   MAE: 1.99770,  MAPE: 190.74%\n",
      "[800 Epochs]    RMSE:2.27338,   MAE: 2.11609,  MAPE: 203.34%\n",
      "[900 Epochs]    RMSE:2.03756,   MAE: 1.86861,  MAPE: 178.45%\n",
      "[1000 Epochs]    RMSE:1.84954,   MAE: 1.69606,  MAPE: 161.61%\n",
      "[1100 Epochs]    RMSE:1.65205,   MAE: 1.48684,  MAPE: 141.13%\n",
      "[1200 Epochs]    RMSE:1.67149,   MAE: 1.51885,  MAPE: 143.84%\n",
      "[1300 Epochs]    RMSE:1.39250,   MAE: 1.23178,  MAPE: 116.36%\n",
      "[1400 Epochs]    RMSE:1.51568,   MAE: 1.37095,  MAPE: 128.96%\n",
      "[1500 Epochs]    RMSE:1.39451,   MAE: 1.25709,  MAPE: 118.30%\n",
      "[1600 Epochs]    RMSE:1.47588,   MAE: 1.34534,  MAPE: 126.79%\n",
      "[1700 Epochs]    RMSE:1.45685,   MAE: 1.33459,  MAPE: 125.53%\n",
      "[1800 Epochs]    RMSE:1.18958,   MAE: 1.07084,  MAPE: 99.94%\n",
      "[1900 Epochs]    RMSE:1.24681,   MAE: 1.12566,  MAPE: 104.86%\n",
      "[2000 Epochs]    RMSE:1.09173,   MAE: 0.96688,  MAPE: 89.93%\n",
      "[2100 Epochs]    RMSE:0.38755,   MAE: 0.30968,  MAPE: 29.71%\n",
      "[2200 Epochs]    RMSE:0.62250,   MAE: 0.54247,  MAPE: 50.19%\n",
      "[2300 Epochs]    RMSE:0.85133,   MAE: 0.80014,  MAPE: 73.36%\n",
      "[2400 Epochs]    RMSE:1.68384,   MAE: 1.60483,  MAPE: 150.24%\n",
      "[2500 Epochs]    RMSE:2.22500,   MAE: 2.15362,  MAPE: 204.23%\n",
      "[2600 Epochs]    RMSE:1.20794,   MAE: 1.08460,  MAPE: 100.60%\n",
      "[2700 Epochs]    RMSE:1.42136,   MAE: 1.32686,  MAPE: 122.75%\n",
      "[2800 Epochs]    RMSE:1.78759,   MAE: 1.72023,  MAPE: 164.91%\n",
      "[2900 Epochs]    RMSE:0.96596,   MAE: 0.85177,  MAPE: 77.30%\n",
      "[3000 Epochs]    RMSE:0.51597,   MAE: 0.44845,  MAPE: 44.10%\n",
      "[3100 Epochs]    RMSE:0.42961,   MAE: 0.37363,  MAPE: 33.66%\n",
      "[3200 Epochs]    RMSE:0.22972,   MAE: 0.18717,  MAPE: 17.85%\n",
      "[3300 Epochs]    RMSE:0.50107,   MAE: 0.44839,  MAPE: 44.46%\n",
      "[3400 Epochs]    RMSE:0.32556,   MAE: 0.27164,  MAPE: 27.26%\n",
      "[3500 Epochs]    RMSE:0.37538,   MAE: 0.32218,  MAPE: 32.46%\n",
      "[3600 Epochs]    RMSE:0.34880,   MAE: 0.29523,  MAPE: 25.78%\n",
      "[3700 Epochs]    RMSE:0.51213,   MAE: 0.46306,  MAPE: 40.89%\n",
      "[3800 Epochs]    RMSE:0.56945,   MAE: 0.50920,  MAPE: 44.94%\n",
      "[3900 Epochs]    RMSE:0.67760,   MAE: 0.62468,  MAPE: 55.63%\n",
      "[4000 Epochs]    RMSE:0.49770,   MAE: 0.43430,  MAPE: 43.95%\n",
      "[4100 Epochs]    RMSE:0.43965,   MAE: 0.38417,  MAPE: 38.80%\n",
      "[4200 Epochs]    RMSE:0.39235,   MAE: 0.33159,  MAPE: 33.88%\n",
      "[4300 Epochs]    RMSE:0.46561,   MAE: 0.42916,  MAPE: 42.58%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4400 Epochs]    RMSE:0.30237,   MAE: 0.26224,  MAPE: 23.62%\n",
      "[4500 Epochs]    RMSE:0.26988,   MAE: 0.23262,  MAPE: 23.24%\n",
      "[4600 Epochs]    RMSE:0.66739,   MAE: 0.64185,  MAPE: 63.09%\n",
      "[4700 Epochs]    RMSE:1.17705,   MAE: 1.16195,  MAPE: 112.77%\n",
      "[4800 Epochs]    RMSE:0.53456,   MAE: 0.47969,  MAPE: 41.64%\n",
      "[4900 Epochs]    RMSE:0.71110,   MAE: 0.67319,  MAPE: 59.74%\n",
      "\n",
      "[Final Epochs]    RMSE:0.57345,   MAE: 0.53461,  MAPE: 54.10%\n",
      "\n",
      "\n",
      "Trial No.14\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:132.52301,   MAE: 132.47815,  MAPE: 12467.91%\n",
      "[100 Epochs]    RMSE:2.33904,   MAE: 1.93761,  MAPE: 180.67%\n",
      "[200 Epochs]    RMSE:1.48543,   MAE: 1.18037,  MAPE: 111.89%\n",
      "[300 Epochs]    RMSE:1.46215,   MAE: 1.24350,  MAPE: 117.14%\n",
      "[400 Epochs]    RMSE:1.23322,   MAE: 1.06585,  MAPE: 99.54%\n",
      "[500 Epochs]    RMSE:1.16390,   MAE: 1.05381,  MAPE: 99.75%\n",
      "[600 Epochs]    RMSE:3.27541,   MAE: 3.23096,  MAPE: 306.54%\n",
      "[700 Epochs]    RMSE:1.43943,   MAE: 1.32767,  MAPE: 130.83%\n",
      "[800 Epochs]    RMSE:1.18798,   MAE: 1.07290,  MAPE: 106.01%\n",
      "[900 Epochs]    RMSE:1.00609,   MAE: 0.89030,  MAPE: 88.62%\n",
      "[1000 Epochs]    RMSE:1.02814,   MAE: 0.93221,  MAPE: 92.01%\n",
      "[1100 Epochs]    RMSE:0.97538,   MAE: 0.88823,  MAPE: 87.85%\n",
      "[1200 Epochs]    RMSE:0.83837,   MAE: 0.75190,  MAPE: 74.61%\n",
      "[1300 Epochs]    RMSE:0.68426,   MAE: 0.60070,  MAPE: 59.86%\n",
      "[1400 Epochs]    RMSE:0.85023,   MAE: 0.78919,  MAPE: 77.42%\n",
      "[1500 Epochs]    RMSE:0.80297,   MAE: 0.74719,  MAPE: 73.27%\n",
      "[1600 Epochs]    RMSE:0.69765,   MAE: 0.64041,  MAPE: 62.88%\n",
      "[1700 Epochs]    RMSE:0.69690,   MAE: 0.64826,  MAPE: 63.36%\n",
      "[1800 Epochs]    RMSE:0.64138,   MAE: 0.59650,  MAPE: 58.36%\n",
      "[1900 Epochs]    RMSE:0.57327,   MAE: 0.52800,  MAPE: 51.81%\n",
      "[2000 Epochs]    RMSE:0.55068,   MAE: 0.51046,  MAPE: 49.83%\n",
      "[2100 Epochs]    RMSE:0.29453,   MAE: 0.24826,  MAPE: 24.45%\n",
      "[2200 Epochs]    RMSE:0.47001,   MAE: 0.43100,  MAPE: 42.18%\n",
      "[2300 Epochs]    RMSE:0.34772,   MAE: 0.30560,  MAPE: 30.24%\n",
      "[2400 Epochs]    RMSE:0.40988,   MAE: 0.37248,  MAPE: 36.81%\n",
      "[2500 Epochs]    RMSE:0.39909,   MAE: 0.37009,  MAPE: 36.40%\n",
      "[2600 Epochs]    RMSE:0.34910,   MAE: 0.31698,  MAPE: 31.79%\n",
      "[2700 Epochs]    RMSE:0.32256,   MAE: 0.30210,  MAPE: 29.44%\n",
      "[2800 Epochs]    RMSE:0.34950,   MAE: 0.33050,  MAPE: 32.19%\n",
      "[2900 Epochs]    RMSE:0.15032,   MAE: 0.12479,  MAPE: 11.39%\n",
      "[3000 Epochs]    RMSE:0.19941,   MAE: 0.18283,  MAPE: 18.07%\n",
      "[3100 Epochs]    RMSE:0.35873,   MAE: 0.34298,  MAPE: 31.38%\n",
      "[3200 Epochs]    RMSE:0.11345,   MAE: 0.08612,  MAPE: 7.68%\n",
      "[3300 Epochs]    RMSE:0.12823,   MAE: 0.10876,  MAPE: 10.86%\n",
      "[3400 Epochs]    RMSE:0.16912,   MAE: 0.13869,  MAPE: 12.11%\n",
      "[3500 Epochs]    RMSE:0.09195,   MAE: 0.07171,  MAPE: 6.99%\n",
      "[3600 Epochs]    RMSE:0.09160,   MAE: 0.07341,  MAPE: 7.42%\n",
      "[3700 Epochs]    RMSE:0.16056,   MAE: 0.13046,  MAPE: 13.63%\n",
      "[3800 Epochs]    RMSE:0.14226,   MAE: 0.12151,  MAPE: 10.74%\n",
      "[3900 Epochs]    RMSE:0.10200,   MAE: 0.08555,  MAPE: 8.66%\n",
      "[4000 Epochs]    RMSE:0.08532,   MAE: 0.06595,  MAPE: 6.21%\n",
      "[4100 Epochs]    RMSE:0.10217,   MAE: 0.08321,  MAPE: 8.70%\n",
      "[4200 Epochs]    RMSE:0.18494,   MAE: 0.15705,  MAPE: 16.36%\n",
      "[4300 Epochs]    RMSE:0.24583,   MAE: 0.20485,  MAPE: 21.38%\n",
      "[4400 Epochs]    RMSE:0.09916,   MAE: 0.07974,  MAPE: 8.19%\n",
      "[4500 Epochs]    RMSE:0.08581,   MAE: 0.06224,  MAPE: 6.01%\n",
      "[4600 Epochs]    RMSE:0.14279,   MAE: 0.12549,  MAPE: 11.25%\n",
      "[4700 Epochs]    RMSE:0.12492,   MAE: 0.10401,  MAPE: 9.41%\n",
      "[4800 Epochs]    RMSE:0.11134,   MAE: 0.08697,  MAPE: 9.14%\n",
      "[4900 Epochs]    RMSE:0.08627,   MAE: 0.06812,  MAPE: 6.74%\n",
      "\n",
      "[Final Epochs]    RMSE:0.11257,   MAE: 0.09479,  MAPE: 9.72%\n",
      "\n",
      "\n",
      "Trial No.15\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:33.92839,   MAE: 33.50750,  MAPE: 3083.85%\n",
      "[100 Epochs]    RMSE:2.75914,   MAE: 2.23144,  MAPE: 230.56%\n",
      "[200 Epochs]    RMSE:1.80815,   MAE: 1.50057,  MAPE: 128.50%\n",
      "[300 Epochs]    RMSE:1.74027,   MAE: 1.49256,  MAPE: 153.05%\n",
      "[400 Epochs]    RMSE:2.71461,   MAE: 2.37942,  MAPE: 244.81%\n",
      "[500 Epochs]    RMSE:1.65539,   MAE: 1.44889,  MAPE: 147.13%\n",
      "[600 Epochs]    RMSE:2.68898,   MAE: 2.62738,  MAPE: 254.95%\n",
      "[700 Epochs]    RMSE:2.74091,   MAE: 2.64704,  MAPE: 258.31%\n",
      "[800 Epochs]    RMSE:8.35966,   MAE: 8.35077,  MAPE: 793.25%\n",
      "[900 Epochs]    RMSE:0.70098,   MAE: 0.56622,  MAPE: 49.57%\n",
      "[1000 Epochs]    RMSE:2.10330,   MAE: 2.06313,  MAPE: 188.47%\n",
      "[1100 Epochs]    RMSE:1.26538,   MAE: 1.17605,  MAPE: 103.72%\n",
      "[1200 Epochs]    RMSE:1.28118,   MAE: 1.18539,  MAPE: 104.11%\n",
      "[1300 Epochs]    RMSE:0.43854,   MAE: 0.35720,  MAPE: 35.67%\n",
      "[1400 Epochs]    RMSE:0.79648,   MAE: 0.74839,  MAPE: 74.57%\n",
      "[1500 Epochs]    RMSE:0.80779,   MAE: 0.72662,  MAPE: 73.78%\n",
      "[1600 Epochs]    RMSE:0.77021,   MAE: 0.68222,  MAPE: 70.52%\n",
      "[1700 Epochs]    RMSE:0.40875,   MAE: 0.32905,  MAPE: 34.95%\n",
      "[1800 Epochs]    RMSE:1.16338,   MAE: 1.13585,  MAPE: 111.14%\n",
      "[1900 Epochs]    RMSE:1.99845,   MAE: 1.98417,  MAPE: 189.23%\n",
      "[2000 Epochs]    RMSE:0.43308,   MAE: 0.39655,  MAPE: 40.63%\n",
      "[2100 Epochs]    RMSE:0.58201,   MAE: 0.54277,  MAPE: 47.70%\n",
      "[2200 Epochs]    RMSE:0.45167,   MAE: 0.39484,  MAPE: 33.82%\n",
      "[2300 Epochs]    RMSE:0.16098,   MAE: 0.12714,  MAPE: 11.08%\n",
      "[2400 Epochs]    RMSE:0.27269,   MAE: 0.24664,  MAPE: 25.15%\n",
      "[2500 Epochs]    RMSE:0.36355,   MAE: 0.32653,  MAPE: 33.73%\n",
      "[2600 Epochs]    RMSE:0.37118,   MAE: 0.33061,  MAPE: 34.35%\n",
      "[2700 Epochs]    RMSE:0.28660,   MAE: 0.24891,  MAPE: 21.13%\n",
      "[2800 Epochs]    RMSE:0.27963,   MAE: 0.24332,  MAPE: 20.43%\n",
      "[2900 Epochs]    RMSE:0.26633,   MAE: 0.22921,  MAPE: 19.45%\n",
      "[3000 Epochs]    RMSE:0.16426,   MAE: 0.14458,  MAPE: 14.71%\n",
      "[3100 Epochs]    RMSE:0.14495,   MAE: 0.12081,  MAPE: 10.55%\n",
      "[3200 Epochs]    RMSE:0.25637,   MAE: 0.23073,  MAPE: 19.96%\n",
      "[3300 Epochs]    RMSE:0.18872,   MAE: 0.15902,  MAPE: 13.50%\n",
      "[3400 Epochs]    RMSE:0.13516,   MAE: 0.11610,  MAPE: 11.95%\n",
      "[3500 Epochs]    RMSE:0.11349,   MAE: 0.09303,  MAPE: 9.54%\n",
      "[3600 Epochs]    RMSE:0.09077,   MAE: 0.06899,  MAPE: 7.27%\n",
      "[3700 Epochs]    RMSE:0.11659,   MAE: 0.09747,  MAPE: 8.72%\n",
      "[3800 Epochs]    RMSE:0.10587,   MAE: 0.08720,  MAPE: 7.81%\n",
      "[3900 Epochs]    RMSE:0.07540,   MAE: 0.05560,  MAPE: 5.43%\n",
      "[4000 Epochs]    RMSE:0.19252,   MAE: 0.17901,  MAPE: 17.57%\n",
      "[4100 Epochs]    RMSE:0.13461,   MAE: 0.11604,  MAPE: 10.25%\n",
      "[4200 Epochs]    RMSE:0.08770,   MAE: 0.07172,  MAPE: 7.29%\n",
      "[4300 Epochs]    RMSE:0.08035,   MAE: 0.06522,  MAPE: 6.20%\n",
      "[4400 Epochs]    RMSE:0.06305,   MAE: 0.04793,  MAPE: 4.75%\n",
      "[4500 Epochs]    RMSE:0.09787,   MAE: 0.08289,  MAPE: 7.85%\n",
      "[4600 Epochs]    RMSE:0.07396,   MAE: 0.05602,  MAPE: 5.37%\n",
      "[4700 Epochs]    RMSE:0.11386,   MAE: 0.09473,  MAPE: 9.96%\n",
      "[4800 Epochs]    RMSE:0.07261,   MAE: 0.05387,  MAPE: 5.40%\n",
      "[4900 Epochs]    RMSE:0.10360,   MAE: 0.07405,  MAPE: 7.02%\n",
      "\n",
      "[Final Epochs]    RMSE:0.10909,   MAE: 0.09675,  MAPE: 8.88%\n",
      "\n",
      "\n",
      "Trial No.16\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 30\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:39.65631,   MAE: 38.97437,  MAPE: 3583.40%\n",
      "[100 Epochs]    RMSE:5.09838,   MAE: 4.75642,  MAPE: 418.16%\n",
      "[200 Epochs]    RMSE:2.45449,   MAE: 2.02435,  MAPE: 169.72%\n",
      "[300 Epochs]    RMSE:2.54521,   MAE: 2.22639,  MAPE: 189.02%\n",
      "[400 Epochs]    RMSE:2.20426,   MAE: 1.98859,  MAPE: 171.27%\n",
      "[500 Epochs]    RMSE:0.82530,   MAE: 0.70126,  MAPE: 68.86%\n",
      "[600 Epochs]    RMSE:0.50345,   MAE: 0.41394,  MAPE: 36.07%\n",
      "[700 Epochs]    RMSE:0.78975,   MAE: 0.70623,  MAPE: 60.94%\n",
      "[800 Epochs]    RMSE:0.50979,   MAE: 0.42192,  MAPE: 41.54%\n",
      "[900 Epochs]    RMSE:0.56401,   MAE: 0.47663,  MAPE: 41.34%\n",
      "[1000 Epochs]    RMSE:0.67831,   MAE: 0.61191,  MAPE: 53.59%\n",
      "[1100 Epochs]    RMSE:0.58634,   MAE: 0.53721,  MAPE: 45.26%\n",
      "[1200 Epochs]    RMSE:0.25620,   MAE: 0.21774,  MAPE: 20.19%\n",
      "[1300 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[1400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "\n",
      "[Final Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "\n",
      "\n",
      "Trial No.17\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 30\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:186.01041,   MAE: 185.96738,  MAPE: 17556.35%\n",
      "[100 Epochs]    RMSE:2.04571,   MAE: 2.01261,  MAPE: 193.66%\n",
      "[200 Epochs]    RMSE:0.33759,   MAE: 0.27640,  MAPE: 24.80%\n",
      "[300 Epochs]    RMSE:0.68972,   MAE: 0.66080,  MAPE: 64.99%\n",
      "[400 Epochs]    RMSE:0.36810,   MAE: 0.32812,  MAPE: 33.59%\n",
      "[500 Epochs]    RMSE:0.25961,   MAE: 0.22157,  MAPE: 19.12%\n",
      "[600 Epochs]    RMSE:0.16938,   MAE: 0.13324,  MAPE: 11.76%\n",
      "[700 Epochs]    RMSE:0.12822,   MAE: 0.10111,  MAPE: 10.15%\n",
      "[800 Epochs]    RMSE:0.47651,   MAE: 0.46018,  MAPE: 45.27%\n",
      "[900 Epochs]    RMSE:0.12342,   MAE: 0.10175,  MAPE: 9.85%\n",
      "[1000 Epochs]    RMSE:0.12037,   MAE: 0.09779,  MAPE: 9.28%\n",
      "[1100 Epochs]    RMSE:0.12654,   MAE: 0.09944,  MAPE: 8.99%\n",
      "[1200 Epochs]    RMSE:0.12392,   MAE: 0.10206,  MAPE: 10.22%\n",
      "[1300 Epochs]    RMSE:0.11483,   MAE: 0.09116,  MAPE: 8.92%\n",
      "[1400 Epochs]    RMSE:0.12361,   MAE: 0.09650,  MAPE: 8.87%\n",
      "[1500 Epochs]    RMSE:0.11344,   MAE: 0.08872,  MAPE: 8.66%\n",
      "[1600 Epochs]    RMSE:0.13615,   MAE: 0.10467,  MAPE: 9.38%\n",
      "[1700 Epochs]    RMSE:0.11647,   MAE: 0.08983,  MAPE: 8.47%\n",
      "[1800 Epochs]    RMSE:0.11234,   MAE: 0.08702,  MAPE: 8.70%\n",
      "[1900 Epochs]    RMSE:0.14302,   MAE: 0.11823,  MAPE: 12.32%\n",
      "[2000 Epochs]    RMSE:0.11395,   MAE: 0.08666,  MAPE: 8.28%\n",
      "[2100 Epochs]    RMSE:0.21983,   MAE: 0.18786,  MAPE: 18.11%\n",
      "[2200 Epochs]    RMSE:0.19158,   MAE: 0.16215,  MAPE: 16.80%\n",
      "[2300 Epochs]    RMSE:0.15464,   MAE: 0.12941,  MAPE: 13.02%\n",
      "[2400 Epochs]    RMSE:0.15974,   MAE: 0.13390,  MAPE: 12.04%\n",
      "[2500 Epochs]    RMSE:0.14844,   MAE: 0.12188,  MAPE: 10.98%\n",
      "[2600 Epochs]    RMSE:0.12955,   MAE: 0.10425,  MAPE: 10.86%\n",
      "[2700 Epochs]    RMSE:0.11948,   MAE: 0.09532,  MAPE: 9.67%\n",
      "[2800 Epochs]    RMSE:0.12489,   MAE: 0.10043,  MAPE: 10.37%\n",
      "[2900 Epochs]    RMSE:0.11897,   MAE: 0.08946,  MAPE: 8.42%\n",
      "[3000 Epochs]    RMSE:0.11835,   MAE: 0.09388,  MAPE: 9.53%\n",
      "[3100 Epochs]    RMSE:0.16042,   MAE: 0.12789,  MAPE: 11.09%\n",
      "[3200 Epochs]    RMSE:0.12396,   MAE: 0.09324,  MAPE: 8.63%\n",
      "[3300 Epochs]    RMSE:0.13513,   MAE: 0.10106,  MAPE: 9.07%\n",
      "[3400 Epochs]    RMSE:0.11358,   MAE: 0.08830,  MAPE: 8.89%\n",
      "[3500 Epochs]    RMSE:0.11789,   MAE: 0.08767,  MAPE: 8.26%\n",
      "[3600 Epochs]    RMSE:0.13559,   MAE: 0.11122,  MAPE: 11.58%\n",
      "[3700 Epochs]    RMSE:0.12534,   MAE: 0.10036,  MAPE: 10.33%\n",
      "[3800 Epochs]    RMSE:0.12388,   MAE: 0.09113,  MAPE: 8.41%\n",
      "[3900 Epochs]    RMSE:0.15887,   MAE: 0.12758,  MAPE: 11.12%\n",
      "[4000 Epochs]    RMSE:0.14808,   MAE: 0.11248,  MAPE: 9.91%\n",
      "[4100 Epochs]    RMSE:0.13041,   MAE: 0.10579,  MAPE: 10.86%\n",
      "[4200 Epochs]    RMSE:0.13684,   MAE: 0.10381,  MAPE: 9.33%\n",
      "[4300 Epochs]    RMSE:0.11461,   MAE: 0.08457,  MAPE: 8.07%\n",
      "[4400 Epochs]    RMSE:0.11151,   MAE: 0.08535,  MAPE: 8.74%\n",
      "[4500 Epochs]    RMSE:0.11297,   MAE: 0.08727,  MAPE: 8.91%\n",
      "[4600 Epochs]    RMSE:0.12587,   MAE: 0.10075,  MAPE: 10.25%\n",
      "[4700 Epochs]    RMSE:0.11052,   MAE: 0.08335,  MAPE: 8.41%\n",
      "[4800 Epochs]    RMSE:0.11145,   MAE: 0.08218,  MAPE: 8.04%\n",
      "[4900 Epochs]    RMSE:0.16374,   MAE: 0.13235,  MAPE: 11.51%\n",
      "\n",
      "[Final Epochs]    RMSE:0.13173,   MAE: 0.09882,  MAPE: 8.97%\n",
      "\n",
      "\n",
      "Trial No.18\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 30\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:201.20094,   MAE: 201.14963,  MAPE: 18945.04%\n",
      "[100 Epochs]    RMSE:3.35788,   MAE: 3.28763,  MAPE: 297.41%\n",
      "[200 Epochs]    RMSE:0.84050,   MAE: 0.74794,  MAPE: 78.82%\n",
      "[300 Epochs]    RMSE:0.48496,   MAE: 0.40065,  MAPE: 43.96%\n",
      "[400 Epochs]    RMSE:0.22840,   MAE: 0.16937,  MAPE: 18.90%\n",
      "[500 Epochs]    RMSE:0.21547,   MAE: 0.17663,  MAPE: 16.94%\n",
      "[600 Epochs]    RMSE:0.19369,   MAE: 0.15034,  MAPE: 16.40%\n",
      "[700 Epochs]    RMSE:0.18784,   MAE: 0.15152,  MAPE: 16.28%\n",
      "[800 Epochs]    RMSE:0.17012,   MAE: 0.13462,  MAPE: 14.51%\n",
      "[900 Epochs]    RMSE:0.12740,   MAE: 0.09620,  MAPE: 10.13%\n",
      "[1000 Epochs]    RMSE:0.19283,   MAE: 0.16078,  MAPE: 17.04%\n",
      "[1100 Epochs]    RMSE:0.15959,   MAE: 0.12841,  MAPE: 11.36%\n",
      "[1200 Epochs]    RMSE:0.14574,   MAE: 0.11093,  MAPE: 11.05%\n",
      "[1300 Epochs]    RMSE:0.15400,   MAE: 0.11771,  MAPE: 10.62%\n",
      "[1400 Epochs]    RMSE:0.12900,   MAE: 0.09981,  MAPE: 9.79%\n",
      "[1500 Epochs]    RMSE:0.12907,   MAE: 0.10493,  MAPE: 10.55%\n",
      "[1600 Epochs]    RMSE:0.13086,   MAE: 0.10468,  MAPE: 11.04%\n",
      "[1700 Epochs]    RMSE:0.11967,   MAE: 0.09002,  MAPE: 8.68%\n",
      "[1800 Epochs]    RMSE:0.18605,   MAE: 0.15317,  MAPE: 13.46%\n",
      "[1900 Epochs]    RMSE:0.12296,   MAE: 0.08859,  MAPE: 8.35%\n",
      "[2000 Epochs]    RMSE:0.13249,   MAE: 0.10161,  MAPE: 9.15%\n",
      "[2100 Epochs]    RMSE:0.12454,   MAE: 0.09126,  MAPE: 8.20%\n",
      "[2200 Epochs]    RMSE:0.12337,   MAE: 0.10000,  MAPE: 10.23%\n",
      "[2300 Epochs]    RMSE:0.10959,   MAE: 0.07394,  MAPE: 6.99%\n",
      "[2400 Epochs]    RMSE:0.12893,   MAE: 0.09291,  MAPE: 8.55%\n",
      "[2500 Epochs]    RMSE:0.14588,   MAE: 0.12915,  MAPE: 12.87%\n",
      "[2600 Epochs]    RMSE:0.17653,   MAE: 0.15436,  MAPE: 15.05%\n",
      "[2700 Epochs]    RMSE:0.10846,   MAE: 0.08298,  MAPE: 8.75%\n",
      "[2800 Epochs]    RMSE:0.13190,   MAE: 0.10680,  MAPE: 9.33%\n",
      "[2900 Epochs]    RMSE:0.10522,   MAE: 0.08326,  MAPE: 8.53%\n",
      "[3000 Epochs]    RMSE:0.34491,   MAE: 0.27101,  MAPE: 30.41%\n",
      "[3100 Epochs]    RMSE:0.19656,   MAE: 0.16466,  MAPE: 17.34%\n",
      "[3200 Epochs]    RMSE:0.13310,   MAE: 0.10727,  MAPE: 11.01%\n",
      "[3300 Epochs]    RMSE:0.13569,   MAE: 0.10919,  MAPE: 11.68%\n",
      "[3400 Epochs]    RMSE:0.12216,   MAE: 0.09461,  MAPE: 9.20%\n",
      "[3500 Epochs]    RMSE:0.11776,   MAE: 0.09421,  MAPE: 9.50%\n",
      "[3600 Epochs]    RMSE:0.16620,   MAE: 0.13417,  MAPE: 11.68%\n",
      "[3700 Epochs]    RMSE:0.13299,   MAE: 0.10158,  MAPE: 9.32%\n",
      "[3800 Epochs]    RMSE:0.12074,   MAE: 0.09595,  MAPE: 9.65%\n",
      "[3900 Epochs]    RMSE:0.11700,   MAE: 0.08965,  MAPE: 8.66%\n",
      "[4000 Epochs]    RMSE:0.14653,   MAE: 0.12212,  MAPE: 12.54%\n",
      "[4100 Epochs]    RMSE:0.11552,   MAE: 0.08866,  MAPE: 8.61%\n",
      "[4200 Epochs]    RMSE:0.14804,   MAE: 0.12394,  MAPE: 12.68%\n",
      "[4300 Epochs]    RMSE:0.12999,   MAE: 0.10628,  MAPE: 10.82%\n",
      "[4400 Epochs]    RMSE:0.12331,   MAE: 0.09619,  MAPE: 9.09%\n",
      "[4500 Epochs]    RMSE:0.13225,   MAE: 0.10002,  MAPE: 9.09%\n",
      "[4600 Epochs]    RMSE:0.11931,   MAE: 0.09111,  MAPE: 8.63%\n",
      "[4700 Epochs]    RMSE:0.14100,   MAE: 0.10670,  MAPE: 9.51%\n",
      "[4800 Epochs]    RMSE:0.13812,   MAE: 0.10712,  MAPE: 9.63%\n",
      "[4900 Epochs]    RMSE:0.11643,   MAE: 0.09207,  MAPE: 9.32%\n",
      "\n",
      "[Final Epochs]    RMSE:0.12481,   MAE: 0.10079,  MAPE: 10.22%\n",
      "\n",
      "\n",
      "Trial No.19\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 40\n",
      "Hidden 2 neuron : 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:166.61038,   MAE: 166.54617,  MAPE: 15761.48%\n",
      "[100 Epochs]    RMSE:0.22133,   MAE: 0.17800,  MAPE: 19.25%\n",
      "[200 Epochs]    RMSE:0.18553,   MAE: 0.14959,  MAPE: 15.96%\n",
      "[300 Epochs]    RMSE:0.18192,   MAE: 0.13901,  MAPE: 15.51%\n",
      "[400 Epochs]    RMSE:0.24403,   MAE: 0.20028,  MAPE: 21.86%\n",
      "[500 Epochs]    RMSE:0.21087,   MAE: 0.18666,  MAPE: 16.51%\n",
      "[600 Epochs]    RMSE:0.16987,   MAE: 0.14649,  MAPE: 13.63%\n",
      "[700 Epochs]    RMSE:0.20046,   MAE: 0.14611,  MAPE: 16.98%\n",
      "[800 Epochs]    RMSE:0.33807,   MAE: 0.30024,  MAPE: 31.93%\n",
      "[900 Epochs]    RMSE:0.12820,   MAE: 0.10006,  MAPE: 9.71%\n",
      "[1000 Epochs]    RMSE:0.13794,   MAE: 0.10792,  MAPE: 9.89%\n",
      "[1100 Epochs]    RMSE:0.12773,   MAE: 0.09814,  MAPE: 9.18%\n",
      "[1200 Epochs]    RMSE:0.11104,   MAE: 0.08401,  MAPE: 8.43%\n",
      "[1300 Epochs]    RMSE:0.12360,   MAE: 0.09790,  MAPE: 10.31%\n",
      "[1400 Epochs]    RMSE:0.11910,   MAE: 0.09300,  MAPE: 9.86%\n",
      "[1500 Epochs]    RMSE:0.12944,   MAE: 0.09821,  MAPE: 8.97%\n",
      "[1600 Epochs]    RMSE:0.11288,   MAE: 0.08749,  MAPE: 8.95%\n",
      "[1700 Epochs]    RMSE:0.11476,   MAE: 0.08476,  MAPE: 8.07%\n",
      "[1800 Epochs]    RMSE:0.11131,   MAE: 0.08480,  MAPE: 8.84%\n",
      "[1900 Epochs]    RMSE:0.10919,   MAE: 0.08152,  MAPE: 8.15%\n",
      "[2000 Epochs]    RMSE:0.12996,   MAE: 0.09750,  MAPE: 8.86%\n",
      "[2100 Epochs]    RMSE:0.12831,   MAE: 0.09344,  MAPE: 8.55%\n",
      "[2200 Epochs]    RMSE:0.10861,   MAE: 0.08075,  MAPE: 8.15%\n",
      "[2300 Epochs]    RMSE:0.12117,   MAE: 0.09587,  MAPE: 9.84%\n",
      "[2400 Epochs]    RMSE:0.14049,   MAE: 0.11812,  MAPE: 11.99%\n",
      "[2500 Epochs]    RMSE:0.17669,   MAE: 0.14624,  MAPE: 12.73%\n",
      "[2600 Epochs]    RMSE:0.12370,   MAE: 0.09844,  MAPE: 10.11%\n",
      "[2700 Epochs]    RMSE:0.11180,   MAE: 0.08518,  MAPE: 8.72%\n",
      "[2800 Epochs]    RMSE:0.10661,   MAE: 0.07716,  MAPE: 7.66%\n",
      "[2900 Epochs]    RMSE:0.11007,   MAE: 0.08398,  MAPE: 8.45%\n",
      "[3000 Epochs]    RMSE:0.14170,   MAE: 0.11157,  MAPE: 9.84%\n",
      "[3100 Epochs]    RMSE:0.10642,   MAE: 0.07877,  MAPE: 7.87%\n",
      "[3200 Epochs]    RMSE:0.10898,   MAE: 0.08212,  MAPE: 8.52%\n",
      "[3300 Epochs]    RMSE:0.11511,   MAE: 0.08344,  MAPE: 7.75%\n",
      "[3400 Epochs]    RMSE:0.10398,   MAE: 0.07687,  MAPE: 7.84%\n",
      "[3500 Epochs]    RMSE:0.17375,   MAE: 0.14394,  MAPE: 12.57%\n",
      "[3600 Epochs]    RMSE:0.12009,   MAE: 0.08860,  MAPE: 8.06%\n",
      "[3700 Epochs]    RMSE:0.10913,   MAE: 0.08160,  MAPE: 8.50%\n",
      "[3800 Epochs]    RMSE:0.11902,   MAE: 0.08277,  MAPE: 7.60%\n",
      "[3900 Epochs]    RMSE:0.12715,   MAE: 0.10433,  MAPE: 10.83%\n",
      "[4000 Epochs]    RMSE:0.10800,   MAE: 0.07752,  MAPE: 7.18%\n",
      "[4100 Epochs]    RMSE:0.09890,   MAE: 0.06983,  MAPE: 6.98%\n",
      "[4200 Epochs]    RMSE:0.10162,   MAE: 0.07398,  MAPE: 7.52%\n",
      "[4300 Epochs]    RMSE:0.15430,   MAE: 0.12032,  MAPE: 10.92%\n",
      "[4400 Epochs]    RMSE:0.10583,   MAE: 0.07985,  MAPE: 8.07%\n",
      "[4500 Epochs]    RMSE:0.09989,   MAE: 0.07204,  MAPE: 7.13%\n",
      "[4600 Epochs]    RMSE:0.12166,   MAE: 0.08875,  MAPE: 7.99%\n",
      "[4700 Epochs]    RMSE:0.09500,   MAE: 0.06731,  MAPE: 6.47%\n",
      "[4800 Epochs]    RMSE:0.09507,   MAE: 0.06437,  MAPE: 6.22%\n",
      "[4900 Epochs]    RMSE:0.09826,   MAE: 0.06816,  MAPE: 6.41%\n",
      "\n",
      "[Final Epochs]    RMSE:0.14937,   MAE: 0.13122,  MAPE: 13.42%\n",
      "\n",
      "\n",
      "Trial No.20\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 40\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:380.90482,   MAE: 380.69852,  MAPE: 35746.74%\n",
      "[100 Epochs]    RMSE:3.88462,   MAE: 3.18765,  MAPE: 332.30%\n",
      "[200 Epochs]    RMSE:1.40646,   MAE: 1.10845,  MAPE: 106.41%\n",
      "[300 Epochs]    RMSE:2.02074,   MAE: 1.85005,  MAPE: 187.89%\n",
      "[400 Epochs]    RMSE:1.73869,   MAE: 1.66053,  MAPE: 165.30%\n",
      "[500 Epochs]    RMSE:0.40512,   MAE: 0.34344,  MAPE: 35.27%\n",
      "[600 Epochs]    RMSE:0.30204,   MAE: 0.26347,  MAPE: 26.97%\n",
      "[700 Epochs]    RMSE:0.25461,   MAE: 0.23325,  MAPE: 23.29%\n",
      "[800 Epochs]    RMSE:0.10000,   MAE: 0.07611,  MAPE: 7.69%\n",
      "[900 Epochs]    RMSE:0.12785,   MAE: 0.10782,  MAPE: 10.83%\n",
      "[1000 Epochs]    RMSE:0.09367,   MAE: 0.06499,  MAPE: 6.34%\n",
      "[1100 Epochs]    RMSE:0.11236,   MAE: 0.08786,  MAPE: 8.70%\n",
      "[1200 Epochs]    RMSE:0.09709,   MAE: 0.07039,  MAPE: 7.11%\n",
      "[1300 Epochs]    RMSE:0.10352,   MAE: 0.07753,  MAPE: 7.82%\n",
      "[1400 Epochs]    RMSE:0.16219,   MAE: 0.12992,  MAPE: 12.15%\n",
      "[1500 Epochs]    RMSE:0.10375,   MAE: 0.07710,  MAPE: 6.97%\n",
      "[1600 Epochs]    RMSE:0.08944,   MAE: 0.06519,  MAPE: 6.47%\n",
      "[1700 Epochs]    RMSE:0.09782,   MAE: 0.07501,  MAPE: 7.64%\n",
      "[1800 Epochs]    RMSE:0.10534,   MAE: 0.07717,  MAPE: 7.17%\n",
      "[1900 Epochs]    RMSE:0.12541,   MAE: 0.10141,  MAPE: 9.01%\n",
      "[2000 Epochs]    RMSE:0.18230,   MAE: 0.14466,  MAPE: 14.02%\n",
      "[2100 Epochs]    RMSE:0.10318,   MAE: 0.07640,  MAPE: 7.83%\n",
      "[2200 Epochs]    RMSE:0.10076,   MAE: 0.07042,  MAPE: 6.90%\n",
      "[2300 Epochs]    RMSE:0.10786,   MAE: 0.08513,  MAPE: 8.48%\n",
      "[2400 Epochs]    RMSE:0.15179,   MAE: 0.12300,  MAPE: 11.29%\n",
      "[2500 Epochs]    RMSE:0.14526,   MAE: 0.11970,  MAPE: 10.64%\n",
      "[2600 Epochs]    RMSE:0.09061,   MAE: 0.06558,  MAPE: 6.49%\n",
      "[2700 Epochs]    RMSE:0.14393,   MAE: 0.11616,  MAPE: 10.39%\n",
      "[2800 Epochs]    RMSE:0.10304,   MAE: 0.06885,  MAPE: 6.70%\n",
      "[2900 Epochs]    RMSE:0.13656,   MAE: 0.10643,  MAPE: 9.66%\n",
      "[3000 Epochs]    RMSE:0.14199,   MAE: 0.12513,  MAPE: 12.53%\n",
      "[3100 Epochs]    RMSE:0.08766,   MAE: 0.06230,  MAPE: 6.13%\n",
      "[3200 Epochs]    RMSE:0.15053,   MAE: 0.12620,  MAPE: 11.15%\n",
      "[3300 Epochs]    RMSE:0.13190,   MAE: 0.10835,  MAPE: 10.15%\n",
      "[3400 Epochs]    RMSE:0.13809,   MAE: 0.12145,  MAPE: 11.84%\n",
      "[3500 Epochs]    RMSE:0.12176,   MAE: 0.09392,  MAPE: 8.30%\n",
      "[3600 Epochs]    RMSE:0.09056,   MAE: 0.06822,  MAPE: 6.65%\n",
      "[3700 Epochs]    RMSE:0.09192,   MAE: 0.06770,  MAPE: 6.43%\n",
      "[3800 Epochs]    RMSE:0.24115,   MAE: 0.22943,  MAPE: 22.23%\n",
      "[3900 Epochs]    RMSE:0.12895,   MAE: 0.10464,  MAPE: 10.38%\n",
      "[4000 Epochs]    RMSE:0.12037,   MAE: 0.09551,  MAPE: 9.45%\n",
      "[4100 Epochs]    RMSE:0.12495,   MAE: 0.09325,  MAPE: 8.76%\n",
      "[4200 Epochs]    RMSE:0.12631,   MAE: 0.09293,  MAPE: 8.62%\n",
      "[4300 Epochs]    RMSE:0.12967,   MAE: 0.09700,  MAPE: 8.94%\n",
      "[4400 Epochs]    RMSE:0.11202,   MAE: 0.08719,  MAPE: 8.55%\n",
      "[4500 Epochs]    RMSE:0.11589,   MAE: 0.08424,  MAPE: 7.91%\n",
      "[4600 Epochs]    RMSE:0.13202,   MAE: 0.09802,  MAPE: 8.85%\n",
      "[4700 Epochs]    RMSE:0.11251,   MAE: 0.08650,  MAPE: 8.40%\n",
      "[4800 Epochs]    RMSE:0.11111,   MAE: 0.08532,  MAPE: 8.38%\n",
      "[4900 Epochs]    RMSE:0.12251,   MAE: 0.09882,  MAPE: 10.19%\n",
      "\n",
      "[Final Epochs]    RMSE:0.11894,   MAE: 0.08356,  MAPE: 7.72%\n",
      "\n",
      "\n",
      "Trial No.21\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 40\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:133.61965,   MAE: 133.56392,  MAPE: 12558.39%\n",
      "[100 Epochs]    RMSE:0.71210,   MAE: 0.58288,  MAPE: 59.03%\n",
      "[200 Epochs]    RMSE:0.91948,   MAE: 0.83955,  MAPE: 85.72%\n",
      "[300 Epochs]    RMSE:0.62582,   MAE: 0.54867,  MAPE: 58.00%\n",
      "[400 Epochs]    RMSE:0.24777,   MAE: 0.19498,  MAPE: 21.56%\n",
      "[500 Epochs]    RMSE:0.21112,   MAE: 0.17840,  MAPE: 18.72%\n",
      "[600 Epochs]    RMSE:0.16368,   MAE: 0.12793,  MAPE: 11.16%\n",
      "[700 Epochs]    RMSE:0.19519,   MAE: 0.16339,  MAPE: 13.98%\n",
      "[800 Epochs]    RMSE:0.12748,   MAE: 0.10594,  MAPE: 10.84%\n",
      "[900 Epochs]    RMSE:0.12581,   MAE: 0.10392,  MAPE: 10.46%\n",
      "[1000 Epochs]    RMSE:0.12938,   MAE: 0.10780,  MAPE: 10.94%\n",
      "[1100 Epochs]    RMSE:0.15031,   MAE: 0.12337,  MAPE: 13.16%\n",
      "[1200 Epochs]    RMSE:0.11964,   MAE: 0.09930,  MAPE: 10.20%\n",
      "[1300 Epochs]    RMSE:0.11034,   MAE: 0.08888,  MAPE: 8.95%\n",
      "[1400 Epochs]    RMSE:0.15337,   MAE: 0.13188,  MAPE: 13.45%\n",
      "[1500 Epochs]    RMSE:0.11227,   MAE: 0.08465,  MAPE: 7.70%\n",
      "[1600 Epochs]    RMSE:0.10349,   MAE: 0.07913,  MAPE: 7.82%\n",
      "[1700 Epochs]    RMSE:0.18472,   MAE: 0.16845,  MAPE: 16.73%\n",
      "[1800 Epochs]    RMSE:0.09785,   MAE: 0.07260,  MAPE: 6.81%\n",
      "[1900 Epochs]    RMSE:0.09513,   MAE: 0.07011,  MAPE: 6.72%\n",
      "[2000 Epochs]    RMSE:0.10200,   MAE: 0.07753,  MAPE: 7.30%\n",
      "[2100 Epochs]    RMSE:0.09727,   MAE: 0.07251,  MAPE: 7.03%\n",
      "[2200 Epochs]    RMSE:0.13492,   MAE: 0.10709,  MAPE: 11.57%\n",
      "[2300 Epochs]    RMSE:0.31562,   MAE: 0.27395,  MAPE: 22.69%\n",
      "[2400 Epochs]    RMSE:0.16345,   MAE: 0.13638,  MAPE: 14.28%\n",
      "[2500 Epochs]    RMSE:0.18336,   MAE: 0.15430,  MAPE: 16.25%\n",
      "[2600 Epochs]    RMSE:0.13480,   MAE: 0.10615,  MAPE: 9.31%\n",
      "[2700 Epochs]    RMSE:0.11347,   MAE: 0.09168,  MAPE: 9.13%\n",
      "[2800 Epochs]    RMSE:0.10963,   MAE: 0.08524,  MAPE: 8.10%\n",
      "[2900 Epochs]    RMSE:0.13128,   MAE: 0.10286,  MAPE: 9.07%\n",
      "[3000 Epochs]    RMSE:0.12397,   MAE: 0.09830,  MAPE: 10.07%\n",
      "[3100 Epochs]    RMSE:0.11015,   MAE: 0.08380,  MAPE: 7.83%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3200 Epochs]    RMSE:0.11471,   MAE: 0.09235,  MAPE: 8.52%\n",
      "[3300 Epochs]    RMSE:0.10861,   MAE: 0.08167,  MAPE: 7.77%\n",
      "[3400 Epochs]    RMSE:0.10549,   MAE: 0.08151,  MAPE: 8.21%\n",
      "[3500 Epochs]    RMSE:0.13150,   MAE: 0.10522,  MAPE: 9.18%\n",
      "[3600 Epochs]    RMSE:0.10936,   MAE: 0.08467,  MAPE: 8.50%\n",
      "[3700 Epochs]    RMSE:0.12920,   MAE: 0.10699,  MAPE: 10.79%\n",
      "[3800 Epochs]    RMSE:0.13066,   MAE: 0.10351,  MAPE: 10.67%\n",
      "[3900 Epochs]    RMSE:0.12460,   MAE: 0.09921,  MAPE: 10.57%\n",
      "[4000 Epochs]    RMSE:0.15827,   MAE: 0.12567,  MAPE: 11.48%\n",
      "[4100 Epochs]    RMSE:0.12983,   MAE: 0.10060,  MAPE: 9.11%\n",
      "[4200 Epochs]    RMSE:0.11443,   MAE: 0.08694,  MAPE: 7.77%\n",
      "[4300 Epochs]    RMSE:0.10454,   MAE: 0.08008,  MAPE: 7.81%\n",
      "[4400 Epochs]    RMSE:0.35219,   MAE: 0.30514,  MAPE: 25.58%\n",
      "[4500 Epochs]    RMSE:0.17888,   MAE: 0.14076,  MAPE: 15.10%\n",
      "[4600 Epochs]    RMSE:0.16401,   MAE: 0.13953,  MAPE: 13.73%\n",
      "[4700 Epochs]    RMSE:0.15362,   MAE: 0.11180,  MAPE: 12.61%\n",
      "[4800 Epochs]    RMSE:0.13930,   MAE: 0.11017,  MAPE: 10.99%\n",
      "[4900 Epochs]    RMSE:0.14915,   MAE: 0.11368,  MAPE: 12.37%\n",
      "\n",
      "[Final Epochs]    RMSE:0.13449,   MAE: 0.10075,  MAPE: 9.74%\n",
      "\n",
      "\n",
      "Trial No.22\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 50\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:75.25125,   MAE: 75.16465,  MAPE: 7079.45%\n",
      "[100 Epochs]    RMSE:5.64835,   MAE: 5.28293,  MAPE: 525.32%\n",
      "[200 Epochs]    RMSE:3.98129,   MAE: 3.70431,  MAPE: 369.19%\n",
      "[300 Epochs]    RMSE:2.17559,   MAE: 1.96977,  MAPE: 197.95%\n",
      "[400 Epochs]    RMSE:1.52924,   MAE: 1.34558,  MAPE: 137.02%\n",
      "[500 Epochs]    RMSE:1.00624,   MAE: 0.86866,  MAPE: 89.22%\n",
      "[600 Epochs]    RMSE:0.78672,   MAE: 0.68893,  MAPE: 71.02%\n",
      "[700 Epochs]    RMSE:0.49814,   MAE: 0.42846,  MAPE: 44.99%\n",
      "[800 Epochs]    RMSE:0.31871,   MAE: 0.26447,  MAPE: 28.51%\n",
      "[900 Epochs]    RMSE:0.14476,   MAE: 0.11621,  MAPE: 12.41%\n",
      "[1000 Epochs]    RMSE:0.32156,   MAE: 0.27371,  MAPE: 29.14%\n",
      "[1100 Epochs]    RMSE:0.12221,   MAE: 0.09815,  MAPE: 10.08%\n",
      "[1200 Epochs]    RMSE:0.10541,   MAE: 0.07706,  MAPE: 7.51%\n",
      "[1300 Epochs]    RMSE:0.13659,   MAE: 0.10486,  MAPE: 9.38%\n",
      "[1400 Epochs]    RMSE:0.10277,   MAE: 0.07429,  MAPE: 7.34%\n",
      "[1500 Epochs]    RMSE:0.10247,   MAE: 0.07347,  MAPE: 7.49%\n",
      "[1600 Epochs]    RMSE:0.16844,   MAE: 0.14310,  MAPE: 12.55%\n",
      "[1700 Epochs]    RMSE:0.09991,   MAE: 0.06730,  MAPE: 6.89%\n",
      "[1800 Epochs]    RMSE:0.10801,   MAE: 0.07653,  MAPE: 7.26%\n",
      "[1900 Epochs]    RMSE:0.10010,   MAE: 0.06742,  MAPE: 6.56%\n",
      "[2000 Epochs]    RMSE:0.10157,   MAE: 0.07344,  MAPE: 7.73%\n",
      "[2100 Epochs]    RMSE:0.12096,   MAE: 0.09169,  MAPE: 8.54%\n",
      "[2200 Epochs]    RMSE:0.09514,   MAE: 0.06535,  MAPE: 6.70%\n",
      "[2300 Epochs]    RMSE:0.09469,   MAE: 0.06437,  MAPE: 6.45%\n",
      "[2400 Epochs]    RMSE:0.11634,   MAE: 0.09558,  MAPE: 9.66%\n",
      "[2500 Epochs]    RMSE:0.11032,   MAE: 0.08186,  MAPE: 8.11%\n",
      "[2600 Epochs]    RMSE:0.11479,   MAE: 0.09219,  MAPE: 9.13%\n",
      "[2700 Epochs]    RMSE:0.11595,   MAE: 0.09769,  MAPE: 10.08%\n",
      "[2800 Epochs]    RMSE:0.13574,   MAE: 0.10871,  MAPE: 9.98%\n",
      "[2900 Epochs]    RMSE:0.10242,   MAE: 0.07464,  MAPE: 8.15%\n",
      "[3000 Epochs]    RMSE:0.09398,   MAE: 0.06903,  MAPE: 7.55%\n",
      "[3100 Epochs]    RMSE:0.08459,   MAE: 0.06451,  MAPE: 6.67%\n",
      "[3200 Epochs]    RMSE:0.08002,   MAE: 0.05647,  MAPE: 5.71%\n",
      "[3300 Epochs]    RMSE:0.08823,   MAE: 0.06450,  MAPE: 6.67%\n",
      "[3400 Epochs]    RMSE:0.15043,   MAE: 0.12951,  MAPE: 13.40%\n",
      "[3500 Epochs]    RMSE:0.08005,   MAE: 0.05755,  MAPE: 5.68%\n",
      "[3600 Epochs]    RMSE:0.09451,   MAE: 0.06990,  MAPE: 7.16%\n",
      "[3700 Epochs]    RMSE:0.10446,   MAE: 0.07914,  MAPE: 7.66%\n",
      "[3800 Epochs]    RMSE:0.09475,   MAE: 0.06669,  MAPE: 6.81%\n",
      "[3900 Epochs]    RMSE:0.09893,   MAE: 0.06710,  MAPE: 6.86%\n",
      "[4000 Epochs]    RMSE:0.09472,   MAE: 0.07001,  MAPE: 6.79%\n",
      "[4100 Epochs]    RMSE:0.11917,   MAE: 0.09631,  MAPE: 9.98%\n",
      "[4200 Epochs]    RMSE:0.10550,   MAE: 0.08385,  MAPE: 8.67%\n",
      "[4300 Epochs]    RMSE:0.13949,   MAE: 0.11294,  MAPE: 11.94%\n",
      "[4400 Epochs]    RMSE:0.11847,   MAE: 0.09522,  MAPE: 9.93%\n",
      "[4500 Epochs]    RMSE:0.13363,   MAE: 0.10044,  MAPE: 9.35%\n",
      "[4600 Epochs]    RMSE:0.09180,   MAE: 0.07202,  MAPE: 7.32%\n",
      "[4700 Epochs]    RMSE:0.15359,   MAE: 0.12640,  MAPE: 13.28%\n",
      "[4800 Epochs]    RMSE:0.24270,   MAE: 0.20466,  MAPE: 21.49%\n",
      "[4900 Epochs]    RMSE:0.23895,   MAE: 0.20345,  MAPE: 20.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "\n",
      "\n",
      "Trial No.23\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 50\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:242.43393,   MAE: 242.40257,  MAPE: 22857.04%\n",
      "[100 Epochs]    RMSE:3.68342,   MAE: 3.58694,  MAPE: 330.67%\n",
      "[200 Epochs]    RMSE:0.87635,   MAE: 0.73436,  MAPE: 74.58%\n",
      "[300 Epochs]    RMSE:0.42311,   MAE: 0.34981,  MAPE: 35.15%\n",
      "[400 Epochs]    RMSE:0.27280,   MAE: 0.23454,  MAPE: 20.67%\n",
      "[500 Epochs]    RMSE:0.12724,   MAE: 0.10175,  MAPE: 9.64%\n",
      "[600 Epochs]    RMSE:0.10859,   MAE: 0.08233,  MAPE: 8.13%\n",
      "[700 Epochs]    RMSE:0.10804,   MAE: 0.08066,  MAPE: 7.96%\n",
      "[800 Epochs]    RMSE:0.16009,   MAE: 0.12704,  MAPE: 11.49%\n",
      "[900 Epochs]    RMSE:0.13683,   MAE: 0.10051,  MAPE: 9.19%\n",
      "[1000 Epochs]    RMSE:0.10917,   MAE: 0.08014,  MAPE: 8.08%\n",
      "[1100 Epochs]    RMSE:0.11213,   MAE: 0.07256,  MAPE: 6.87%\n",
      "[1200 Epochs]    RMSE:0.10979,   MAE: 0.08340,  MAPE: 8.41%\n",
      "[1300 Epochs]    RMSE:0.10803,   MAE: 0.07778,  MAPE: 7.80%\n",
      "[1400 Epochs]    RMSE:0.14167,   MAE: 0.12038,  MAPE: 11.86%\n",
      "[1500 Epochs]    RMSE:0.11213,   MAE: 0.08456,  MAPE: 8.58%\n",
      "[1600 Epochs]    RMSE:0.12120,   MAE: 0.09546,  MAPE: 9.27%\n",
      "[1700 Epochs]    RMSE:0.14818,   MAE: 0.11925,  MAPE: 12.30%\n",
      "[1800 Epochs]    RMSE:0.13680,   MAE: 0.09809,  MAPE: 9.14%\n",
      "[1900 Epochs]    RMSE:0.16021,   MAE: 0.13252,  MAPE: 13.61%\n",
      "[2000 Epochs]    RMSE:0.11556,   MAE: 0.08067,  MAPE: 7.63%\n",
      "[2100 Epochs]    RMSE:0.12809,   MAE: 0.09377,  MAPE: 9.83%\n",
      "[2200 Epochs]    RMSE:0.11589,   MAE: 0.08199,  MAPE: 8.15%\n",
      "[2300 Epochs]    RMSE:0.12535,   MAE: 0.08792,  MAPE: 8.25%\n",
      "[2400 Epochs]    RMSE:0.11704,   MAE: 0.08756,  MAPE: 8.96%\n",
      "[2500 Epochs]    RMSE:0.11019,   MAE: 0.07860,  MAPE: 7.86%\n",
      "[2600 Epochs]    RMSE:0.18560,   MAE: 0.15100,  MAPE: 15.83%\n",
      "[2700 Epochs]    RMSE:0.16398,   MAE: 0.12902,  MAPE: 13.55%\n",
      "[2800 Epochs]    RMSE:0.16032,   MAE: 0.13182,  MAPE: 12.85%\n",
      "[2900 Epochs]    RMSE:0.14656,   MAE: 0.10656,  MAPE: 11.76%\n",
      "[3000 Epochs]    RMSE:0.13510,   MAE: 0.09814,  MAPE: 10.77%\n",
      "[3100 Epochs]    RMSE:0.12520,   MAE: 0.09041,  MAPE: 9.72%\n",
      "[3200 Epochs]    RMSE:0.12304,   MAE: 0.09138,  MAPE: 9.68%\n",
      "[3300 Epochs]    RMSE:0.11697,   MAE: 0.08571,  MAPE: 8.85%\n",
      "[3400 Epochs]    RMSE:0.11561,   MAE: 0.08347,  MAPE: 8.50%\n",
      "[3500 Epochs]    RMSE:0.12102,   MAE: 0.09032,  MAPE: 9.33%\n",
      "[3600 Epochs]    RMSE:0.11888,   MAE: 0.08751,  MAPE: 8.85%\n",
      "[3700 Epochs]    RMSE:0.11940,   MAE: 0.09023,  MAPE: 9.44%\n",
      "[3800 Epochs]    RMSE:0.11589,   MAE: 0.08491,  MAPE: 8.75%\n",
      "[3900 Epochs]    RMSE:0.11978,   MAE: 0.08590,  MAPE: 8.37%\n",
      "[4000 Epochs]    RMSE:0.11537,   MAE: 0.08176,  MAPE: 8.15%\n",
      "[4100 Epochs]    RMSE:0.11409,   MAE: 0.08081,  MAPE: 8.14%\n",
      "[4200 Epochs]    RMSE:0.11384,   MAE: 0.08045,  MAPE: 8.13%\n",
      "[4300 Epochs]    RMSE:0.11513,   MAE: 0.08186,  MAPE: 8.10%\n",
      "[4400 Epochs]    RMSE:0.11658,   MAE: 0.08632,  MAPE: 9.05%\n",
      "[4500 Epochs]    RMSE:0.11296,   MAE: 0.08044,  MAPE: 8.18%\n",
      "[4600 Epochs]    RMSE:0.11214,   MAE: 0.07970,  MAPE: 8.05%\n",
      "[4700 Epochs]    RMSE:0.11911,   MAE: 0.08959,  MAPE: 9.21%\n",
      "[4800 Epochs]    RMSE:0.13546,   MAE: 0.10698,  MAPE: 11.60%\n",
      "[4900 Epochs]    RMSE:0.11207,   MAE: 0.07917,  MAPE: 7.84%\n",
      "\n",
      "[Final Epochs]    RMSE:0.11081,   MAE: 0.08065,  MAPE: 8.27%\n",
      "\n",
      "\n",
      "Trial No.24\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 50\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:215.01861,   MAE: 214.72699,  MAPE: 20082.02%\n",
      "[100 Epochs]    RMSE:1.77904,   MAE: 1.51574,  MAPE: 127.05%\n",
      "[200 Epochs]    RMSE:1.49078,   MAE: 1.37872,  MAPE: 126.31%\n",
      "[300 Epochs]    RMSE:0.53836,   MAE: 0.46387,  MAPE: 40.38%\n",
      "[400 Epochs]    RMSE:0.24975,   MAE: 0.22051,  MAPE: 19.51%\n",
      "[500 Epochs]    RMSE:0.08740,   MAE: 0.06769,  MAPE: 6.69%\n",
      "[600 Epochs]    RMSE:0.07671,   MAE: 0.06050,  MAPE: 6.11%\n",
      "[700 Epochs]    RMSE:0.08813,   MAE: 0.05956,  MAPE: 6.33%\n",
      "[800 Epochs]    RMSE:0.12568,   MAE: 0.09418,  MAPE: 8.70%\n",
      "[900 Epochs]    RMSE:0.08296,   MAE: 0.06002,  MAPE: 5.81%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1000 Epochs]    RMSE:0.08760,   MAE: 0.06568,  MAPE: 6.17%\n",
      "[1100 Epochs]    RMSE:0.09238,   MAE: 0.07193,  MAPE: 6.50%\n",
      "[1200 Epochs]    RMSE:0.10180,   MAE: 0.07995,  MAPE: 7.87%\n",
      "[1300 Epochs]    RMSE:0.27613,   MAE: 0.20532,  MAPE: 18.63%\n",
      "[1400 Epochs]    RMSE:0.13737,   MAE: 0.11176,  MAPE: 11.21%\n",
      "[1500 Epochs]    RMSE:0.09411,   MAE: 0.06895,  MAPE: 6.97%\n",
      "[1600 Epochs]    RMSE:0.09847,   MAE: 0.07771,  MAPE: 7.82%\n",
      "[1700 Epochs]    RMSE:0.08885,   MAE: 0.06566,  MAPE: 6.91%\n",
      "[1800 Epochs]    RMSE:0.10694,   MAE: 0.08701,  MAPE: 8.32%\n",
      "[1900 Epochs]    RMSE:0.08808,   MAE: 0.06433,  MAPE: 6.41%\n",
      "[2000 Epochs]    RMSE:0.11006,   MAE: 0.08874,  MAPE: 8.45%\n",
      "[2100 Epochs]    RMSE:0.10213,   MAE: 0.07976,  MAPE: 7.94%\n",
      "[2200 Epochs]    RMSE:0.15663,   MAE: 0.13191,  MAPE: 11.34%\n",
      "[2300 Epochs]    RMSE:0.11582,   MAE: 0.09333,  MAPE: 9.10%\n",
      "[2400 Epochs]    RMSE:0.11171,   MAE: 0.08200,  MAPE: 8.50%\n",
      "[2500 Epochs]    RMSE:0.25041,   MAE: 0.22711,  MAPE: 23.44%\n",
      "[2600 Epochs]    RMSE:0.10748,   MAE: 0.08016,  MAPE: 7.88%\n",
      "[2700 Epochs]    RMSE:0.10949,   MAE: 0.07921,  MAPE: 7.61%\n",
      "[2800 Epochs]    RMSE:0.10871,   MAE: 0.07862,  MAPE: 7.60%\n",
      "[2900 Epochs]    RMSE:0.12275,   MAE: 0.09290,  MAPE: 8.55%\n",
      "[3000 Epochs]    RMSE:0.10967,   MAE: 0.07897,  MAPE: 7.61%\n",
      "[3100 Epochs]    RMSE:0.10721,   MAE: 0.07847,  MAPE: 7.78%\n",
      "[3200 Epochs]    RMSE:0.11215,   MAE: 0.08020,  MAPE: 7.67%\n",
      "[3300 Epochs]    RMSE:0.13254,   MAE: 0.10789,  MAPE: 11.38%\n",
      "[3400 Epochs]    RMSE:0.11844,   MAE: 0.08391,  MAPE: 7.84%\n",
      "[3500 Epochs]    RMSE:0.10833,   MAE: 0.07919,  MAPE: 7.85%\n",
      "[3600 Epochs]    RMSE:0.10802,   MAE: 0.07784,  MAPE: 7.65%\n",
      "[3700 Epochs]    RMSE:0.10977,   MAE: 0.08154,  MAPE: 8.39%\n",
      "[3800 Epochs]    RMSE:0.11788,   MAE: 0.08840,  MAPE: 8.36%\n",
      "[3900 Epochs]    RMSE:0.11963,   MAE: 0.09069,  MAPE: 8.59%\n",
      "[4000 Epochs]    RMSE:0.10888,   MAE: 0.07829,  MAPE: 7.74%\n",
      "[4100 Epochs]    RMSE:0.10986,   MAE: 0.07880,  MAPE: 7.72%\n",
      "[4200 Epochs]    RMSE:0.12568,   MAE: 0.09329,  MAPE: 8.55%\n",
      "[4300 Epochs]    RMSE:0.12234,   MAE: 0.09601,  MAPE: 10.11%\n",
      "[4400 Epochs]    RMSE:0.11346,   MAE: 0.08172,  MAPE: 7.81%\n",
      "[4500 Epochs]    RMSE:0.11018,   MAE: 0.07900,  MAPE: 7.68%\n",
      "[4600 Epochs]    RMSE:0.11113,   MAE: 0.08331,  MAPE: 8.73%\n",
      "[4700 Epochs]    RMSE:0.11250,   MAE: 0.08357,  MAPE: 8.30%\n",
      "[4800 Epochs]    RMSE:0.12449,   MAE: 0.09890,  MAPE: 10.06%\n",
      "[4900 Epochs]    RMSE:0.13465,   MAE: 0.09872,  MAPE: 9.04%\n",
      "\n",
      "[Final Epochs]    RMSE:0.13919,   MAE: 0.11585,  MAPE: 11.49%\n",
      "\n",
      "\n",
      "Trial No.25\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:233.39939,   MAE: 233.29785,  MAPE: 22014.24%\n",
      "[100 Epochs]    RMSE:3.36521,   MAE: 3.35777,  MAPE: 312.36%\n",
      "[200 Epochs]    RMSE:1.42131,   MAE: 1.40837,  MAPE: 136.94%\n",
      "[300 Epochs]    RMSE:0.19440,   MAE: 0.16590,  MAPE: 15.80%\n",
      "[400 Epochs]    RMSE:0.16175,   MAE: 0.13232,  MAPE: 11.76%\n",
      "[500 Epochs]    RMSE:0.18250,   MAE: 0.15385,  MAPE: 16.27%\n",
      "[600 Epochs]    RMSE:0.16308,   MAE: 0.12842,  MAPE: 11.00%\n",
      "[700 Epochs]    RMSE:0.19694,   MAE: 0.17061,  MAPE: 17.79%\n",
      "[800 Epochs]    RMSE:0.14455,   MAE: 0.12121,  MAPE: 12.73%\n",
      "[900 Epochs]    RMSE:0.13487,   MAE: 0.11283,  MAPE: 11.82%\n",
      "[1000 Epochs]    RMSE:0.16731,   MAE: 0.14459,  MAPE: 15.02%\n",
      "[1100 Epochs]    RMSE:0.11719,   MAE: 0.09634,  MAPE: 9.94%\n",
      "[1200 Epochs]    RMSE:0.13196,   MAE: 0.11030,  MAPE: 11.66%\n",
      "[1300 Epochs]    RMSE:0.11055,   MAE: 0.08590,  MAPE: 8.22%\n",
      "[1400 Epochs]    RMSE:0.17594,   MAE: 0.14337,  MAPE: 12.49%\n",
      "[1500 Epochs]    RMSE:0.15495,   MAE: 0.12233,  MAPE: 10.66%\n",
      "[1600 Epochs]    RMSE:0.14693,   MAE: 0.11389,  MAPE: 10.00%\n",
      "[1700 Epochs]    RMSE:0.11705,   MAE: 0.08679,  MAPE: 7.90%\n",
      "[1800 Epochs]    RMSE:0.10276,   MAE: 0.07681,  MAPE: 7.45%\n",
      "[1900 Epochs]    RMSE:0.10736,   MAE: 0.07919,  MAPE: 7.43%\n",
      "[2000 Epochs]    RMSE:0.10771,   MAE: 0.08541,  MAPE: 8.77%\n",
      "[2100 Epochs]    RMSE:0.10091,   MAE: 0.07600,  MAPE: 7.37%\n",
      "[2200 Epochs]    RMSE:0.10768,   MAE: 0.08030,  MAPE: 7.46%\n",
      "[2300 Epochs]    RMSE:0.09797,   MAE: 0.07337,  MAPE: 7.38%\n",
      "[2400 Epochs]    RMSE:0.15266,   MAE: 0.12267,  MAPE: 10.73%\n",
      "[2500 Epochs]    RMSE:0.11012,   MAE: 0.08087,  MAPE: 7.38%\n",
      "[2600 Epochs]    RMSE:0.13227,   MAE: 0.10185,  MAPE: 9.02%\n",
      "[2700 Epochs]    RMSE:0.12801,   MAE: 0.09981,  MAPE: 8.79%\n",
      "[2800 Epochs]    RMSE:0.11483,   MAE: 0.08356,  MAPE: 7.55%\n",
      "[2900 Epochs]    RMSE:0.12448,   MAE: 0.10528,  MAPE: 10.74%\n",
      "[3000 Epochs]    RMSE:0.10618,   MAE: 0.08512,  MAPE: 8.79%\n",
      "[3100 Epochs]    RMSE:0.16193,   MAE: 0.13598,  MAPE: 11.78%\n",
      "[3200 Epochs]    RMSE:0.12472,   MAE: 0.09109,  MAPE: 8.21%\n",
      "[3300 Epochs]    RMSE:0.12959,   MAE: 0.09921,  MAPE: 8.85%\n",
      "[3400 Epochs]    RMSE:0.10657,   MAE: 0.07852,  MAPE: 7.84%\n",
      "[3500 Epochs]    RMSE:0.10619,   MAE: 0.07663,  MAPE: 7.82%\n",
      "[3600 Epochs]    RMSE:0.11582,   MAE: 0.08239,  MAPE: 7.67%\n",
      "[3700 Epochs]    RMSE:0.11544,   MAE: 0.08067,  MAPE: 7.48%\n",
      "[3800 Epochs]    RMSE:0.10185,   MAE: 0.07507,  MAPE: 7.64%\n",
      "[3900 Epochs]    RMSE:0.10434,   MAE: 0.07200,  MAPE: 6.79%\n",
      "[4000 Epochs]    RMSE:0.12287,   MAE: 0.09277,  MAPE: 8.24%\n",
      "[4100 Epochs]    RMSE:0.11000,   MAE: 0.08055,  MAPE: 7.24%\n",
      "[4200 Epochs]    RMSE:0.10230,   MAE: 0.07158,  MAPE: 6.54%\n",
      "[4300 Epochs]    RMSE:0.09101,   MAE: 0.06289,  MAPE: 6.01%\n",
      "[4400 Epochs]    RMSE:0.12032,   MAE: 0.10184,  MAPE: 10.55%\n",
      "[4500 Epochs]    RMSE:0.23134,   MAE: 0.19617,  MAPE: 19.38%\n",
      "[4600 Epochs]    RMSE:0.23796,   MAE: 0.20201,  MAPE: 18.88%\n",
      "[4700 Epochs]    RMSE:0.22718,   MAE: 0.18782,  MAPE: 20.22%\n",
      "[4800 Epochs]    RMSE:0.35964,   MAE: 0.30958,  MAPE: 25.68%\n",
      "[4900 Epochs]    RMSE:0.20843,   MAE: 0.17810,  MAPE: 16.55%\n",
      "\n",
      "[Final Epochs]    RMSE:0.20252,   MAE: 0.17160,  MAPE: 17.76%\n",
      "\n",
      "\n",
      "Trial No.26\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:204.72378,   MAE: 204.69475,  MAPE: 19311.19%\n",
      "[100 Epochs]    RMSE:2.17988,   MAE: 2.08474,  MAPE: 190.35%\n",
      "[200 Epochs]    RMSE:0.53337,   MAE: 0.50639,  MAPE: 47.79%\n",
      "[300 Epochs]    RMSE:0.38851,   MAE: 0.30831,  MAPE: 32.25%\n",
      "[400 Epochs]    RMSE:0.14128,   MAE: 0.11767,  MAPE: 10.75%\n",
      "[500 Epochs]    RMSE:0.09072,   MAE: 0.06612,  MAPE: 6.40%\n",
      "[600 Epochs]    RMSE:0.14371,   MAE: 0.12348,  MAPE: 10.92%\n",
      "[700 Epochs]    RMSE:0.09206,   MAE: 0.06567,  MAPE: 6.49%\n",
      "[800 Epochs]    RMSE:0.18452,   MAE: 0.14156,  MAPE: 13.13%\n",
      "[900 Epochs]    RMSE:0.13413,   MAE: 0.11281,  MAPE: 11.38%\n",
      "[1000 Epochs]    RMSE:0.10432,   MAE: 0.06823,  MAPE: 6.58%\n",
      "[1100 Epochs]    RMSE:0.11632,   MAE: 0.07809,  MAPE: 7.21%\n",
      "[1200 Epochs]    RMSE:0.11280,   MAE: 0.07667,  MAPE: 7.04%\n",
      "[1300 Epochs]    RMSE:0.09724,   MAE: 0.06857,  MAPE: 6.61%\n",
      "[1400 Epochs]    RMSE:0.12179,   MAE: 0.10269,  MAPE: 10.75%\n",
      "[1500 Epochs]    RMSE:0.20407,   MAE: 0.17126,  MAPE: 17.80%\n",
      "[1600 Epochs]    RMSE:0.11976,   MAE: 0.09185,  MAPE: 9.66%\n",
      "[1700 Epochs]    RMSE:0.16234,   MAE: 0.13216,  MAPE: 13.39%\n",
      "[1800 Epochs]    RMSE:0.10108,   MAE: 0.07278,  MAPE: 7.92%\n",
      "[1900 Epochs]    RMSE:0.09818,   MAE: 0.07336,  MAPE: 8.07%\n",
      "[2000 Epochs]    RMSE:0.10047,   MAE: 0.07406,  MAPE: 7.91%\n",
      "[2100 Epochs]    RMSE:0.15438,   MAE: 0.12428,  MAPE: 11.95%\n",
      "[2200 Epochs]    RMSE:0.13380,   MAE: 0.10194,  MAPE: 10.73%\n",
      "[2300 Epochs]    RMSE:0.12689,   MAE: 0.09828,  MAPE: 10.01%\n",
      "[2400 Epochs]    RMSE:0.12922,   MAE: 0.09248,  MAPE: 9.05%\n",
      "[2500 Epochs]    RMSE:0.45059,   MAE: 0.40709,  MAPE: 34.38%\n",
      "[2600 Epochs]    RMSE:0.22462,   MAE: 0.19579,  MAPE: 18.67%\n",
      "[2700 Epochs]    RMSE:0.19161,   MAE: 0.13887,  MAPE: 15.54%\n",
      "[2800 Epochs]    RMSE:0.16919,   MAE: 0.12210,  MAPE: 13.25%\n",
      "[2900 Epochs]    RMSE:0.15509,   MAE: 0.11777,  MAPE: 12.02%\n",
      "[3000 Epochs]    RMSE:0.14702,   MAE: 0.10921,  MAPE: 11.58%\n",
      "[3100 Epochs]    RMSE:0.14156,   MAE: 0.10635,  MAPE: 10.89%\n",
      "[3200 Epochs]    RMSE:0.17412,   MAE: 0.13724,  MAPE: 14.88%\n",
      "[3300 Epochs]    RMSE:0.13499,   MAE: 0.10144,  MAPE: 10.57%\n",
      "[3400 Epochs]    RMSE:0.13126,   MAE: 0.09835,  MAPE: 10.10%\n",
      "[3500 Epochs]    RMSE:0.13014,   MAE: 0.09680,  MAPE: 9.72%\n",
      "[3600 Epochs]    RMSE:0.12971,   MAE: 0.09601,  MAPE: 9.51%\n",
      "[3700 Epochs]    RMSE:0.29680,   MAE: 0.25810,  MAPE: 21.55%\n",
      "[3800 Epochs]    RMSE:0.13960,   MAE: 0.10377,  MAPE: 9.89%\n",
      "[3900 Epochs]    RMSE:0.12329,   MAE: 0.09225,  MAPE: 9.15%\n",
      "[4000 Epochs]    RMSE:0.12746,   MAE: 0.09801,  MAPE: 10.16%\n",
      "[4100 Epochs]    RMSE:0.12657,   MAE: 0.09783,  MAPE: 10.11%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4200 Epochs]    RMSE:0.12731,   MAE: 0.09244,  MAPE: 8.90%\n",
      "[4300 Epochs]    RMSE:0.14273,   MAE: 0.10700,  MAPE: 9.85%\n",
      "[4400 Epochs]    RMSE:0.11749,   MAE: 0.09040,  MAPE: 9.23%\n",
      "[4500 Epochs]    RMSE:0.12023,   MAE: 0.09065,  MAPE: 8.68%\n",
      "[4600 Epochs]    RMSE:0.11711,   MAE: 0.08765,  MAPE: 8.45%\n",
      "[4700 Epochs]    RMSE:0.11640,   MAE: 0.08876,  MAPE: 8.93%\n",
      "[4800 Epochs]    RMSE:0.11235,   MAE: 0.08370,  MAPE: 8.43%\n",
      "[4900 Epochs]    RMSE:0.12983,   MAE: 0.10565,  MAPE: 9.73%\n",
      "\n",
      "[Final Epochs]    RMSE:0.12663,   MAE: 0.08846,  MAPE: 8.50%\n",
      "\n",
      "\n",
      "Trial No.27\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:223.87353,   MAE: 223.81018,  MAPE: 21042.70%\n",
      "[100 Epochs]    RMSE:1.50184,   MAE: 1.33022,  MAPE: 116.10%\n",
      "[200 Epochs]    RMSE:6.64049,   MAE: 6.62994,  MAPE: 631.77%\n",
      "[300 Epochs]    RMSE:0.38657,   MAE: 0.33860,  MAPE: 30.15%\n",
      "[400 Epochs]    RMSE:0.49222,   MAE: 0.45334,  MAPE: 47.08%\n",
      "[500 Epochs]    RMSE:0.21348,   MAE: 0.18153,  MAPE: 15.55%\n",
      "[600 Epochs]    RMSE:0.14328,   MAE: 0.11581,  MAPE: 10.18%\n",
      "[700 Epochs]    RMSE:0.14449,   MAE: 0.11813,  MAPE: 12.66%\n",
      "[800 Epochs]    RMSE:0.17880,   MAE: 0.15606,  MAPE: 15.96%\n",
      "[900 Epochs]    RMSE:0.10369,   MAE: 0.08155,  MAPE: 8.49%\n",
      "[1000 Epochs]    RMSE:0.14053,   MAE: 0.11598,  MAPE: 12.15%\n",
      "[1100 Epochs]    RMSE:0.45918,   MAE: 0.43043,  MAPE: 37.34%\n",
      "[1200 Epochs]    RMSE:0.13574,   MAE: 0.10742,  MAPE: 9.62%\n",
      "[1300 Epochs]    RMSE:0.14826,   MAE: 0.12549,  MAPE: 12.91%\n",
      "[1400 Epochs]    RMSE:0.10392,   MAE: 0.08225,  MAPE: 8.40%\n",
      "[1500 Epochs]    RMSE:0.12626,   MAE: 0.10451,  MAPE: 10.81%\n",
      "[1600 Epochs]    RMSE:0.10584,   MAE: 0.08319,  MAPE: 8.78%\n",
      "[1700 Epochs]    RMSE:0.10556,   MAE: 0.08439,  MAPE: 8.66%\n",
      "[1800 Epochs]    RMSE:0.11368,   MAE: 0.09181,  MAPE: 9.37%\n",
      "[1900 Epochs]    RMSE:0.21691,   MAE: 0.20440,  MAPE: 19.45%\n",
      "[2000 Epochs]    RMSE:0.12387,   MAE: 0.10402,  MAPE: 9.83%\n",
      "[2100 Epochs]    RMSE:0.10987,   MAE: 0.08752,  MAPE: 9.07%\n",
      "[2200 Epochs]    RMSE:0.11045,   MAE: 0.08755,  MAPE: 9.16%\n",
      "[2300 Epochs]    RMSE:0.13445,   MAE: 0.10473,  MAPE: 9.27%\n",
      "[2400 Epochs]    RMSE:0.11036,   MAE: 0.08597,  MAPE: 8.70%\n",
      "[2500 Epochs]    RMSE:0.10618,   MAE: 0.08021,  MAPE: 8.11%\n",
      "[2600 Epochs]    RMSE:0.10590,   MAE: 0.08088,  MAPE: 7.96%\n",
      "[2700 Epochs]    RMSE:0.09514,   MAE: 0.07307,  MAPE: 7.08%\n",
      "[2800 Epochs]    RMSE:0.11931,   MAE: 0.08885,  MAPE: 8.31%\n",
      "[2900 Epochs]    RMSE:0.08980,   MAE: 0.06500,  MAPE: 6.30%\n",
      "[3000 Epochs]    RMSE:0.09752,   MAE: 0.07656,  MAPE: 6.99%\n",
      "[3100 Epochs]    RMSE:0.09727,   MAE: 0.07424,  MAPE: 6.77%\n",
      "[3200 Epochs]    RMSE:0.10020,   MAE: 0.08035,  MAPE: 7.12%\n",
      "[3300 Epochs]    RMSE:0.10532,   MAE: 0.07781,  MAPE: 8.76%\n",
      "[3400 Epochs]    RMSE:0.12695,   MAE: 0.09912,  MAPE: 9.14%\n",
      "[3500 Epochs]    RMSE:0.09199,   MAE: 0.07674,  MAPE: 7.35%\n",
      "[3600 Epochs]    RMSE:0.09390,   MAE: 0.07577,  MAPE: 6.85%\n",
      "[3700 Epochs]    RMSE:0.08119,   MAE: 0.06244,  MAPE: 6.47%\n",
      "[3800 Epochs]    RMSE:0.08752,   MAE: 0.06819,  MAPE: 6.88%\n",
      "[3900 Epochs]    RMSE:0.07411,   MAE: 0.05561,  MAPE: 5.55%\n",
      "[4000 Epochs]    RMSE:0.07806,   MAE: 0.06100,  MAPE: 5.73%\n",
      "[4100 Epochs]    RMSE:0.10171,   MAE: 0.07799,  MAPE: 7.36%\n",
      "[4200 Epochs]    RMSE:0.11217,   MAE: 0.09249,  MAPE: 8.44%\n",
      "[4300 Epochs]    RMSE:0.07568,   MAE: 0.06060,  MAPE: 5.99%\n",
      "[4400 Epochs]    RMSE:0.15327,   MAE: 0.12373,  MAPE: 13.53%\n",
      "[4500 Epochs]    RMSE:0.11206,   MAE: 0.08698,  MAPE: 9.24%\n",
      "[4600 Epochs]    RMSE:0.11455,   MAE: 0.09560,  MAPE: 9.60%\n",
      "[4700 Epochs]    RMSE:0.09017,   MAE: 0.07019,  MAPE: 6.61%\n",
      "[4800 Epochs]    RMSE:0.10200,   MAE: 0.08382,  MAPE: 7.41%\n",
      "[4900 Epochs]    RMSE:0.25467,   MAE: 0.22839,  MAPE: 19.62%\n",
      "\n",
      "[Final Epochs]    RMSE:0.10459,   MAE: 0.09112,  MAPE: 8.32%\n",
      "\n",
      "\n",
      "Trial No.28\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:67.89205,   MAE: 67.49811,  MAPE: 6405.34%\n",
      "[100 Epochs]    RMSE:2.15233,   MAE: 1.82008,  MAPE: 171.91%\n",
      "[200 Epochs]    RMSE:2.83770,   MAE: 2.48794,  MAPE: 216.36%\n",
      "[300 Epochs]    RMSE:1.97135,   MAE: 1.70641,  MAPE: 173.99%\n",
      "[400 Epochs]    RMSE:0.65102,   MAE: 0.54872,  MAPE: 54.26%\n",
      "[500 Epochs]    RMSE:0.53374,   MAE: 0.45702,  MAPE: 41.95%\n",
      "[600 Epochs]    RMSE:1.05049,   MAE: 0.97486,  MAPE: 85.60%\n",
      "[700 Epochs]    RMSE:0.30103,   MAE: 0.26030,  MAPE: 23.91%\n",
      "[800 Epochs]    RMSE:0.40300,   MAE: 0.35486,  MAPE: 37.31%\n",
      "[900 Epochs]    RMSE:0.26055,   MAE: 0.22291,  MAPE: 19.10%\n",
      "[1000 Epochs]    RMSE:0.15515,   MAE: 0.12716,  MAPE: 13.50%\n",
      "[1100 Epochs]    RMSE:0.19228,   MAE: 0.15978,  MAPE: 13.89%\n",
      "[1200 Epochs]    RMSE:0.31476,   MAE: 0.28045,  MAPE: 23.58%\n",
      "[1300 Epochs]    RMSE:0.13194,   MAE: 0.10305,  MAPE: 9.25%\n",
      "[1400 Epochs]    RMSE:0.11464,   MAE: 0.09302,  MAPE: 9.00%\n",
      "[1500 Epochs]    RMSE:0.12550,   MAE: 0.10478,  MAPE: 10.66%\n",
      "[1600 Epochs]    RMSE:0.11298,   MAE: 0.08883,  MAPE: 8.54%\n",
      "[1700 Epochs]    RMSE:0.12686,   MAE: 0.10523,  MAPE: 10.84%\n",
      "[1800 Epochs]    RMSE:0.13360,   MAE: 0.10068,  MAPE: 9.08%\n",
      "[1900 Epochs]    RMSE:0.27674,   MAE: 0.23741,  MAPE: 24.21%\n",
      "[2000 Epochs]    RMSE:0.21953,   MAE: 0.16779,  MAPE: 18.99%\n",
      "[2100 Epochs]    RMSE:0.17430,   MAE: 0.14875,  MAPE: 14.93%\n",
      "[2200 Epochs]    RMSE:0.16728,   MAE: 0.14243,  MAPE: 12.97%\n",
      "[2300 Epochs]    RMSE:0.14140,   MAE: 0.11496,  MAPE: 10.83%\n",
      "[2400 Epochs]    RMSE:0.12494,   MAE: 0.09676,  MAPE: 9.42%\n",
      "[2500 Epochs]    RMSE:0.12124,   MAE: 0.09281,  MAPE: 9.00%\n",
      "[2600 Epochs]    RMSE:0.12490,   MAE: 0.09517,  MAPE: 9.05%\n",
      "[2700 Epochs]    RMSE:0.16254,   MAE: 0.13889,  MAPE: 14.45%\n",
      "[2800 Epochs]    RMSE:0.12232,   MAE: 0.09136,  MAPE: 8.68%\n",
      "[2900 Epochs]    RMSE:0.13698,   MAE: 0.10474,  MAPE: 9.50%\n",
      "[3000 Epochs]    RMSE:0.11446,   MAE: 0.08580,  MAPE: 8.25%\n",
      "[3100 Epochs]    RMSE:0.11590,   MAE: 0.09214,  MAPE: 9.56%\n",
      "[3200 Epochs]    RMSE:0.12734,   MAE: 0.09437,  MAPE: 8.60%\n",
      "[3300 Epochs]    RMSE:0.12825,   MAE: 0.10593,  MAPE: 10.89%\n",
      "[3400 Epochs]    RMSE:0.12361,   MAE: 0.10298,  MAPE: 10.47%\n",
      "[3500 Epochs]    RMSE:0.13590,   MAE: 0.10212,  MAPE: 9.08%\n",
      "[3600 Epochs]    RMSE:0.11220,   MAE: 0.08226,  MAPE: 7.79%\n",
      "[3700 Epochs]    RMSE:0.13483,   MAE: 0.11286,  MAPE: 11.61%\n",
      "[3800 Epochs]    RMSE:0.11626,   MAE: 0.08421,  MAPE: 7.81%\n",
      "[3900 Epochs]    RMSE:0.11266,   MAE: 0.08185,  MAPE: 7.69%\n",
      "[4000 Epochs]    RMSE:0.10626,   MAE: 0.08010,  MAPE: 8.06%\n",
      "[4100 Epochs]    RMSE:0.15164,   MAE: 0.13297,  MAPE: 13.36%\n",
      "[4200 Epochs]    RMSE:0.13843,   MAE: 0.10562,  MAPE: 9.26%\n",
      "[4300 Epochs]    RMSE:0.33556,   MAE: 0.29697,  MAPE: 24.90%\n",
      "[4400 Epochs]    RMSE:0.12980,   MAE: 0.09918,  MAPE: 8.83%\n",
      "[4500 Epochs]    RMSE:0.11258,   MAE: 0.08780,  MAPE: 8.64%\n",
      "[4600 Epochs]    RMSE:0.12378,   MAE: 0.09179,  MAPE: 8.19%\n",
      "[4700 Epochs]    RMSE:0.15343,   MAE: 0.12272,  MAPE: 10.64%\n",
      "[4800 Epochs]    RMSE:0.10628,   MAE: 0.08172,  MAPE: 7.97%\n",
      "[4900 Epochs]    RMSE:0.13376,   MAE: 0.09725,  MAPE: 8.72%\n",
      "\n",
      "[Final Epochs]    RMSE:0.11952,   MAE: 0.08425,  MAPE: 7.72%\n",
      "\n",
      "\n",
      "Trial No.29\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:172.96841,   MAE: 172.82164,  MAPE: 16190.77%\n",
      "[100 Epochs]    RMSE:5.10893,   MAE: 4.96124,  MAPE: 485.58%\n",
      "[200 Epochs]    RMSE:2.39233,   MAE: 2.19443,  MAPE: 223.28%\n",
      "[300 Epochs]    RMSE:2.40051,   MAE: 2.33716,  MAPE: 214.10%\n",
      "[400 Epochs]    RMSE:2.43430,   MAE: 2.40419,  MAPE: 228.87%\n",
      "[500 Epochs]    RMSE:0.23429,   MAE: 0.18777,  MAPE: 17.53%\n",
      "[600 Epochs]    RMSE:0.13459,   MAE: 0.10857,  MAPE: 9.70%\n",
      "[700 Epochs]    RMSE:0.18715,   MAE: 0.16456,  MAPE: 14.56%\n",
      "[800 Epochs]    RMSE:0.17342,   MAE: 0.13172,  MAPE: 12.67%\n",
      "[900 Epochs]    RMSE:0.11498,   MAE: 0.09192,  MAPE: 9.18%\n",
      "[1000 Epochs]    RMSE:0.10902,   MAE: 0.08637,  MAPE: 8.10%\n",
      "[1100 Epochs]    RMSE:0.10272,   MAE: 0.08209,  MAPE: 7.44%\n",
      "[1200 Epochs]    RMSE:0.09074,   MAE: 0.07110,  MAPE: 6.84%\n",
      "[1300 Epochs]    RMSE:0.16318,   MAE: 0.14100,  MAPE: 12.66%\n",
      "[1400 Epochs]    RMSE:0.09845,   MAE: 0.07492,  MAPE: 7.29%\n",
      "[1500 Epochs]    RMSE:0.25389,   MAE: 0.22669,  MAPE: 22.74%\n",
      "[1600 Epochs]    RMSE:0.09004,   MAE: 0.06993,  MAPE: 6.73%\n",
      "[1700 Epochs]    RMSE:0.30637,   MAE: 0.29119,  MAPE: 28.55%\n",
      "[1800 Epochs]    RMSE:0.16150,   MAE: 0.13558,  MAPE: 12.26%\n",
      "[1900 Epochs]    RMSE:0.12226,   MAE: 0.10096,  MAPE: 9.32%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2000 Epochs]    RMSE:0.25761,   MAE: 0.21957,  MAPE: 22.40%\n",
      "[2100 Epochs]    RMSE:0.09132,   MAE: 0.06970,  MAPE: 7.06%\n",
      "[2200 Epochs]    RMSE:0.14717,   MAE: 0.12723,  MAPE: 11.44%\n",
      "[2300 Epochs]    RMSE:0.08093,   MAE: 0.06153,  MAPE: 6.07%\n",
      "[2400 Epochs]    RMSE:0.25171,   MAE: 0.21631,  MAPE: 22.38%\n",
      "[2500 Epochs]    RMSE:0.11975,   MAE: 0.09213,  MAPE: 9.93%\n",
      "[2600 Epochs]    RMSE:0.13428,   MAE: 0.10516,  MAPE: 9.99%\n",
      "[2700 Epochs]    RMSE:0.11208,   MAE: 0.08750,  MAPE: 8.10%\n",
      "[2800 Epochs]    RMSE:0.24230,   MAE: 0.20102,  MAPE: 21.28%\n",
      "[2900 Epochs]    RMSE:0.12079,   MAE: 0.10008,  MAPE: 9.11%\n",
      "[3000 Epochs]    RMSE:0.13095,   MAE: 0.10041,  MAPE: 11.10%\n",
      "[3100 Epochs]    RMSE:0.13080,   MAE: 0.10616,  MAPE: 10.12%\n",
      "[3200 Epochs]    RMSE:0.12856,   MAE: 0.10444,  MAPE: 10.73%\n",
      "[3300 Epochs]    RMSE:0.11857,   MAE: 0.09009,  MAPE: 8.85%\n",
      "[3400 Epochs]    RMSE:0.11983,   MAE: 0.09224,  MAPE: 9.41%\n",
      "[3500 Epochs]    RMSE:2.53597,   MAE: 2.52433,  MAPE: 232.69%\n",
      "[3600 Epochs]    RMSE:0.26252,   MAE: 0.21772,  MAPE: 23.42%\n",
      "[3700 Epochs]    RMSE:0.24757,   MAE: 0.21127,  MAPE: 21.55%\n",
      "[3800 Epochs]    RMSE:0.25097,   MAE: 0.21144,  MAPE: 22.29%\n",
      "[3900 Epochs]    RMSE:0.25338,   MAE: 0.21521,  MAPE: 20.17%\n",
      "[4000 Epochs]    RMSE:0.24008,   MAE: 0.20432,  MAPE: 20.34%\n",
      "[4100 Epochs]    RMSE:0.23895,   MAE: 0.20353,  MAPE: 20.93%\n",
      "[4200 Epochs]    RMSE:0.23019,   MAE: 0.19513,  MAPE: 19.46%\n",
      "[4300 Epochs]    RMSE:0.23882,   MAE: 0.20350,  MAPE: 20.46%\n",
      "[4400 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4500 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4600 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4700 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4800 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4900 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "\n",
      "[Final Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "\n",
      "\n",
      "Trial No.30\n",
      "Prediction :thickness\n",
      "Learning rate : 0.005\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:333.67814,   MAE: 333.64453,  MAPE: 31430.76%\n",
      "[100 Epochs]    RMSE:3.50036,   MAE: 3.33688,  MAPE: 335.07%\n",
      "[200 Epochs]    RMSE:1.77165,   MAE: 1.69589,  MAPE: 167.14%\n",
      "[300 Epochs]    RMSE:0.46697,   MAE: 0.37542,  MAPE: 32.26%\n",
      "[400 Epochs]    RMSE:1.69287,   MAE: 1.66559,  MAPE: 154.24%\n",
      "[500 Epochs]    RMSE:0.44975,   MAE: 0.37011,  MAPE: 31.05%\n",
      "[600 Epochs]    RMSE:0.24222,   MAE: 0.19817,  MAPE: 21.62%\n",
      "[700 Epochs]    RMSE:0.21846,   MAE: 0.18744,  MAPE: 15.92%\n",
      "[800 Epochs]    RMSE:0.13583,   MAE: 0.11075,  MAPE: 10.11%\n",
      "[900 Epochs]    RMSE:0.18901,   MAE: 0.15031,  MAPE: 16.62%\n",
      "[1000 Epochs]    RMSE:0.14523,   MAE: 0.11159,  MAPE: 10.01%\n",
      "[1100 Epochs]    RMSE:0.12651,   MAE: 0.09399,  MAPE: 9.90%\n",
      "[1200 Epochs]    RMSE:0.10826,   MAE: 0.08185,  MAPE: 8.50%\n",
      "[1300 Epochs]    RMSE:0.16440,   MAE: 0.13480,  MAPE: 13.09%\n",
      "[1400 Epochs]    RMSE:0.14643,   MAE: 0.11704,  MAPE: 12.05%\n",
      "[1500 Epochs]    RMSE:0.16539,   MAE: 0.13873,  MAPE: 14.78%\n",
      "[1600 Epochs]    RMSE:0.14794,   MAE: 0.11708,  MAPE: 10.52%\n",
      "[1700 Epochs]    RMSE:0.15236,   MAE: 0.13255,  MAPE: 12.33%\n",
      "[1800 Epochs]    RMSE:0.16291,   MAE: 0.13265,  MAPE: 11.70%\n",
      "[1900 Epochs]    RMSE:0.18356,   MAE: 0.15261,  MAPE: 16.26%\n",
      "[2000 Epochs]    RMSE:0.11274,   MAE: 0.08095,  MAPE: 7.99%\n",
      "[2100 Epochs]    RMSE:0.11267,   MAE: 0.08458,  MAPE: 8.08%\n",
      "[2200 Epochs]    RMSE:0.14489,   MAE: 0.10516,  MAPE: 10.13%\n",
      "[2300 Epochs]    RMSE:0.14508,   MAE: 0.11595,  MAPE: 10.38%\n",
      "[2400 Epochs]    RMSE:0.15316,   MAE: 0.12886,  MAPE: 13.77%\n",
      "[2500 Epochs]    RMSE:0.10284,   MAE: 0.08147,  MAPE: 8.46%\n",
      "[2600 Epochs]    RMSE:0.13301,   MAE: 0.11357,  MAPE: 11.00%\n",
      "[2700 Epochs]    RMSE:0.11007,   MAE: 0.09211,  MAPE: 9.57%\n",
      "[2800 Epochs]    RMSE:0.08130,   MAE: 0.05811,  MAPE: 5.64%\n",
      "[2900 Epochs]    RMSE:0.09291,   MAE: 0.07218,  MAPE: 7.80%\n",
      "[3000 Epochs]    RMSE:0.13813,   MAE: 0.12292,  MAPE: 12.34%\n",
      "[3100 Epochs]    RMSE:0.13268,   MAE: 0.10659,  MAPE: 10.01%\n",
      "[3200 Epochs]    RMSE:0.12343,   MAE: 0.08886,  MAPE: 7.99%\n",
      "[3300 Epochs]    RMSE:0.13510,   MAE: 0.10366,  MAPE: 9.43%\n",
      "[3400 Epochs]    RMSE:0.10997,   MAE: 0.08618,  MAPE: 7.87%\n",
      "[3500 Epochs]    RMSE:0.17708,   MAE: 0.15034,  MAPE: 12.84%\n",
      "[3600 Epochs]    RMSE:0.11322,   MAE: 0.08344,  MAPE: 8.31%\n",
      "[3700 Epochs]    RMSE:0.16263,   MAE: 0.13097,  MAPE: 11.39%\n",
      "[3800 Epochs]    RMSE:0.29074,   MAE: 0.27389,  MAPE: 26.85%\n",
      "[3900 Epochs]    RMSE:0.11384,   MAE: 0.08088,  MAPE: 8.64%\n",
      "[4000 Epochs]    RMSE:0.11580,   MAE: 0.08424,  MAPE: 8.02%\n",
      "[4100 Epochs]    RMSE:0.15429,   MAE: 0.12652,  MAPE: 13.55%\n",
      "[4200 Epochs]    RMSE:0.10516,   MAE: 0.07075,  MAPE: 7.06%\n",
      "[4300 Epochs]    RMSE:0.11290,   MAE: 0.08779,  MAPE: 9.04%\n",
      "[4400 Epochs]    RMSE:0.11469,   MAE: 0.09147,  MAPE: 9.06%\n",
      "[4500 Epochs]    RMSE:0.10699,   MAE: 0.08176,  MAPE: 8.43%\n",
      "[4600 Epochs]    RMSE:0.09791,   MAE: 0.07284,  MAPE: 7.34%\n",
      "[4700 Epochs]    RMSE:0.12937,   MAE: 0.09236,  MAPE: 8.41%\n",
      "[4800 Epochs]    RMSE:0.10413,   MAE: 0.07252,  MAPE: 6.98%\n",
      "[4900 Epochs]    RMSE:0.10785,   MAE: 0.08348,  MAPE: 8.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.10637,   MAE: 0.06920,  MAPE: 6.61%\n",
      "\n",
      "\n",
      "Trial No.31\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 30\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:36.17249,   MAE: 35.90454,  MAPE: 3328.79%\n",
      "[100 Epochs]    RMSE:0.26466,   MAE: 0.21881,  MAPE: 23.39%\n",
      "[200 Epochs]    RMSE:1.17610,   MAE: 1.15732,  MAPE: 105.18%\n",
      "[300 Epochs]    RMSE:0.18438,   MAE: 0.15618,  MAPE: 14.60%\n",
      "[400 Epochs]    RMSE:0.18028,   MAE: 0.14735,  MAPE: 15.80%\n",
      "[500 Epochs]    RMSE:0.16664,   MAE: 0.13499,  MAPE: 11.68%\n",
      "[600 Epochs]    RMSE:6.80319,   MAE: 6.79283,  MAPE: 649.13%\n",
      "[700 Epochs]    RMSE:0.14424,   MAE: 0.12000,  MAPE: 12.63%\n",
      "[800 Epochs]    RMSE:0.13415,   MAE: 0.11260,  MAPE: 11.46%\n",
      "[900 Epochs]    RMSE:0.19340,   MAE: 0.16129,  MAPE: 13.69%\n",
      "[1000 Epochs]    RMSE:0.38516,   MAE: 0.36393,  MAPE: 36.79%\n",
      "[1100 Epochs]    RMSE:0.12106,   MAE: 0.09196,  MAPE: 8.54%\n",
      "[1200 Epochs]    RMSE:0.12224,   MAE: 0.10071,  MAPE: 9.76%\n",
      "[1300 Epochs]    RMSE:0.12861,   MAE: 0.10522,  MAPE: 10.92%\n",
      "[1400 Epochs]    RMSE:0.11840,   MAE: 0.09348,  MAPE: 9.47%\n",
      "[1500 Epochs]    RMSE:0.11376,   MAE: 0.08368,  MAPE: 7.95%\n",
      "[1600 Epochs]    RMSE:0.11326,   MAE: 0.08865,  MAPE: 8.71%\n",
      "[1700 Epochs]    RMSE:0.13522,   MAE: 0.09853,  MAPE: 8.86%\n",
      "[1800 Epochs]    RMSE:0.11631,   MAE: 0.08432,  MAPE: 7.92%\n",
      "[1900 Epochs]    RMSE:0.15648,   MAE: 0.12752,  MAPE: 13.51%\n",
      "[2000 Epochs]    RMSE:0.11603,   MAE: 0.08912,  MAPE: 9.12%\n",
      "[2100 Epochs]    RMSE:0.11397,   MAE: 0.08717,  MAPE: 8.80%\n",
      "[2200 Epochs]    RMSE:0.13402,   MAE: 0.10968,  MAPE: 11.24%\n",
      "[2300 Epochs]    RMSE:0.16786,   MAE: 0.13231,  MAPE: 11.58%\n",
      "[2400 Epochs]    RMSE:0.12019,   MAE: 0.08902,  MAPE: 8.22%\n",
      "[2500 Epochs]    RMSE:0.11829,   MAE: 0.09016,  MAPE: 9.38%\n",
      "[2600 Epochs]    RMSE:0.11143,   MAE: 0.08313,  MAPE: 8.40%\n",
      "[2700 Epochs]    RMSE:0.11070,   MAE: 0.08433,  MAPE: 8.50%\n",
      "[2800 Epochs]    RMSE:0.10984,   MAE: 0.07808,  MAPE: 7.66%\n",
      "[2900 Epochs]    RMSE:0.11571,   MAE: 0.08832,  MAPE: 9.21%\n",
      "[3000 Epochs]    RMSE:0.14459,   MAE: 0.11834,  MAPE: 12.26%\n",
      "[3100 Epochs]    RMSE:0.33059,   MAE: 0.25361,  MAPE: 28.94%\n",
      "[3200 Epochs]    RMSE:0.24615,   MAE: 0.20827,  MAPE: 21.05%\n",
      "[3300 Epochs]    RMSE:0.24074,   MAE: 0.20402,  MAPE: 20.66%\n",
      "[3400 Epochs]    RMSE:0.23824,   MAE: 0.20204,  MAPE: 20.42%\n",
      "[3500 Epochs]    RMSE:0.23661,   MAE: 0.20054,  MAPE: 20.57%\n",
      "[3600 Epochs]    RMSE:0.23521,   MAE: 0.19901,  MAPE: 20.56%\n",
      "[3700 Epochs]    RMSE:0.23267,   MAE: 0.19693,  MAPE: 20.29%\n",
      "[3800 Epochs]    RMSE:0.22876,   MAE: 0.19367,  MAPE: 19.77%\n",
      "[3900 Epochs]    RMSE:0.22177,   MAE: 0.18583,  MAPE: 19.46%\n",
      "[4000 Epochs]    RMSE:0.72379,   MAE: 0.70192,  MAPE: 70.38%\n",
      "[4100 Epochs]    RMSE:0.30273,   MAE: 0.27056,  MAPE: 28.27%\n",
      "[4200 Epochs]    RMSE:0.17303,   MAE: 0.15060,  MAPE: 14.44%\n",
      "[4300 Epochs]    RMSE:0.15278,   MAE: 0.12561,  MAPE: 11.23%\n",
      "[4400 Epochs]    RMSE:0.14660,   MAE: 0.11249,  MAPE: 10.05%\n",
      "[4500 Epochs]    RMSE:0.11323,   MAE: 0.08468,  MAPE: 8.56%\n",
      "[4600 Epochs]    RMSE:0.18662,   MAE: 0.15441,  MAPE: 13.52%\n",
      "[4700 Epochs]    RMSE:0.11226,   MAE: 0.08506,  MAPE: 8.62%\n",
      "[4800 Epochs]    RMSE:0.11155,   MAE: 0.08362,  MAPE: 8.45%\n",
      "[4900 Epochs]    RMSE:0.11881,   MAE: 0.08391,  MAPE: 7.89%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Final Epochs]    RMSE:0.11853,   MAE: 0.08235,  MAPE: 7.73%\n",
      "\n",
      "\n",
      "Trial No.32\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 30\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:132.56979,   MAE: 132.48756,  MAPE: 12457.24%\n",
      "[100 Epochs]    RMSE:0.25561,   MAE: 0.20375,  MAPE: 22.62%\n",
      "[200 Epochs]    RMSE:0.43036,   MAE: 0.38737,  MAPE: 40.44%\n",
      "[300 Epochs]    RMSE:0.22593,   MAE: 0.19327,  MAPE: 19.40%\n",
      "[400 Epochs]    RMSE:0.20471,   MAE: 0.17242,  MAPE: 16.84%\n",
      "[500 Epochs]    RMSE:0.17096,   MAE: 0.14413,  MAPE: 13.90%\n",
      "[600 Epochs]    RMSE:0.14148,   MAE: 0.11794,  MAPE: 11.78%\n",
      "[700 Epochs]    RMSE:0.14391,   MAE: 0.12055,  MAPE: 11.11%\n",
      "[800 Epochs]    RMSE:0.14409,   MAE: 0.11663,  MAPE: 10.36%\n",
      "[900 Epochs]    RMSE:0.16230,   MAE: 0.13697,  MAPE: 14.38%\n",
      "[1000 Epochs]    RMSE:0.14889,   MAE: 0.11808,  MAPE: 10.25%\n",
      "[1100 Epochs]    RMSE:0.15347,   MAE: 0.13068,  MAPE: 13.60%\n",
      "[1200 Epochs]    RMSE:0.11028,   MAE: 0.08758,  MAPE: 8.73%\n",
      "[1300 Epochs]    RMSE:0.15445,   MAE: 0.12631,  MAPE: 11.00%\n",
      "[1400 Epochs]    RMSE:0.17144,   MAE: 0.14101,  MAPE: 12.06%\n",
      "[1500 Epochs]    RMSE:0.17403,   MAE: 0.14110,  MAPE: 12.17%\n",
      "[1600 Epochs]    RMSE:0.23895,   MAE: 0.20345,  MAPE: 20.39%\n",
      "[1700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "\n",
      "[Final Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "\n",
      "\n",
      "Trial No.33\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 30\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:160.32942,   MAE: 160.23857,  MAPE: 15187.55%\n",
      "[100 Epochs]    RMSE:3.72913,   MAE: 3.71142,  MAPE: 347.48%\n",
      "[200 Epochs]    RMSE:0.23942,   MAE: 0.20581,  MAPE: 21.24%\n",
      "[300 Epochs]    RMSE:0.19870,   MAE: 0.16647,  MAPE: 14.35%\n",
      "[400 Epochs]    RMSE:0.11992,   MAE: 0.09310,  MAPE: 9.77%\n",
      "[500 Epochs]    RMSE:0.23191,   MAE: 0.19958,  MAPE: 21.09%\n",
      "[600 Epochs]    RMSE:0.14464,   MAE: 0.12489,  MAPE: 12.20%\n",
      "[700 Epochs]    RMSE:0.11930,   MAE: 0.09610,  MAPE: 8.85%\n",
      "[800 Epochs]    RMSE:0.31091,   MAE: 0.24256,  MAPE: 27.46%\n",
      "[900 Epochs]    RMSE:0.16025,   MAE: 0.13745,  MAPE: 13.66%\n",
      "[1000 Epochs]    RMSE:0.15345,   MAE: 0.12724,  MAPE: 13.46%\n",
      "[1100 Epochs]    RMSE:0.17886,   MAE: 0.14636,  MAPE: 12.31%\n",
      "[1200 Epochs]    RMSE:0.14133,   MAE: 0.11796,  MAPE: 12.35%\n",
      "[1300 Epochs]    RMSE:0.11108,   MAE: 0.08495,  MAPE: 8.09%\n",
      "[1400 Epochs]    RMSE:0.29106,   MAE: 0.26034,  MAPE: 21.98%\n",
      "[1500 Epochs]    RMSE:0.11939,   MAE: 0.09268,  MAPE: 9.45%\n",
      "[1600 Epochs]    RMSE:0.14363,   MAE: 0.10834,  MAPE: 9.71%\n",
      "[1700 Epochs]    RMSE:0.14594,   MAE: 0.12302,  MAPE: 12.57%\n",
      "[1800 Epochs]    RMSE:0.12100,   MAE: 0.09505,  MAPE: 10.05%\n",
      "[1900 Epochs]    RMSE:0.11203,   MAE: 0.08528,  MAPE: 8.60%\n",
      "[2000 Epochs]    RMSE:0.12279,   MAE: 0.08846,  MAPE: 8.21%\n",
      "[2100 Epochs]    RMSE:0.13331,   MAE: 0.09690,  MAPE: 8.81%\n",
      "[2200 Epochs]    RMSE:0.12969,   MAE: 0.10549,  MAPE: 10.81%\n",
      "[2300 Epochs]    RMSE:0.13141,   MAE: 0.09555,  MAPE: 8.71%\n",
      "[2400 Epochs]    RMSE:0.11065,   MAE: 0.08206,  MAPE: 8.14%\n",
      "[2500 Epochs]    RMSE:0.13709,   MAE: 0.11169,  MAPE: 11.86%\n",
      "[2600 Epochs]    RMSE:0.11561,   MAE: 0.08929,  MAPE: 9.10%\n",
      "[2700 Epochs]    RMSE:0.11020,   MAE: 0.08062,  MAPE: 8.01%\n",
      "[2800 Epochs]    RMSE:0.10991,   MAE: 0.08057,  MAPE: 8.08%\n",
      "[2900 Epochs]    RMSE:0.10986,   MAE: 0.08047,  MAPE: 8.06%\n",
      "[3000 Epochs]    RMSE:0.11888,   MAE: 0.08530,  MAPE: 8.06%\n",
      "[3100 Epochs]    RMSE:0.11067,   MAE: 0.08084,  MAPE: 8.05%\n",
      "[3200 Epochs]    RMSE:0.11217,   MAE: 0.08435,  MAPE: 8.65%\n",
      "[3300 Epochs]    RMSE:0.11275,   MAE: 0.08476,  MAPE: 8.62%\n",
      "[3400 Epochs]    RMSE:0.12200,   MAE: 0.08622,  MAPE: 8.07%\n",
      "[3500 Epochs]    RMSE:0.11060,   MAE: 0.08137,  MAPE: 8.27%\n",
      "[3600 Epochs]    RMSE:0.10944,   MAE: 0.07936,  MAPE: 8.03%\n",
      "[3700 Epochs]    RMSE:0.10934,   MAE: 0.07938,  MAPE: 8.03%\n",
      "[3800 Epochs]    RMSE:0.12089,   MAE: 0.09384,  MAPE: 9.83%\n",
      "[3900 Epochs]    RMSE:0.10962,   MAE: 0.07804,  MAPE: 7.81%\n",
      "[4000 Epochs]    RMSE:0.11090,   MAE: 0.07955,  MAPE: 7.98%\n",
      "[4100 Epochs]    RMSE:0.10920,   MAE: 0.07925,  MAPE: 8.12%\n",
      "[4200 Epochs]    RMSE:0.11082,   MAE: 0.08225,  MAPE: 8.48%\n",
      "[4300 Epochs]    RMSE:0.11884,   MAE: 0.09127,  MAPE: 9.57%\n",
      "[4400 Epochs]    RMSE:0.13416,   MAE: 0.10853,  MAPE: 11.36%\n",
      "[4500 Epochs]    RMSE:0.11068,   MAE: 0.08347,  MAPE: 8.60%\n",
      "[4600 Epochs]    RMSE:0.10625,   MAE: 0.07565,  MAPE: 7.52%\n",
      "[4700 Epochs]    RMSE:0.10655,   MAE: 0.07601,  MAPE: 7.49%\n",
      "[4800 Epochs]    RMSE:0.11163,   MAE: 0.08548,  MAPE: 8.92%\n",
      "[4900 Epochs]    RMSE:0.11256,   MAE: 0.07785,  MAPE: 7.54%\n",
      "\n",
      "[Final Epochs]    RMSE:0.10532,   MAE: 0.07211,  MAPE: 7.18%\n",
      "\n",
      "\n",
      "Trial No.34\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 40\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:80.10797,   MAE: 79.89249,  MAPE: 7468.88%\n",
      "[100 Epochs]    RMSE:1.39851,   MAE: 1.33634,  MAPE: 135.29%\n",
      "[200 Epochs]    RMSE:0.84413,   MAE: 0.80837,  MAPE: 81.97%\n",
      "[300 Epochs]    RMSE:0.19685,   MAE: 0.16129,  MAPE: 17.43%\n",
      "[400 Epochs]    RMSE:0.14605,   MAE: 0.12073,  MAPE: 12.07%\n",
      "[500 Epochs]    RMSE:0.18613,   MAE: 0.14876,  MAPE: 12.70%\n",
      "[600 Epochs]    RMSE:0.22000,   MAE: 0.18263,  MAPE: 15.65%\n",
      "[700 Epochs]    RMSE:0.16377,   MAE: 0.13809,  MAPE: 14.28%\n",
      "[800 Epochs]    RMSE:0.18581,   MAE: 0.15276,  MAPE: 13.08%\n",
      "[900 Epochs]    RMSE:0.18757,   MAE: 0.16002,  MAPE: 16.60%\n",
      "[1000 Epochs]    RMSE:0.12551,   MAE: 0.10010,  MAPE: 9.47%\n",
      "[1100 Epochs]    RMSE:0.13025,   MAE: 0.10123,  MAPE: 9.08%\n",
      "[1200 Epochs]    RMSE:0.11448,   MAE: 0.08954,  MAPE: 8.70%\n",
      "[1300 Epochs]    RMSE:0.12001,   MAE: 0.09277,  MAPE: 8.48%\n",
      "[1400 Epochs]    RMSE:0.11100,   MAE: 0.08385,  MAPE: 7.86%\n",
      "[1500 Epochs]    RMSE:0.48743,   MAE: 0.46318,  MAPE: 40.29%\n",
      "[1600 Epochs]    RMSE:0.12977,   MAE: 0.10615,  MAPE: 10.65%\n",
      "[1700 Epochs]    RMSE:0.11459,   MAE: 0.08949,  MAPE: 8.94%\n",
      "[1800 Epochs]    RMSE:0.11128,   MAE: 0.08164,  MAPE: 7.82%\n",
      "[1900 Epochs]    RMSE:0.13722,   MAE: 0.11226,  MAPE: 11.53%\n",
      "[2000 Epochs]    RMSE:0.12117,   MAE: 0.08611,  MAPE: 7.91%\n",
      "[2100 Epochs]    RMSE:0.11159,   MAE: 0.08432,  MAPE: 8.65%\n",
      "[2200 Epochs]    RMSE:0.11506,   MAE: 0.08318,  MAPE: 7.78%\n",
      "[2300 Epochs]    RMSE:0.13554,   MAE: 0.09875,  MAPE: 8.90%\n",
      "[2400 Epochs]    RMSE:0.11058,   MAE: 0.08246,  MAPE: 8.48%\n",
      "[2500 Epochs]    RMSE:0.11399,   MAE: 0.08450,  MAPE: 8.84%\n",
      "[2600 Epochs]    RMSE:0.11455,   MAE: 0.08592,  MAPE: 8.93%\n",
      "[2700 Epochs]    RMSE:0.12208,   MAE: 0.08238,  MAPE: 7.65%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2800 Epochs]    RMSE:0.11458,   MAE: 0.08052,  MAPE: 7.62%\n",
      "[2900 Epochs]    RMSE:0.10630,   MAE: 0.07543,  MAPE: 7.65%\n",
      "[3000 Epochs]    RMSE:0.10973,   MAE: 0.07306,  MAPE: 7.18%\n",
      "[3100 Epochs]    RMSE:0.11112,   MAE: 0.07449,  MAPE: 7.23%\n",
      "[3200 Epochs]    RMSE:0.11473,   MAE: 0.07970,  MAPE: 7.56%\n",
      "[3300 Epochs]    RMSE:0.11186,   MAE: 0.07338,  MAPE: 7.13%\n",
      "[3400 Epochs]    RMSE:0.10979,   MAE: 0.08106,  MAPE: 8.19%\n",
      "[3500 Epochs]    RMSE:0.11286,   MAE: 0.08343,  MAPE: 8.05%\n",
      "[3600 Epochs]    RMSE:0.11905,   MAE: 0.07986,  MAPE: 7.56%\n",
      "[3700 Epochs]    RMSE:0.12101,   MAE: 0.09058,  MAPE: 9.56%\n",
      "[3800 Epochs]    RMSE:0.12048,   MAE: 0.08170,  MAPE: 7.72%\n",
      "[3900 Epochs]    RMSE:0.11569,   MAE: 0.08631,  MAPE: 8.18%\n",
      "[4000 Epochs]    RMSE:0.10902,   MAE: 0.07191,  MAPE: 7.21%\n",
      "[4100 Epochs]    RMSE:0.10815,   MAE: 0.07232,  MAPE: 7.23%\n",
      "[4200 Epochs]    RMSE:0.11393,   MAE: 0.07768,  MAPE: 7.43%\n",
      "[4300 Epochs]    RMSE:0.12534,   MAE: 0.09806,  MAPE: 10.18%\n",
      "[4400 Epochs]    RMSE:0.11441,   MAE: 0.07458,  MAPE: 7.17%\n",
      "[4500 Epochs]    RMSE:0.13209,   MAE: 0.10673,  MAPE: 10.96%\n",
      "[4600 Epochs]    RMSE:0.12700,   MAE: 0.08697,  MAPE: 8.11%\n",
      "[4700 Epochs]    RMSE:0.11385,   MAE: 0.07678,  MAPE: 7.37%\n",
      "[4800 Epochs]    RMSE:0.11059,   MAE: 0.07804,  MAPE: 8.20%\n",
      "[4900 Epochs]    RMSE:0.11170,   MAE: 0.07924,  MAPE: 8.25%\n",
      "\n",
      "[Final Epochs]    RMSE:0.11677,   MAE: 0.08104,  MAPE: 7.61%\n",
      "\n",
      "\n",
      "Trial No.35\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 40\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:286.03618,   MAE: 286.00220,  MAPE: 26958.75%\n",
      "[100 Epochs]    RMSE:0.24258,   MAE: 0.20607,  MAPE: 21.28%\n",
      "[200 Epochs]    RMSE:0.21185,   MAE: 0.18140,  MAPE: 17.59%\n",
      "[300 Epochs]    RMSE:0.23940,   MAE: 0.18290,  MAPE: 20.51%\n",
      "[400 Epochs]    RMSE:0.26825,   MAE: 0.20831,  MAPE: 23.46%\n",
      "[500 Epochs]    RMSE:0.22995,   MAE: 0.18159,  MAPE: 20.21%\n",
      "[600 Epochs]    RMSE:0.17668,   MAE: 0.14059,  MAPE: 15.27%\n",
      "[700 Epochs]    RMSE:0.16403,   MAE: 0.14113,  MAPE: 13.36%\n",
      "[800 Epochs]    RMSE:0.14360,   MAE: 0.11926,  MAPE: 12.45%\n",
      "[900 Epochs]    RMSE:0.14666,   MAE: 0.11955,  MAPE: 12.75%\n",
      "[1000 Epochs]    RMSE:0.13346,   MAE: 0.10959,  MAPE: 11.58%\n",
      "[1100 Epochs]    RMSE:0.13600,   MAE: 0.11092,  MAPE: 11.85%\n",
      "[1200 Epochs]    RMSE:0.13289,   MAE: 0.10828,  MAPE: 11.52%\n",
      "[1300 Epochs]    RMSE:0.11835,   MAE: 0.09765,  MAPE: 9.88%\n",
      "[1400 Epochs]    RMSE:0.12759,   MAE: 0.10351,  MAPE: 11.00%\n",
      "[1500 Epochs]    RMSE:0.12512,   MAE: 0.10160,  MAPE: 10.70%\n",
      "[1600 Epochs]    RMSE:0.13341,   MAE: 0.10923,  MAPE: 11.49%\n",
      "[1700 Epochs]    RMSE:0.11550,   MAE: 0.09181,  MAPE: 9.28%\n",
      "[1800 Epochs]    RMSE:0.20249,   MAE: 0.17319,  MAPE: 14.85%\n",
      "[1900 Epochs]    RMSE:0.14944,   MAE: 0.11898,  MAPE: 10.41%\n",
      "[2000 Epochs]    RMSE:0.16248,   MAE: 0.13307,  MAPE: 11.42%\n",
      "[2100 Epochs]    RMSE:0.11539,   MAE: 0.08880,  MAPE: 8.29%\n",
      "[2200 Epochs]    RMSE:0.27758,   MAE: 0.23539,  MAPE: 21.49%\n",
      "[2300 Epochs]    RMSE:0.24911,   MAE: 0.20759,  MAPE: 22.25%\n",
      "[2400 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[2500 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[2600 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[2700 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[2800 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[2900 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3000 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3100 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3200 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3300 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3400 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3500 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3600 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3700 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3800 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3900 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4000 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4100 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4200 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4300 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4400 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4500 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4600 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4700 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4800 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4900 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "\n",
      "[Final Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "\n",
      "\n",
      "Trial No.36\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 40\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:219.54424,   MAE: 219.48848,  MAPE: 20672.33%\n",
      "[100 Epochs]    RMSE:0.52217,   MAE: 0.45688,  MAPE: 47.96%\n",
      "[200 Epochs]    RMSE:0.19584,   MAE: 0.16586,  MAPE: 15.49%\n",
      "[300 Epochs]    RMSE:0.14605,   MAE: 0.11930,  MAPE: 11.48%\n",
      "[400 Epochs]    RMSE:0.13236,   MAE: 0.11002,  MAPE: 11.25%\n",
      "[500 Epochs]    RMSE:0.13052,   MAE: 0.10368,  MAPE: 9.84%\n",
      "[600 Epochs]    RMSE:0.27718,   MAE: 0.23616,  MAPE: 21.04%\n",
      "[700 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[900 Epochs]    RMSE:0.23893,   MAE: 0.20345,  MAPE: 20.39%\n",
      "[1000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4000 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4200 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4400 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4500 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4600 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "\n",
      "[Final Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "\n",
      "\n",
      "Trial No.37\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 50\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:166.53944,   MAE: 166.50099,  MAPE: 15755.61%\n",
      "[100 Epochs]    RMSE:5.15677,   MAE: 5.14171,  MAPE: 490.29%\n",
      "[200 Epochs]    RMSE:0.30419,   MAE: 0.22602,  MAPE: 25.59%\n",
      "[300 Epochs]    RMSE:0.59387,   MAE: 0.56083,  MAPE: 48.54%\n",
      "[400 Epochs]    RMSE:0.19161,   MAE: 0.14292,  MAPE: 16.37%\n",
      "[500 Epochs]    RMSE:0.15967,   MAE: 0.13146,  MAPE: 11.67%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[600 Epochs]    RMSE:0.16698,   MAE: 0.14146,  MAPE: 14.81%\n",
      "[700 Epochs]    RMSE:0.12277,   MAE: 0.09459,  MAPE: 9.87%\n",
      "[800 Epochs]    RMSE:0.12605,   MAE: 0.09952,  MAPE: 10.48%\n",
      "[900 Epochs]    RMSE:0.11864,   MAE: 0.08835,  MAPE: 9.06%\n",
      "[1000 Epochs]    RMSE:0.11775,   MAE: 0.08686,  MAPE: 8.88%\n",
      "[1100 Epochs]    RMSE:0.14250,   MAE: 0.11412,  MAPE: 12.19%\n",
      "[1200 Epochs]    RMSE:0.12197,   MAE: 0.08671,  MAPE: 8.51%\n",
      "[1300 Epochs]    RMSE:0.11310,   MAE: 0.08231,  MAPE: 8.44%\n",
      "[1400 Epochs]    RMSE:0.12138,   MAE: 0.08217,  MAPE: 7.84%\n",
      "[1500 Epochs]    RMSE:0.11331,   MAE: 0.07634,  MAPE: 7.83%\n",
      "[1600 Epochs]    RMSE:0.11703,   MAE: 0.08372,  MAPE: 8.25%\n",
      "[1700 Epochs]    RMSE:0.11096,   MAE: 0.07646,  MAPE: 7.89%\n",
      "[1800 Epochs]    RMSE:0.11963,   MAE: 0.09085,  MAPE: 9.46%\n",
      "[1900 Epochs]    RMSE:0.12230,   MAE: 0.09476,  MAPE: 9.66%\n",
      "[2000 Epochs]    RMSE:0.19356,   MAE: 0.14195,  MAPE: 16.41%\n",
      "[2100 Epochs]    RMSE:0.63831,   MAE: 0.60220,  MAPE: 51.82%\n",
      "[2200 Epochs]    RMSE:0.46423,   MAE: 0.41450,  MAPE: 34.42%\n",
      "[2300 Epochs]    RMSE:0.14262,   MAE: 0.11040,  MAPE: 11.98%\n",
      "[2400 Epochs]    RMSE:0.14046,   MAE: 0.11507,  MAPE: 11.26%\n",
      "[2500 Epochs]    RMSE:0.13092,   MAE: 0.09329,  MAPE: 9.13%\n",
      "[2600 Epochs]    RMSE:0.17384,   MAE: 0.14150,  MAPE: 15.23%\n",
      "[2700 Epochs]    RMSE:0.12409,   MAE: 0.08570,  MAPE: 8.42%\n",
      "[2800 Epochs]    RMSE:0.11473,   MAE: 0.08419,  MAPE: 8.78%\n",
      "[2900 Epochs]    RMSE:0.13961,   MAE: 0.11260,  MAPE: 11.75%\n",
      "[3000 Epochs]    RMSE:0.12496,   MAE: 0.09657,  MAPE: 10.17%\n",
      "[3100 Epochs]    RMSE:0.11923,   MAE: 0.08501,  MAPE: 8.31%\n",
      "[3200 Epochs]    RMSE:0.11953,   MAE: 0.08574,  MAPE: 8.34%\n",
      "[3300 Epochs]    RMSE:0.13744,   MAE: 0.10499,  MAPE: 9.62%\n",
      "[3400 Epochs]    RMSE:0.11448,   MAE: 0.08445,  MAPE: 8.75%\n",
      "[3500 Epochs]    RMSE:0.13010,   MAE: 0.10340,  MAPE: 10.80%\n",
      "[3600 Epochs]    RMSE:0.14160,   MAE: 0.11671,  MAPE: 12.10%\n",
      "[3700 Epochs]    RMSE:0.11292,   MAE: 0.08302,  MAPE: 8.62%\n",
      "[3800 Epochs]    RMSE:0.11965,   MAE: 0.08608,  MAPE: 8.27%\n",
      "[3900 Epochs]    RMSE:0.11939,   MAE: 0.09163,  MAPE: 9.57%\n",
      "[4000 Epochs]    RMSE:0.11466,   MAE: 0.08567,  MAPE: 8.92%\n",
      "[4100 Epochs]    RMSE:0.13957,   MAE: 0.10728,  MAPE: 9.73%\n",
      "[4200 Epochs]    RMSE:0.11136,   MAE: 0.08083,  MAPE: 8.29%\n",
      "[4300 Epochs]    RMSE:0.12680,   MAE: 0.09302,  MAPE: 8.67%\n",
      "[4400 Epochs]    RMSE:0.14383,   MAE: 0.11073,  MAPE: 9.98%\n",
      "[4500 Epochs]    RMSE:0.11387,   MAE: 0.08530,  MAPE: 8.85%\n",
      "[4600 Epochs]    RMSE:0.11130,   MAE: 0.07956,  MAPE: 7.92%\n",
      "[4700 Epochs]    RMSE:0.11032,   MAE: 0.07944,  MAPE: 8.05%\n",
      "[4800 Epochs]    RMSE:0.11535,   MAE: 0.08709,  MAPE: 9.02%\n",
      "[4900 Epochs]    RMSE:0.11404,   MAE: 0.08564,  MAPE: 8.93%\n",
      "\n",
      "[Final Epochs]    RMSE:0.11379,   MAE: 0.08503,  MAPE: 8.76%\n",
      "\n",
      "\n",
      "Trial No.38\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 50\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:32.59113,   MAE: 32.37347,  MAPE: 3090.60%\n",
      "[100 Epochs]    RMSE:0.30651,   MAE: 0.25327,  MAPE: 23.23%\n",
      "[200 Epochs]    RMSE:0.16172,   MAE: 0.12315,  MAPE: 13.12%\n",
      "[300 Epochs]    RMSE:0.15425,   MAE: 0.11948,  MAPE: 11.90%\n",
      "[400 Epochs]    RMSE:0.16115,   MAE: 0.12123,  MAPE: 12.55%\n",
      "[500 Epochs]    RMSE:0.16123,   MAE: 0.12803,  MAPE: 13.22%\n",
      "[600 Epochs]    RMSE:0.16484,   MAE: 0.13820,  MAPE: 12.30%\n",
      "[700 Epochs]    RMSE:0.18720,   MAE: 0.14790,  MAPE: 13.33%\n",
      "[800 Epochs]    RMSE:0.12359,   MAE: 0.09249,  MAPE: 8.92%\n",
      "[900 Epochs]    RMSE:0.12543,   MAE: 0.09826,  MAPE: 9.13%\n",
      "[1000 Epochs]    RMSE:0.12519,   MAE: 0.09786,  MAPE: 10.64%\n",
      "[1100 Epochs]    RMSE:0.13032,   MAE: 0.10481,  MAPE: 9.45%\n",
      "[1200 Epochs]    RMSE:0.22889,   MAE: 0.19541,  MAPE: 17.96%\n",
      "[1300 Epochs]    RMSE:0.17352,   MAE: 0.13026,  MAPE: 14.38%\n",
      "[1400 Epochs]    RMSE:0.13794,   MAE: 0.10073,  MAPE: 10.65%\n",
      "[1500 Epochs]    RMSE:0.13325,   MAE: 0.09872,  MAPE: 10.51%\n",
      "[1600 Epochs]    RMSE:0.12579,   MAE: 0.09204,  MAPE: 9.43%\n",
      "[1700 Epochs]    RMSE:0.12280,   MAE: 0.09074,  MAPE: 9.27%\n",
      "[1800 Epochs]    RMSE:0.12287,   MAE: 0.09025,  MAPE: 8.93%\n",
      "[1900 Epochs]    RMSE:0.12760,   MAE: 0.09992,  MAPE: 10.26%\n",
      "[2000 Epochs]    RMSE:0.12112,   MAE: 0.09327,  MAPE: 9.52%\n",
      "[2100 Epochs]    RMSE:0.12748,   MAE: 0.09367,  MAPE: 8.84%\n",
      "[2200 Epochs]    RMSE:0.15361,   MAE: 0.12392,  MAPE: 11.04%\n",
      "[2300 Epochs]    RMSE:0.11633,   MAE: 0.08700,  MAPE: 8.68%\n",
      "[2400 Epochs]    RMSE:0.11974,   MAE: 0.09299,  MAPE: 9.35%\n",
      "[2500 Epochs]    RMSE:0.12825,   MAE: 0.10255,  MAPE: 10.57%\n",
      "[2600 Epochs]    RMSE:0.11603,   MAE: 0.08980,  MAPE: 9.13%\n",
      "[2700 Epochs]    RMSE:0.12506,   MAE: 0.09328,  MAPE: 8.66%\n",
      "[2800 Epochs]    RMSE:0.12470,   MAE: 0.09888,  MAPE: 10.36%\n",
      "[2900 Epochs]    RMSE:0.11560,   MAE: 0.08945,  MAPE: 9.25%\n",
      "[3000 Epochs]    RMSE:0.11457,   MAE: 0.08694,  MAPE: 8.46%\n",
      "[3100 Epochs]    RMSE:0.12003,   MAE: 0.08857,  MAPE: 8.27%\n",
      "[3200 Epochs]    RMSE:0.13366,   MAE: 0.10801,  MAPE: 11.22%\n",
      "[3300 Epochs]    RMSE:0.11801,   MAE: 0.09327,  MAPE: 9.58%\n",
      "[3400 Epochs]    RMSE:0.11802,   MAE: 0.09341,  MAPE: 9.52%\n",
      "[3500 Epochs]    RMSE:0.11531,   MAE: 0.09005,  MAPE: 9.06%\n",
      "[3600 Epochs]    RMSE:0.12133,   MAE: 0.09676,  MAPE: 9.91%\n",
      "[3700 Epochs]    RMSE:0.11635,   MAE: 0.08743,  MAPE: 8.19%\n",
      "[3800 Epochs]    RMSE:0.12231,   MAE: 0.09047,  MAPE: 8.37%\n",
      "[3900 Epochs]    RMSE:0.11892,   MAE: 0.09237,  MAPE: 8.77%\n",
      "[4000 Epochs]    RMSE:0.11823,   MAE: 0.09326,  MAPE: 9.65%\n",
      "[4100 Epochs]    RMSE:0.13612,   MAE: 0.10390,  MAPE: 9.28%\n",
      "[4200 Epochs]    RMSE:0.13537,   MAE: 0.09764,  MAPE: 8.96%\n",
      "[4300 Epochs]    RMSE:0.12131,   MAE: 0.08951,  MAPE: 8.27%\n",
      "[4400 Epochs]    RMSE:0.12023,   MAE: 0.08945,  MAPE: 8.28%\n",
      "[4500 Epochs]    RMSE:0.11732,   MAE: 0.08646,  MAPE: 8.05%\n",
      "[4600 Epochs]    RMSE:0.11340,   MAE: 0.08778,  MAPE: 8.94%\n",
      "[4700 Epochs]    RMSE:0.11112,   MAE: 0.08337,  MAPE: 8.20%\n",
      "[4800 Epochs]    RMSE:0.11470,   MAE: 0.08457,  MAPE: 7.96%\n",
      "[4900 Epochs]    RMSE:0.11105,   MAE: 0.08138,  MAPE: 7.82%\n",
      "\n",
      "[Final Epochs]    RMSE:0.11032,   MAE: 0.08310,  MAPE: 8.18%\n",
      "\n",
      "\n",
      "Trial No.39\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 50\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:459.93491,   MAE: 459.89621,  MAPE: 43427.96%\n",
      "[100 Epochs]    RMSE:0.34828,   MAE: 0.27455,  MAPE: 30.62%\n",
      "[200 Epochs]    RMSE:0.20800,   MAE: 0.18158,  MAPE: 17.99%\n",
      "[300 Epochs]    RMSE:0.29927,   MAE: 0.23548,  MAPE: 26.49%\n",
      "[400 Epochs]    RMSE:0.18268,   MAE: 0.15482,  MAPE: 16.26%\n",
      "[500 Epochs]    RMSE:0.24331,   MAE: 0.20637,  MAPE: 22.01%\n",
      "[600 Epochs]    RMSE:0.14018,   MAE: 0.11758,  MAPE: 10.69%\n",
      "[700 Epochs]    RMSE:0.20178,   MAE: 0.17088,  MAPE: 18.33%\n",
      "[800 Epochs]    RMSE:0.11183,   MAE: 0.08952,  MAPE: 9.28%\n",
      "[900 Epochs]    RMSE:0.16103,   MAE: 0.13118,  MAPE: 11.15%\n",
      "[1000 Epochs]    RMSE:0.11410,   MAE: 0.09265,  MAPE: 9.71%\n",
      "[1100 Epochs]    RMSE:0.16139,   MAE: 0.13103,  MAPE: 11.09%\n",
      "[1200 Epochs]    RMSE:0.14847,   MAE: 0.12402,  MAPE: 13.02%\n",
      "[1300 Epochs]    RMSE:0.12248,   MAE: 0.09570,  MAPE: 8.82%\n",
      "[1400 Epochs]    RMSE:0.12291,   MAE: 0.10208,  MAPE: 10.56%\n",
      "[1500 Epochs]    RMSE:0.11952,   MAE: 0.09773,  MAPE: 9.91%\n",
      "[1600 Epochs]    RMSE:0.13088,   MAE: 0.10878,  MAPE: 11.26%\n",
      "[1700 Epochs]    RMSE:0.11018,   MAE: 0.08418,  MAPE: 8.13%\n",
      "[1800 Epochs]    RMSE:0.13002,   MAE: 0.10697,  MAPE: 11.12%\n",
      "[1900 Epochs]    RMSE:0.11695,   MAE: 0.09270,  MAPE: 9.61%\n",
      "[2000 Epochs]    RMSE:0.10990,   MAE: 0.08415,  MAPE: 8.52%\n",
      "[2100 Epochs]    RMSE:0.12152,   MAE: 0.09734,  MAPE: 10.06%\n",
      "[2200 Epochs]    RMSE:0.13777,   MAE: 0.10543,  MAPE: 9.42%\n",
      "[2300 Epochs]    RMSE:0.10919,   MAE: 0.08271,  MAPE: 8.21%\n",
      "[2400 Epochs]    RMSE:0.11164,   MAE: 0.08472,  MAPE: 8.28%\n",
      "[2500 Epochs]    RMSE:0.12800,   MAE: 0.09417,  MAPE: 8.59%\n",
      "[2600 Epochs]    RMSE:0.16336,   MAE: 0.13043,  MAPE: 11.41%\n",
      "[2700 Epochs]    RMSE:0.11015,   MAE: 0.08313,  MAPE: 8.43%\n",
      "[2800 Epochs]    RMSE:0.16762,   MAE: 0.13658,  MAPE: 14.70%\n",
      "[2900 Epochs]    RMSE:0.13651,   MAE: 0.11053,  MAPE: 11.44%\n",
      "[3000 Epochs]    RMSE:0.57864,   MAE: 0.55243,  MAPE: 55.98%\n",
      "[3100 Epochs]    RMSE:0.15018,   MAE: 0.11679,  MAPE: 12.92%\n",
      "[3200 Epochs]    RMSE:0.14455,   MAE: 0.11579,  MAPE: 12.43%\n",
      "[3300 Epochs]    RMSE:0.12610,   MAE: 0.09860,  MAPE: 10.19%\n",
      "[3400 Epochs]    RMSE:0.11742,   MAE: 0.08712,  MAPE: 8.54%\n",
      "[3500 Epochs]    RMSE:0.11510,   MAE: 0.08494,  MAPE: 8.48%\n",
      "[3600 Epochs]    RMSE:0.11674,   MAE: 0.08804,  MAPE: 9.04%\n",
      "[3700 Epochs]    RMSE:0.13492,   MAE: 0.10775,  MAPE: 11.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3800 Epochs]    RMSE:0.11601,   MAE: 0.08720,  MAPE: 9.00%\n",
      "[3900 Epochs]    RMSE:0.13050,   MAE: 0.10078,  MAPE: 10.75%\n",
      "[4000 Epochs]    RMSE:0.13204,   MAE: 0.09141,  MAPE: 8.37%\n",
      "[4100 Epochs]    RMSE:0.11189,   MAE: 0.08256,  MAPE: 8.18%\n",
      "[4200 Epochs]    RMSE:0.11066,   MAE: 0.07620,  MAPE: 7.48%\n",
      "[4300 Epochs]    RMSE:0.11536,   MAE: 0.07726,  MAPE: 7.36%\n",
      "[4400 Epochs]    RMSE:0.10834,   MAE: 0.07484,  MAPE: 7.45%\n",
      "[4500 Epochs]    RMSE:0.12390,   MAE: 0.09763,  MAPE: 9.94%\n",
      "[4600 Epochs]    RMSE:0.25271,   MAE: 0.18677,  MAPE: 21.62%\n",
      "[4700 Epochs]    RMSE:0.13612,   MAE: 0.09844,  MAPE: 9.02%\n",
      "[4800 Epochs]    RMSE:0.11004,   MAE: 0.07859,  MAPE: 8.06%\n",
      "[4900 Epochs]    RMSE:0.11070,   MAE: 0.07326,  MAPE: 7.18%\n",
      "\n",
      "[Final Epochs]    RMSE:0.11122,   MAE: 0.08160,  MAPE: 8.27%\n",
      "\n",
      "\n",
      "Trial No.40\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:235.99493,   MAE: 235.78789,  MAPE: 22433.32%\n",
      "[100 Epochs]    RMSE:0.42344,   MAE: 0.36842,  MAPE: 30.43%\n",
      "[200 Epochs]    RMSE:0.23880,   MAE: 0.20351,  MAPE: 20.47%\n",
      "[300 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[400 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[500 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[600 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[700 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[800 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[900 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1000 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1100 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1200 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1300 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1400 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1500 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1600 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1700 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1800 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1900 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2000 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2100 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2200 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2300 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2400 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2500 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2600 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2700 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2800 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2900 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3000 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3100 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3200 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3300 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3400 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3500 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3600 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3700 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3800 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3900 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4000 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4100 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4200 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4300 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4400 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4500 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4600 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4700 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4800 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4900 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "\n",
      "[Final Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "\n",
      "\n",
      "Trial No.41\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:103.90797,   MAE: 103.81223,  MAPE: 9778.76%\n",
      "[100 Epochs]    RMSE:0.25578,   MAE: 0.21910,  MAPE: 19.47%\n",
      "[200 Epochs]    RMSE:0.18907,   MAE: 0.15526,  MAPE: 15.38%\n",
      "[300 Epochs]    RMSE:0.17631,   MAE: 0.14477,  MAPE: 14.23%\n",
      "[400 Epochs]    RMSE:0.16342,   MAE: 0.13457,  MAPE: 13.27%\n",
      "[500 Epochs]    RMSE:0.15136,   MAE: 0.12505,  MAPE: 12.37%\n",
      "[600 Epochs]    RMSE:0.13982,   MAE: 0.11416,  MAPE: 11.05%\n",
      "[700 Epochs]    RMSE:0.13449,   MAE: 0.11081,  MAPE: 10.82%\n",
      "[800 Epochs]    RMSE:0.17532,   MAE: 0.14021,  MAPE: 15.10%\n",
      "[900 Epochs]    RMSE:0.12877,   MAE: 0.10286,  MAPE: 10.63%\n",
      "[1000 Epochs]    RMSE:0.12165,   MAE: 0.09883,  MAPE: 9.83%\n",
      "[1100 Epochs]    RMSE:0.12085,   MAE: 0.09645,  MAPE: 9.13%\n",
      "[1200 Epochs]    RMSE:0.18565,   MAE: 0.15079,  MAPE: 13.34%\n",
      "[1300 Epochs]    RMSE:0.16879,   MAE: 0.13306,  MAPE: 11.81%\n",
      "[1400 Epochs]    RMSE:0.13873,   MAE: 0.10956,  MAPE: 9.81%\n",
      "[1500 Epochs]    RMSE:0.17268,   MAE: 0.14450,  MAPE: 15.20%\n",
      "[1600 Epochs]    RMSE:0.16868,   MAE: 0.13678,  MAPE: 12.03%\n",
      "[1700 Epochs]    RMSE:0.13944,   MAE: 0.11330,  MAPE: 9.90%\n",
      "[1800 Epochs]    RMSE:0.13641,   MAE: 0.10920,  MAPE: 9.58%\n",
      "[1900 Epochs]    RMSE:0.14653,   MAE: 0.11232,  MAPE: 10.07%\n",
      "[2000 Epochs]    RMSE:0.10695,   MAE: 0.08036,  MAPE: 7.77%\n",
      "[2100 Epochs]    RMSE:0.11911,   MAE: 0.09414,  MAPE: 9.84%\n",
      "[2200 Epochs]    RMSE:0.13921,   MAE: 0.10904,  MAPE: 9.89%\n",
      "[2300 Epochs]    RMSE:0.14282,   MAE: 0.11885,  MAPE: 12.28%\n",
      "[2400 Epochs]    RMSE:0.10402,   MAE: 0.07923,  MAPE: 7.69%\n",
      "[2500 Epochs]    RMSE:0.12131,   MAE: 0.09426,  MAPE: 8.47%\n",
      "[2600 Epochs]    RMSE:0.15754,   MAE: 0.13189,  MAPE: 13.71%\n",
      "[2700 Epochs]    RMSE:0.11719,   MAE: 0.08980,  MAPE: 8.17%\n",
      "[2800 Epochs]    RMSE:0.10445,   MAE: 0.08156,  MAPE: 7.72%\n",
      "[2900 Epochs]    RMSE:0.12502,   MAE: 0.10186,  MAPE: 8.94%\n",
      "[3000 Epochs]    RMSE:0.12092,   MAE: 0.09949,  MAPE: 9.83%\n",
      "[3100 Epochs]    RMSE:0.12732,   MAE: 0.10598,  MAPE: 10.88%\n",
      "[3200 Epochs]    RMSE:0.12340,   MAE: 0.10195,  MAPE: 10.10%\n",
      "[3300 Epochs]    RMSE:0.11706,   MAE: 0.09361,  MAPE: 8.86%\n",
      "[3400 Epochs]    RMSE:0.11446,   MAE: 0.09020,  MAPE: 8.41%\n",
      "[3500 Epochs]    RMSE:0.11313,   MAE: 0.08929,  MAPE: 8.48%\n",
      "[3600 Epochs]    RMSE:0.11363,   MAE: 0.08816,  MAPE: 8.24%\n",
      "[3700 Epochs]    RMSE:0.12089,   MAE: 0.09719,  MAPE: 9.78%\n",
      "[3800 Epochs]    RMSE:0.12352,   MAE: 0.09435,  MAPE: 8.61%\n",
      "[3900 Epochs]    RMSE:0.11721,   MAE: 0.09214,  MAPE: 9.23%\n",
      "[4000 Epochs]    RMSE:0.10988,   MAE: 0.08323,  MAPE: 8.04%\n",
      "[4100 Epochs]    RMSE:0.11106,   MAE: 0.08483,  MAPE: 8.23%\n",
      "[4200 Epochs]    RMSE:0.13794,   MAE: 0.11278,  MAPE: 9.91%\n",
      "[4300 Epochs]    RMSE:0.14176,   MAE: 0.10721,  MAPE: 9.52%\n",
      "[4400 Epochs]    RMSE:0.14371,   MAE: 0.10924,  MAPE: 9.67%\n",
      "[4500 Epochs]    RMSE:0.11476,   MAE: 0.08970,  MAPE: 8.73%\n",
      "[4600 Epochs]    RMSE:0.11956,   MAE: 0.09402,  MAPE: 9.35%\n",
      "[4700 Epochs]    RMSE:0.13468,   MAE: 0.10357,  MAPE: 9.17%\n",
      "[4800 Epochs]    RMSE:0.14313,   MAE: 0.10957,  MAPE: 9.71%\n",
      "[4900 Epochs]    RMSE:0.12184,   MAE: 0.09027,  MAPE: 8.31%\n",
      "\n",
      "[Final Epochs]    RMSE:0.13937,   MAE: 0.10755,  MAPE: 9.60%\n",
      "\n",
      "\n",
      "Trial No.42\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:13.96905,   MAE: 12.93886,  MAPE: 1209.94%\n",
      "[100 Epochs]    RMSE:0.27527,   MAE: 0.23145,  MAPE: 21.69%\n",
      "[200 Epochs]    RMSE:0.19118,   MAE: 0.16202,  MAPE: 15.90%\n",
      "[300 Epochs]    RMSE:0.18260,   MAE: 0.15288,  MAPE: 15.39%\n",
      "[400 Epochs]    RMSE:0.21146,   MAE: 0.17177,  MAPE: 14.69%\n",
      "[500 Epochs]    RMSE:0.16228,   MAE: 0.13652,  MAPE: 13.73%\n",
      "[600 Epochs]    RMSE:0.16740,   MAE: 0.13653,  MAPE: 12.12%\n",
      "[700 Epochs]    RMSE:0.17034,   MAE: 0.14277,  MAPE: 14.72%\n",
      "[800 Epochs]    RMSE:0.14687,   MAE: 0.11852,  MAPE: 10.57%\n",
      "[900 Epochs]    RMSE:0.16479,   MAE: 0.13836,  MAPE: 14.09%\n",
      "[1000 Epochs]    RMSE:0.12356,   MAE: 0.10126,  MAPE: 9.69%\n",
      "[1100 Epochs]    RMSE:0.12019,   MAE: 0.09934,  MAPE: 9.41%\n",
      "[1200 Epochs]    RMSE:0.11984,   MAE: 0.09474,  MAPE: 8.62%\n",
      "[1300 Epochs]    RMSE:0.13929,   MAE: 0.10817,  MAPE: 9.55%\n",
      "[1400 Epochs]    RMSE:0.11015,   MAE: 0.08824,  MAPE: 8.55%\n",
      "[1500 Epochs]    RMSE:0.11927,   MAE: 0.09772,  MAPE: 9.61%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1600 Epochs]    RMSE:0.11690,   MAE: 0.09051,  MAPE: 8.31%\n",
      "[1700 Epochs]    RMSE:0.20298,   MAE: 0.17207,  MAPE: 14.64%\n",
      "[1800 Epochs]    RMSE:0.12829,   MAE: 0.10404,  MAPE: 10.45%\n",
      "[1900 Epochs]    RMSE:0.16061,   MAE: 0.12439,  MAPE: 10.95%\n",
      "[2000 Epochs]    RMSE:0.13654,   MAE: 0.10220,  MAPE: 9.14%\n",
      "[2100 Epochs]    RMSE:0.12283,   MAE: 0.10077,  MAPE: 10.38%\n",
      "[2200 Epochs]    RMSE:0.12964,   MAE: 0.09708,  MAPE: 8.73%\n",
      "[2300 Epochs]    RMSE:0.13440,   MAE: 0.11076,  MAPE: 11.32%\n",
      "[2400 Epochs]    RMSE:0.11845,   MAE: 0.08821,  MAPE: 8.23%\n",
      "[2500 Epochs]    RMSE:0.11059,   MAE: 0.08859,  MAPE: 9.14%\n",
      "[2600 Epochs]    RMSE:0.11370,   MAE: 0.08413,  MAPE: 7.88%\n",
      "[2700 Epochs]    RMSE:0.12905,   MAE: 0.09990,  MAPE: 9.15%\n",
      "[2800 Epochs]    RMSE:0.10978,   MAE: 0.08455,  MAPE: 7.91%\n",
      "[2900 Epochs]    RMSE:0.10960,   MAE: 0.08699,  MAPE: 9.20%\n",
      "[3000 Epochs]    RMSE:0.13960,   MAE: 0.11696,  MAPE: 11.92%\n",
      "[3100 Epochs]    RMSE:0.16221,   MAE: 0.14115,  MAPE: 13.99%\n",
      "[3200 Epochs]    RMSE:0.11721,   MAE: 0.09063,  MAPE: 8.44%\n",
      "[3300 Epochs]    RMSE:0.12515,   MAE: 0.09269,  MAPE: 8.46%\n",
      "[3400 Epochs]    RMSE:0.11268,   MAE: 0.08897,  MAPE: 9.05%\n",
      "[3500 Epochs]    RMSE:0.11834,   MAE: 0.09143,  MAPE: 8.52%\n",
      "[3600 Epochs]    RMSE:0.11192,   MAE: 0.08625,  MAPE: 8.34%\n",
      "[3700 Epochs]    RMSE:0.10861,   MAE: 0.08212,  MAPE: 8.09%\n",
      "[3800 Epochs]    RMSE:0.10849,   MAE: 0.08173,  MAPE: 7.88%\n",
      "[3900 Epochs]    RMSE:0.12731,   MAE: 0.10231,  MAPE: 10.62%\n",
      "[4000 Epochs]    RMSE:0.12942,   MAE: 0.10492,  MAPE: 10.87%\n",
      "[4100 Epochs]    RMSE:0.11974,   MAE: 0.09588,  MAPE: 9.80%\n",
      "[4200 Epochs]    RMSE:0.10929,   MAE: 0.08377,  MAPE: 8.57%\n",
      "[4300 Epochs]    RMSE:0.13871,   MAE: 0.11370,  MAPE: 11.90%\n",
      "[4400 Epochs]    RMSE:0.10841,   MAE: 0.08152,  MAPE: 7.90%\n",
      "[4500 Epochs]    RMSE:0.12876,   MAE: 0.10316,  MAPE: 10.79%\n",
      "[4600 Epochs]    RMSE:0.13503,   MAE: 0.09632,  MAPE: 8.99%\n",
      "[4700 Epochs]    RMSE:0.12346,   MAE: 0.09857,  MAPE: 9.05%\n",
      "[4800 Epochs]    RMSE:0.14662,   MAE: 0.10946,  MAPE: 10.06%\n",
      "[4900 Epochs]    RMSE:0.10471,   MAE: 0.07718,  MAPE: 7.83%\n",
      "\n",
      "[Final Epochs]    RMSE:0.10293,   MAE: 0.07654,  MAPE: 7.99%\n",
      "\n",
      "\n",
      "Trial No.43\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 10\n",
      "[0 Epochs]    RMSE:170.80248,   MAE: 170.68925,  MAPE: 16064.72%\n",
      "[100 Epochs]    RMSE:1.21268,   MAE: 1.15299,  MAPE: 103.07%\n",
      "[200 Epochs]    RMSE:0.23206,   MAE: 0.19176,  MAPE: 17.33%\n",
      "[300 Epochs]    RMSE:0.16083,   MAE: 0.13311,  MAPE: 11.78%\n",
      "[400 Epochs]    RMSE:0.12418,   MAE: 0.09720,  MAPE: 9.48%\n",
      "[500 Epochs]    RMSE:0.11714,   MAE: 0.08523,  MAPE: 8.25%\n",
      "[600 Epochs]    RMSE:0.12288,   MAE: 0.08884,  MAPE: 8.36%\n",
      "[700 Epochs]    RMSE:0.26687,   MAE: 0.22648,  MAPE: 19.12%\n",
      "[800 Epochs]    RMSE:0.14032,   MAE: 0.11209,  MAPE: 11.32%\n",
      "[900 Epochs]    RMSE:0.13104,   MAE: 0.10152,  MAPE: 9.63%\n",
      "[1000 Epochs]    RMSE:0.21692,   MAE: 0.18618,  MAPE: 16.23%\n",
      "[1100 Epochs]    RMSE:0.15563,   MAE: 0.12542,  MAPE: 12.50%\n",
      "[1200 Epochs]    RMSE:0.14934,   MAE: 0.11957,  MAPE: 12.23%\n",
      "[1300 Epochs]    RMSE:0.14563,   MAE: 0.11713,  MAPE: 12.02%\n",
      "[1400 Epochs]    RMSE:0.15080,   MAE: 0.12278,  MAPE: 12.68%\n",
      "[1500 Epochs]    RMSE:0.13973,   MAE: 0.11175,  MAPE: 10.80%\n",
      "[1600 Epochs]    RMSE:0.13258,   MAE: 0.10473,  MAPE: 10.44%\n",
      "[1700 Epochs]    RMSE:0.13044,   MAE: 0.10271,  MAPE: 10.16%\n",
      "[1800 Epochs]    RMSE:0.13447,   MAE: 0.10847,  MAPE: 10.98%\n",
      "[1900 Epochs]    RMSE:0.15034,   MAE: 0.11871,  MAPE: 10.74%\n",
      "[2000 Epochs]    RMSE:0.12562,   MAE: 0.09809,  MAPE: 9.63%\n",
      "[2100 Epochs]    RMSE:0.12633,   MAE: 0.09738,  MAPE: 9.43%\n",
      "[2200 Epochs]    RMSE:0.12612,   MAE: 0.09609,  MAPE: 9.25%\n",
      "[2300 Epochs]    RMSE:0.12807,   MAE: 0.09404,  MAPE: 8.91%\n",
      "[2400 Epochs]    RMSE:0.12283,   MAE: 0.09275,  MAPE: 9.41%\n",
      "[2500 Epochs]    RMSE:0.11941,   MAE: 0.08855,  MAPE: 8.78%\n",
      "[2600 Epochs]    RMSE:0.11888,   MAE: 0.08874,  MAPE: 8.85%\n",
      "[2700 Epochs]    RMSE:0.15135,   MAE: 0.12334,  MAPE: 12.77%\n",
      "[2800 Epochs]    RMSE:0.11638,   MAE: 0.08858,  MAPE: 8.90%\n",
      "[2900 Epochs]    RMSE:0.12110,   MAE: 0.09320,  MAPE: 9.50%\n",
      "[3000 Epochs]    RMSE:0.11886,   MAE: 0.09187,  MAPE: 8.74%\n",
      "[3100 Epochs]    RMSE:0.15349,   MAE: 0.12363,  MAPE: 10.86%\n",
      "[3200 Epochs]    RMSE:0.11983,   MAE: 0.09363,  MAPE: 8.90%\n",
      "[3300 Epochs]    RMSE:0.14972,   MAE: 0.11494,  MAPE: 10.27%\n",
      "[3400 Epochs]    RMSE:0.16547,   MAE: 0.13940,  MAPE: 14.55%\n",
      "[3500 Epochs]    RMSE:0.12901,   MAE: 0.10432,  MAPE: 9.65%\n",
      "[3600 Epochs]    RMSE:0.14507,   MAE: 0.12009,  MAPE: 12.00%\n",
      "[3700 Epochs]    RMSE:0.11557,   MAE: 0.08856,  MAPE: 8.47%\n",
      "[3800 Epochs]    RMSE:0.12816,   MAE: 0.10435,  MAPE: 10.70%\n",
      "[3900 Epochs]    RMSE:0.19689,   MAE: 0.17430,  MAPE: 17.33%\n",
      "[4000 Epochs]    RMSE:0.17135,   MAE: 0.14629,  MAPE: 15.16%\n",
      "[4100 Epochs]    RMSE:0.11514,   MAE: 0.08960,  MAPE: 8.76%\n",
      "[4200 Epochs]    RMSE:0.14009,   MAE: 0.11570,  MAPE: 11.81%\n",
      "[4300 Epochs]    RMSE:0.12618,   MAE: 0.10286,  MAPE: 10.44%\n",
      "[4400 Epochs]    RMSE:0.12079,   MAE: 0.09254,  MAPE: 8.60%\n",
      "[4500 Epochs]    RMSE:0.20459,   MAE: 0.17541,  MAPE: 15.42%\n",
      "[4600 Epochs]    RMSE:0.13608,   MAE: 0.10930,  MAPE: 10.19%\n",
      "[4700 Epochs]    RMSE:0.12115,   MAE: 0.09492,  MAPE: 9.65%\n",
      "[4800 Epochs]    RMSE:0.12230,   MAE: 0.09628,  MAPE: 9.91%\n",
      "[4900 Epochs]    RMSE:0.11489,   MAE: 0.08668,  MAPE: 8.73%\n",
      "\n",
      "[Final Epochs]    RMSE:0.24854,   MAE: 0.21657,  MAPE: 19.06%\n",
      "\n",
      "\n",
      "Trial No.44\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 20\n",
      "[0 Epochs]    RMSE:128.84641,   MAE: 128.79991,  MAPE: 12161.60%\n",
      "[100 Epochs]    RMSE:0.22741,   MAE: 0.19062,  MAPE: 20.14%\n",
      "[200 Epochs]    RMSE:0.20362,   MAE: 0.17112,  MAPE: 17.84%\n",
      "[300 Epochs]    RMSE:0.18473,   MAE: 0.15127,  MAPE: 13.53%\n",
      "[400 Epochs]    RMSE:0.15469,   MAE: 0.12518,  MAPE: 13.36%\n",
      "[500 Epochs]    RMSE:0.14144,   MAE: 0.11490,  MAPE: 10.92%\n",
      "[600 Epochs]    RMSE:0.13712,   MAE: 0.10980,  MAPE: 10.17%\n",
      "[700 Epochs]    RMSE:0.15178,   MAE: 0.11922,  MAPE: 10.49%\n",
      "[800 Epochs]    RMSE:0.13871,   MAE: 0.11018,  MAPE: 9.97%\n",
      "[900 Epochs]    RMSE:0.11726,   MAE: 0.09398,  MAPE: 9.09%\n",
      "[1000 Epochs]    RMSE:0.17453,   MAE: 0.14948,  MAPE: 15.50%\n",
      "[1100 Epochs]    RMSE:0.15152,   MAE: 0.12810,  MAPE: 13.34%\n",
      "[1200 Epochs]    RMSE:0.11401,   MAE: 0.09067,  MAPE: 8.92%\n",
      "[1300 Epochs]    RMSE:0.12345,   MAE: 0.09440,  MAPE: 8.66%\n",
      "[1400 Epochs]    RMSE:0.12967,   MAE: 0.09811,  MAPE: 8.86%\n",
      "[1500 Epochs]    RMSE:0.11866,   MAE: 0.09229,  MAPE: 8.70%\n",
      "[1600 Epochs]    RMSE:0.15284,   MAE: 0.11815,  MAPE: 10.33%\n",
      "[1700 Epochs]    RMSE:0.12537,   MAE: 0.10152,  MAPE: 10.41%\n",
      "[1800 Epochs]    RMSE:0.11939,   MAE: 0.09452,  MAPE: 9.88%\n",
      "[1900 Epochs]    RMSE:0.10984,   MAE: 0.08351,  MAPE: 8.31%\n",
      "[2000 Epochs]    RMSE:0.11155,   MAE: 0.08646,  MAPE: 8.79%\n",
      "[2100 Epochs]    RMSE:0.12584,   MAE: 0.09130,  MAPE: 8.34%\n",
      "[2200 Epochs]    RMSE:0.11166,   MAE: 0.08459,  MAPE: 8.50%\n",
      "[2300 Epochs]    RMSE:0.11419,   MAE: 0.09027,  MAPE: 9.19%\n",
      "[2400 Epochs]    RMSE:0.11368,   MAE: 0.08410,  MAPE: 8.00%\n",
      "[2500 Epochs]    RMSE:0.12347,   MAE: 0.08963,  MAPE: 8.26%\n",
      "[2600 Epochs]    RMSE:0.14136,   MAE: 0.10546,  MAPE: 9.43%\n",
      "[2700 Epochs]    RMSE:0.10876,   MAE: 0.07968,  MAPE: 7.92%\n",
      "[2800 Epochs]    RMSE:0.12645,   MAE: 0.10110,  MAPE: 10.51%\n",
      "[2900 Epochs]    RMSE:0.12198,   MAE: 0.08629,  MAPE: 8.00%\n",
      "[3000 Epochs]    RMSE:0.13068,   MAE: 0.09268,  MAPE: 8.47%\n",
      "[3100 Epochs]    RMSE:0.10782,   MAE: 0.07788,  MAPE: 7.81%\n",
      "[3200 Epochs]    RMSE:0.11129,   MAE: 0.08407,  MAPE: 8.61%\n",
      "[3300 Epochs]    RMSE:0.10854,   MAE: 0.07705,  MAPE: 7.57%\n",
      "[3400 Epochs]    RMSE:0.11554,   MAE: 0.08072,  MAPE: 7.60%\n",
      "[3500 Epochs]    RMSE:0.10819,   MAE: 0.07578,  MAPE: 7.43%\n",
      "[3600 Epochs]    RMSE:0.12043,   MAE: 0.09461,  MAPE: 9.74%\n",
      "[3700 Epochs]    RMSE:0.12074,   MAE: 0.09527,  MAPE: 9.82%\n",
      "[3800 Epochs]    RMSE:0.10516,   MAE: 0.07380,  MAPE: 7.34%\n",
      "[3900 Epochs]    RMSE:0.10822,   MAE: 0.08083,  MAPE: 8.11%\n",
      "[4000 Epochs]    RMSE:0.15653,   MAE: 0.13646,  MAPE: 13.70%\n",
      "[4100 Epochs]    RMSE:0.10859,   MAE: 0.08303,  MAPE: 8.53%\n",
      "[4200 Epochs]    RMSE:0.11018,   MAE: 0.08017,  MAPE: 7.51%\n",
      "[4300 Epochs]    RMSE:0.11951,   MAE: 0.08435,  MAPE: 7.74%\n",
      "[4400 Epochs]    RMSE:0.11111,   MAE: 0.08538,  MAPE: 7.88%\n",
      "[4500 Epochs]    RMSE:0.46669,   MAE: 0.45218,  MAPE: 41.47%\n",
      "[4600 Epochs]    RMSE:0.24172,   MAE: 0.20440,  MAPE: 21.36%\n",
      "[4700 Epochs]    RMSE:0.23880,   MAE: 0.20351,  MAPE: 20.47%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4900 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.40%\n",
      "\n",
      "[Final Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.40%\n",
      "\n",
      "\n",
      "Trial No.45\n",
      "Prediction :thickness\n",
      "Learning rate : 0.01\n",
      "Hidden 1 neuron : 70\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:27.51127,   MAE: 27.32295,  MAPE: 2557.62%\n",
      "[100 Epochs]    RMSE:0.15347,   MAE: 0.11909,  MAPE: 12.26%\n",
      "[200 Epochs]    RMSE:0.14980,   MAE: 0.11805,  MAPE: 11.46%\n",
      "[300 Epochs]    RMSE:0.16405,   MAE: 0.13498,  MAPE: 12.38%\n",
      "[400 Epochs]    RMSE:0.15938,   MAE: 0.13067,  MAPE: 13.50%\n",
      "[500 Epochs]    RMSE:0.26217,   MAE: 0.22962,  MAPE: 23.69%\n",
      "[600 Epochs]    RMSE:0.23889,   MAE: 0.20382,  MAPE: 20.77%\n",
      "[700 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[800 Epochs]    RMSE:0.23895,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[900 Epochs]    RMSE:0.23893,   MAE: 0.20345,  MAPE: 20.39%\n",
      "[1000 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[1100 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[1200 Epochs]    RMSE:0.23893,   MAE: 0.20345,  MAPE: 20.39%\n",
      "[1300 Epochs]    RMSE:0.23894,   MAE: 0.20345,  MAPE: 20.39%\n",
      "[1400 Epochs]    RMSE:0.23895,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[1500 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[1600 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[1700 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[1800 Epochs]    RMSE:0.23895,   MAE: 0.20345,  MAPE: 20.39%\n",
      "[1900 Epochs]    RMSE:0.23886,   MAE: 0.20347,  MAPE: 20.43%\n",
      "[2000 Epochs]    RMSE:0.23898,   MAE: 0.20346,  MAPE: 20.37%\n",
      "[2100 Epochs]    RMSE:0.23899,   MAE: 0.20346,  MAPE: 20.37%\n",
      "[2200 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2300 Epochs]    RMSE:0.23901,   MAE: 0.20347,  MAPE: 20.36%\n",
      "[2400 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[2500 Epochs]    RMSE:0.23889,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[2600 Epochs]    RMSE:0.23883,   MAE: 0.20349,  MAPE: 20.45%\n",
      "[2700 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[2800 Epochs]    RMSE:0.23906,   MAE: 0.20349,  MAPE: 20.34%\n",
      "[2900 Epochs]    RMSE:0.23894,   MAE: 0.20345,  MAPE: 20.39%\n",
      "[3000 Epochs]    RMSE:0.23889,   MAE: 0.20346,  MAPE: 20.41%\n",
      "[3100 Epochs]    RMSE:0.23895,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3200 Epochs]    RMSE:0.23898,   MAE: 0.20345,  MAPE: 20.37%\n",
      "[3300 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[3400 Epochs]    RMSE:0.23888,   MAE: 0.20346,  MAPE: 20.42%\n",
      "[3500 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[3600 Epochs]    RMSE:0.23889,   MAE: 0.20346,  MAPE: 20.41%\n",
      "[3700 Epochs]    RMSE:0.23898,   MAE: 0.20346,  MAPE: 20.37%\n",
      "[3800 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[3900 Epochs]    RMSE:0.23892,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4000 Epochs]    RMSE:0.23900,   MAE: 0.20346,  MAPE: 20.37%\n",
      "[4100 Epochs]    RMSE:0.23885,   MAE: 0.20348,  MAPE: 20.43%\n",
      "[4200 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4300 Epochs]    RMSE:0.23905,   MAE: 0.20349,  MAPE: 20.35%\n",
      "[4400 Epochs]    RMSE:0.23896,   MAE: 0.20345,  MAPE: 20.38%\n",
      "[4500 Epochs]    RMSE:0.23899,   MAE: 0.20346,  MAPE: 20.37%\n",
      "[4600 Epochs]    RMSE:0.23891,   MAE: 0.20345,  MAPE: 20.40%\n",
      "[4700 Epochs]    RMSE:0.23877,   MAE: 0.20354,  MAPE: 20.49%\n",
      "[4800 Epochs]    RMSE:0.23890,   MAE: 0.20345,  MAPE: 20.41%\n",
      "[4900 Epochs]    RMSE:0.23889,   MAE: 0.20345,  MAPE: 20.41%\n",
      "\n",
      "[Final Epochs]    RMSE:0.23904,   MAE: 0.20348,  MAPE: 20.35%\n"
     ]
    }
   ],
   "source": [
    "for M in range(1):\n",
    "    \n",
    "    Tr_result_temp = np.zeros((len(Lr)*len(N1)*len(N2) , 7)) # *len(N2)\n",
    "    cnt = 0\n",
    "    \n",
    "#     exec('Label_Trn = TrainLabel_%d'%(M+1))\n",
    "    print('\\n\\n\\n\\n################## Model %d (Predict :'%(M+1) + Model[M] + ') ##################')\n",
    "\n",
    "    for i in range(len(Lr)):\n",
    "        learningRate = Lr[i]\n",
    "\n",
    "        for j in range(len(N1)):\n",
    "            noOfNeuron1 = N1[j]\n",
    "            \n",
    "            for k in range(len(N2)):\n",
    "                noOfNeuron2 = N2[k]\n",
    "\n",
    "                print('\\n\\nTrial No.%d'%(cnt+1))\n",
    "                print('Prediction :' + Model[M])\n",
    "                print('Learning rate : {:.3}'.format(learningRate))\n",
    "                print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "                print('Hidden 2 neuron : %d'%(noOfNeuron2))\n",
    "\n",
    "                ################ 신경망 구조 재설계 ################\n",
    "\n",
    "                tf.keras.backend.clear_session()\n",
    "                def ANN_model(input_data):\n",
    "                    model = keras.Sequential()\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron_in,\n",
    "                                                 input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron2,                  activation = 'relu'))  # Hidden Layer 2\n",
    "                    model.add(keras.layers.Dense(units = noOfNeuron_out,             )) # Output Layer\n",
    "                    model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                                  loss=keras.losses.mean_absolute_error,\n",
    "                                  metrics=['mse','mae','mape'])\n",
    "                    return model\n",
    "                model = ANN_model(TrainData)\n",
    "\n",
    "                ################ 신경망 학습 ################\n",
    "\n",
    "                hist = model.fit(TrainData, TrainLabel, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100)\n",
    "                print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "                      .format(np.sqrt(hist.history['mse'][-1]), hist.history['mae'][-1], hist.history['mape'][-1]))\n",
    "                \n",
    "                model.save('D:/testoneblow/MLmodels/Model_%d.h5'%(cnt+1))\n",
    "                \n",
    "                Tr_result_temp[cnt,0] = cnt+1\n",
    "                Tr_result_temp[cnt,1] = learningRate\n",
    "                Tr_result_temp[cnt,2] = noOfNeuron1\n",
    "                Tr_result_temp[cnt,3] = noOfNeuron2\n",
    "                Tr_result_temp[cnt,4] = np.sqrt(hist.history['mse'][-1])\n",
    "                Tr_result_temp[cnt,5] = hist.history['mae'][-1]\n",
    "                Tr_result_temp[cnt,6] = hist.history['mape'][-1]\n",
    "\n",
    "                cnt=cnt+1\n",
    "\n",
    "\n",
    "    Tr_result_temp_pd = pd.DataFrame(Tr_result_temp, columns=['Case', 'L.rate', 'Nr-HL1', 'Nr-HL2', 'RMSE', 'MAE', 'MAPE'])\n",
    "    Tr_result_temp_pd.to_csv('D:/testoneblow/ANN_prediction5.0/Tr_result_epoch%d.csv'%(Epoch), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Wn1, Wn2, R1, R2] 최고성능 모델 재학습 및 모델 & 히스토리 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:42.80077,   MAE: 42.63838,  MAPE: 4046.86%\n",
      "[100 Epochs]    RMSE:6.63033,   MAE: 5.97376,  MAPE: 542.07%\n",
      "[200 Epochs]    RMSE:5.66367,   MAE: 4.96877,  MAPE: 489.50%\n",
      "[300 Epochs]    RMSE:6.93431,   MAE: 6.44119,  MAPE: 626.04%\n",
      "[400 Epochs]    RMSE:1.83694,   MAE: 1.47773,  MAPE: 136.62%\n",
      "[500 Epochs]    RMSE:3.13734,   MAE: 2.80966,  MAPE: 260.68%\n",
      "[600 Epochs]    RMSE:3.39230,   MAE: 3.07323,  MAPE: 285.51%\n",
      "[700 Epochs]    RMSE:2.61417,   MAE: 2.29030,  MAPE: 211.90%\n",
      "[800 Epochs]    RMSE:2.95113,   MAE: 2.68664,  MAPE: 249.55%\n",
      "[900 Epochs]    RMSE:2.60700,   MAE: 2.35869,  MAPE: 219.02%\n",
      "[1000 Epochs]    RMSE:2.44957,   MAE: 2.21702,  MAPE: 205.98%\n",
      "[1100 Epochs]    RMSE:2.28153,   MAE: 2.06639,  MAPE: 192.19%\n",
      "[1200 Epochs]    RMSE:2.18618,   MAE: 1.99109,  MAPE: 185.37%\n",
      "[1300 Epochs]    RMSE:2.04814,   MAE: 1.86061,  MAPE: 173.15%\n",
      "[1400 Epochs]    RMSE:1.18374,   MAE: 0.98435,  MAPE: 93.43%\n",
      "[1500 Epochs]    RMSE:0.81573,   MAE: 0.67265,  MAPE: 64.42%\n",
      "[1600 Epochs]    RMSE:2.33118,   MAE: 2.25533,  MAPE: 212.45%\n",
      "[1700 Epochs]    RMSE:1.34254,   MAE: 1.11985,  MAPE: 112.13%\n",
      "[1800 Epochs]    RMSE:1.22271,   MAE: 1.06997,  MAPE: 103.79%\n",
      "[1900 Epochs]    RMSE:0.84193,   MAE: 0.71958,  MAPE: 68.77%\n",
      "[2000 Epochs]    RMSE:0.40048,   MAE: 0.32415,  MAPE: 31.32%\n",
      "[2100 Epochs]    RMSE:1.88383,   MAE: 1.86023,  MAPE: 177.19%\n",
      "[2200 Epochs]    RMSE:1.08076,   MAE: 1.04509,  MAPE: 99.34%\n",
      "[2300 Epochs]    RMSE:0.90584,   MAE: 0.86208,  MAPE: 81.84%\n",
      "[2400 Epochs]    RMSE:0.92116,   MAE: 0.88017,  MAPE: 83.56%\n",
      "[2500 Epochs]    RMSE:0.70667,   MAE: 0.64819,  MAPE: 61.30%\n",
      "[2600 Epochs]    RMSE:0.80580,   MAE: 0.75402,  MAPE: 70.95%\n",
      "[2700 Epochs]    RMSE:1.01719,   MAE: 0.98723,  MAPE: 93.68%\n",
      "[2800 Epochs]    RMSE:0.77835,   MAE: 0.74293,  MAPE: 70.45%\n",
      "[2900 Epochs]    RMSE:0.72403,   MAE: 0.69344,  MAPE: 66.63%\n",
      "[3000 Epochs]    RMSE:0.47302,   MAE: 0.42750,  MAPE: 41.25%\n",
      "[3100 Epochs]    RMSE:0.94515,   MAE: 0.92609,  MAPE: 88.40%\n",
      "[3200 Epochs]    RMSE:1.18038,   MAE: 1.16082,  MAPE: 110.59%\n",
      "[3300 Epochs]    RMSE:1.19833,   MAE: 1.17873,  MAPE: 110.29%\n",
      "[3400 Epochs]    RMSE:0.61614,   MAE: 0.58232,  MAPE: 55.23%\n",
      "[3500 Epochs]    RMSE:0.18299,   MAE: 0.15407,  MAPE: 14.95%\n",
      "[3600 Epochs]    RMSE:0.19848,   MAE: 0.16145,  MAPE: 14.49%\n",
      "[3700 Epochs]    RMSE:0.29525,   MAE: 0.27643,  MAPE: 27.27%\n",
      "[3800 Epochs]    RMSE:0.60310,   MAE: 0.58800,  MAPE: 56.78%\n",
      "[3900 Epochs]    RMSE:0.24485,   MAE: 0.21923,  MAPE: 21.70%\n",
      "[4000 Epochs]    RMSE:0.52884,   MAE: 0.51695,  MAPE: 49.86%\n",
      "[4100 Epochs]    RMSE:0.22577,   MAE: 0.19998,  MAPE: 17.89%\n",
      "[4200 Epochs]    RMSE:0.39289,   MAE: 0.37565,  MAPE: 36.28%\n",
      "[4300 Epochs]    RMSE:0.15908,   MAE: 0.12472,  MAPE: 10.93%\n",
      "[4400 Epochs]    RMSE:0.24834,   MAE: 0.22088,  MAPE: 19.93%\n",
      "[4500 Epochs]    RMSE:0.10568,   MAE: 0.08243,  MAPE: 8.12%\n",
      "[4600 Epochs]    RMSE:0.18899,   MAE: 0.17158,  MAPE: 16.97%\n",
      "[4700 Epochs]    RMSE:0.10267,   MAE: 0.08103,  MAPE: 7.98%\n",
      "[4800 Epochs]    RMSE:0.29906,   MAE: 0.27353,  MAPE: 24.29%\n",
      "[4900 Epochs]    RMSE:0.09817,   MAE: 0.07179,  MAPE: 6.99%\n",
      "[5000 Epochs]    RMSE:0.20505,   MAE: 0.18037,  MAPE: 18.21%\n",
      "[5100 Epochs]    RMSE:0.15109,   MAE: 0.12981,  MAPE: 13.27%\n",
      "[5200 Epochs]    RMSE:0.19713,   MAE: 0.17715,  MAPE: 17.60%\n",
      "[5300 Epochs]    RMSE:0.10336,   MAE: 0.08720,  MAPE: 8.80%\n",
      "[5400 Epochs]    RMSE:0.09138,   MAE: 0.07440,  MAPE: 7.44%\n",
      "[5500 Epochs]    RMSE:0.08797,   MAE: 0.07097,  MAPE: 7.07%\n",
      "[5600 Epochs]    RMSE:0.10237,   MAE: 0.08866,  MAPE: 8.70%\n",
      "[5700 Epochs]    RMSE:0.12349,   MAE: 0.10026,  MAPE: 8.77%\n",
      "[5800 Epochs]    RMSE:0.08703,   MAE: 0.06441,  MAPE: 6.00%\n",
      "[5900 Epochs]    RMSE:0.10675,   MAE: 0.08149,  MAPE: 7.35%\n",
      "[6000 Epochs]    RMSE:0.08989,   MAE: 0.07638,  MAPE: 7.51%\n",
      "[6100 Epochs]    RMSE:0.17920,   MAE: 0.16176,  MAPE: 14.50%\n",
      "[6200 Epochs]    RMSE:0.19488,   MAE: 0.16655,  MAPE: 14.53%\n",
      "[6300 Epochs]    RMSE:0.20425,   MAE: 0.17503,  MAPE: 14.99%\n",
      "[6400 Epochs]    RMSE:0.11093,   MAE: 0.08365,  MAPE: 7.67%\n",
      "[6500 Epochs]    RMSE:0.17371,   MAE: 0.14495,  MAPE: 13.10%\n",
      "[6600 Epochs]    RMSE:0.08497,   MAE: 0.06765,  MAPE: 6.73%\n",
      "[6700 Epochs]    RMSE:0.08036,   MAE: 0.06001,  MAPE: 5.59%\n",
      "[6800 Epochs]    RMSE:0.07438,   MAE: 0.05498,  MAPE: 5.52%\n",
      "[6900 Epochs]    RMSE:0.17094,   MAE: 0.14690,  MAPE: 14.21%\n",
      "[7000 Epochs]    RMSE:0.11334,   MAE: 0.08447,  MAPE: 8.82%\n",
      "[7100 Epochs]    RMSE:0.10135,   MAE: 0.08517,  MAPE: 8.41%\n",
      "[7200 Epochs]    RMSE:0.14063,   MAE: 0.12380,  MAPE: 11.29%\n",
      "[7300 Epochs]    RMSE:0.06886,   MAE: 0.04914,  MAPE: 4.68%\n",
      "[7400 Epochs]    RMSE:0.06570,   MAE: 0.04903,  MAPE: 4.72%\n",
      "[7500 Epochs]    RMSE:0.12312,   MAE: 0.09466,  MAPE: 8.79%\n",
      "[7600 Epochs]    RMSE:0.07924,   MAE: 0.06355,  MAPE: 6.09%\n",
      "[7700 Epochs]    RMSE:0.06599,   MAE: 0.04834,  MAPE: 4.69%\n",
      "[7800 Epochs]    RMSE:0.07483,   MAE: 0.05816,  MAPE: 5.58%\n",
      "[7900 Epochs]    RMSE:0.07453,   MAE: 0.05204,  MAPE: 4.95%\n",
      "[8000 Epochs]    RMSE:0.11275,   MAE: 0.08905,  MAPE: 9.39%\n",
      "[8100 Epochs]    RMSE:0.08745,   MAE: 0.06927,  MAPE: 6.22%\n",
      "[8200 Epochs]    RMSE:0.07938,   MAE: 0.06307,  MAPE: 6.58%\n",
      "[8300 Epochs]    RMSE:0.18657,   MAE: 0.16031,  MAPE: 16.92%\n",
      "[8400 Epochs]    RMSE:0.11482,   MAE: 0.10092,  MAPE: 9.90%\n",
      "[8500 Epochs]    RMSE:0.09422,   MAE: 0.07645,  MAPE: 7.38%\n",
      "[8600 Epochs]    RMSE:0.11219,   MAE: 0.08762,  MAPE: 8.80%\n",
      "[8700 Epochs]    RMSE:0.06733,   MAE: 0.05244,  MAPE: 4.90%\n",
      "[8800 Epochs]    RMSE:0.06975,   MAE: 0.04985,  MAPE: 4.98%\n",
      "[8900 Epochs]    RMSE:0.07330,   MAE: 0.05512,  MAPE: 5.07%\n",
      "[9000 Epochs]    RMSE:0.06092,   MAE: 0.04785,  MAPE: 4.73%\n",
      "[9100 Epochs]    RMSE:0.12543,   MAE: 0.09084,  MAPE: 8.49%\n",
      "[9200 Epochs]    RMSE:0.08026,   MAE: 0.05753,  MAPE: 5.70%\n",
      "[9300 Epochs]    RMSE:0.07560,   MAE: 0.05591,  MAPE: 5.24%\n",
      "[9400 Epochs]    RMSE:0.07741,   MAE: 0.05965,  MAPE: 6.32%\n",
      "[9500 Epochs]    RMSE:0.08061,   MAE: 0.06824,  MAPE: 5.98%\n",
      "[9600 Epochs]    RMSE:0.08084,   MAE: 0.06623,  MAPE: 6.50%\n",
      "[9700 Epochs]    RMSE:0.08974,   MAE: 0.06886,  MAPE: 6.79%\n",
      "[9800 Epochs]    RMSE:0.08921,   MAE: 0.06906,  MAPE: 6.76%\n",
      "[9900 Epochs]    RMSE:0.14341,   MAE: 0.13161,  MAPE: 12.28%\n",
      "[10000 Epochs]    RMSE:0.08620,   MAE: 0.07129,  MAPE: 7.55%\n",
      "[10100 Epochs]    RMSE:0.05676,   MAE: 0.04676,  MAPE: 4.45%\n",
      "[10200 Epochs]    RMSE:0.17079,   MAE: 0.15113,  MAPE: 15.55%\n",
      "[10300 Epochs]    RMSE:0.06749,   MAE: 0.05619,  MAPE: 4.98%\n",
      "[10400 Epochs]    RMSE:0.06429,   MAE: 0.04638,  MAPE: 4.75%\n",
      "[10500 Epochs]    RMSE:0.10431,   MAE: 0.09003,  MAPE: 7.97%\n",
      "[10600 Epochs]    RMSE:0.10653,   MAE: 0.09281,  MAPE: 8.02%\n",
      "[10700 Epochs]    RMSE:0.07071,   MAE: 0.05707,  MAPE: 5.28%\n",
      "[10800 Epochs]    RMSE:0.18109,   MAE: 0.15695,  MAPE: 13.40%\n",
      "[10900 Epochs]    RMSE:0.11880,   MAE: 0.10564,  MAPE: 9.67%\n",
      "[11000 Epochs]    RMSE:0.13221,   MAE: 0.11182,  MAPE: 10.42%\n",
      "[11100 Epochs]    RMSE:0.08118,   MAE: 0.06534,  MAPE: 6.83%\n",
      "[11200 Epochs]    RMSE:0.07208,   MAE: 0.04979,  MAPE: 4.94%\n",
      "[11300 Epochs]    RMSE:0.07831,   MAE: 0.06313,  MAPE: 6.07%\n",
      "[11400 Epochs]    RMSE:0.09235,   MAE: 0.06413,  MAPE: 6.20%\n",
      "[11500 Epochs]    RMSE:0.12803,   MAE: 0.10835,  MAPE: 10.20%\n",
      "[11600 Epochs]    RMSE:0.07273,   MAE: 0.05784,  MAPE: 6.15%\n",
      "[11700 Epochs]    RMSE:0.09258,   MAE: 0.06067,  MAPE: 5.49%\n",
      "[11800 Epochs]    RMSE:0.06157,   MAE: 0.05281,  MAPE: 5.16%\n",
      "[11900 Epochs]    RMSE:0.06582,   MAE: 0.04705,  MAPE: 4.48%\n",
      "[12000 Epochs]    RMSE:0.08867,   MAE: 0.07229,  MAPE: 7.69%\n",
      "[12100 Epochs]    RMSE:0.10123,   MAE: 0.08948,  MAPE: 8.03%\n",
      "[12200 Epochs]    RMSE:0.07079,   MAE: 0.05174,  MAPE: 4.98%\n",
      "[12300 Epochs]    RMSE:0.05190,   MAE: 0.04012,  MAPE: 3.83%\n",
      "[12400 Epochs]    RMSE:0.15774,   MAE: 0.15066,  MAPE: 14.72%\n",
      "[12500 Epochs]    RMSE:0.05485,   MAE: 0.04524,  MAPE: 4.47%\n",
      "[12600 Epochs]    RMSE:0.05346,   MAE: 0.04148,  MAPE: 4.20%\n",
      "[12700 Epochs]    RMSE:0.07741,   MAE: 0.05129,  MAPE: 4.79%\n",
      "[12800 Epochs]    RMSE:0.04461,   MAE: 0.03540,  MAPE: 3.39%\n",
      "[12900 Epochs]    RMSE:0.07541,   MAE: 0.05736,  MAPE: 6.24%\n",
      "[13000 Epochs]    RMSE:0.04917,   MAE: 0.03871,  MAPE: 4.00%\n",
      "[13100 Epochs]    RMSE:0.09629,   MAE: 0.06392,  MAPE: 5.99%\n",
      "[13200 Epochs]    RMSE:0.09055,   MAE: 0.07735,  MAPE: 7.07%\n",
      "[13300 Epochs]    RMSE:0.05214,   MAE: 0.03629,  MAPE: 3.43%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13400 Epochs]    RMSE:0.05680,   MAE: 0.04483,  MAPE: 4.42%\n",
      "[13500 Epochs]    RMSE:0.05407,   MAE: 0.03810,  MAPE: 3.53%\n",
      "[13600 Epochs]    RMSE:0.05241,   MAE: 0.03767,  MAPE: 3.54%\n",
      "[13700 Epochs]    RMSE:0.04641,   MAE: 0.03519,  MAPE: 3.34%\n",
      "[13800 Epochs]    RMSE:0.09644,   MAE: 0.07869,  MAPE: 6.77%\n",
      "[13900 Epochs]    RMSE:0.06362,   MAE: 0.04703,  MAPE: 4.45%\n",
      "[14000 Epochs]    RMSE:0.05585,   MAE: 0.04413,  MAPE: 4.24%\n",
      "[14100 Epochs]    RMSE:0.05197,   MAE: 0.03970,  MAPE: 3.98%\n",
      "[14200 Epochs]    RMSE:0.04644,   MAE: 0.03849,  MAPE: 3.92%\n",
      "[14300 Epochs]    RMSE:0.06335,   MAE: 0.05233,  MAPE: 4.74%\n",
      "[14400 Epochs]    RMSE:0.09544,   MAE: 0.07532,  MAPE: 7.09%\n",
      "[14500 Epochs]    RMSE:0.07368,   MAE: 0.06371,  MAPE: 6.39%\n",
      "[14600 Epochs]    RMSE:0.05949,   MAE: 0.04746,  MAPE: 4.71%\n",
      "[14700 Epochs]    RMSE:0.04746,   MAE: 0.03988,  MAPE: 3.84%\n",
      "[14800 Epochs]    RMSE:0.03773,   MAE: 0.02966,  MAPE: 2.88%\n",
      "[14900 Epochs]    RMSE:0.04163,   MAE: 0.03251,  MAPE: 2.96%\n",
      "[15000 Epochs]    RMSE:0.10843,   MAE: 0.09570,  MAPE: 8.80%\n",
      "[15100 Epochs]    RMSE:0.28115,   MAE: 0.22785,  MAPE: 23.94%\n",
      "[15200 Epochs]    RMSE:0.06835,   MAE: 0.05267,  MAPE: 5.03%\n",
      "[15300 Epochs]    RMSE:0.06565,   MAE: 0.04867,  MAPE: 4.47%\n",
      "[15400 Epochs]    RMSE:0.05791,   MAE: 0.04459,  MAPE: 4.25%\n",
      "[15500 Epochs]    RMSE:0.06690,   MAE: 0.05548,  MAPE: 5.34%\n",
      "[15600 Epochs]    RMSE:0.07110,   MAE: 0.05764,  MAPE: 5.59%\n",
      "[15700 Epochs]    RMSE:0.05446,   MAE: 0.04225,  MAPE: 3.93%\n",
      "[15800 Epochs]    RMSE:0.05485,   MAE: 0.04420,  MAPE: 4.29%\n",
      "[15900 Epochs]    RMSE:0.09000,   MAE: 0.07438,  MAPE: 7.68%\n",
      "[16000 Epochs]    RMSE:0.05418,   MAE: 0.04300,  MAPE: 3.92%\n",
      "[16100 Epochs]    RMSE:0.04304,   MAE: 0.03347,  MAPE: 3.31%\n",
      "[16200 Epochs]    RMSE:0.04195,   MAE: 0.03207,  MAPE: 3.17%\n",
      "[16300 Epochs]    RMSE:0.06819,   MAE: 0.05485,  MAPE: 5.10%\n",
      "[16400 Epochs]    RMSE:0.04702,   MAE: 0.03629,  MAPE: 3.76%\n",
      "[16500 Epochs]    RMSE:0.05606,   MAE: 0.04692,  MAPE: 4.27%\n",
      "[16600 Epochs]    RMSE:0.08421,   MAE: 0.06335,  MAPE: 6.26%\n",
      "[16700 Epochs]    RMSE:0.04800,   MAE: 0.03824,  MAPE: 3.72%\n",
      "[16800 Epochs]    RMSE:0.12526,   MAE: 0.10801,  MAPE: 11.34%\n",
      "[16900 Epochs]    RMSE:0.05755,   MAE: 0.04642,  MAPE: 4.37%\n",
      "[17000 Epochs]    RMSE:0.06122,   MAE: 0.04816,  MAPE: 4.47%\n",
      "[17100 Epochs]    RMSE:0.03458,   MAE: 0.02740,  MAPE: 2.49%\n",
      "[17200 Epochs]    RMSE:0.06605,   MAE: 0.05859,  MAPE: 5.50%\n",
      "[17300 Epochs]    RMSE:0.07336,   MAE: 0.06497,  MAPE: 6.49%\n",
      "[17400 Epochs]    RMSE:0.10085,   MAE: 0.08598,  MAPE: 7.41%\n",
      "[17500 Epochs]    RMSE:0.07845,   MAE: 0.06211,  MAPE: 6.32%\n",
      "[17600 Epochs]    RMSE:0.06646,   MAE: 0.05558,  MAPE: 5.65%\n",
      "[17700 Epochs]    RMSE:0.04709,   MAE: 0.03583,  MAPE: 3.65%\n",
      "[17800 Epochs]    RMSE:0.08840,   MAE: 0.07162,  MAPE: 6.81%\n",
      "[17900 Epochs]    RMSE:0.06157,   MAE: 0.05181,  MAPE: 4.95%\n",
      "[18000 Epochs]    RMSE:0.05919,   MAE: 0.04717,  MAPE: 4.74%\n",
      "[18100 Epochs]    RMSE:0.14658,   MAE: 0.11817,  MAPE: 11.70%\n",
      "[18200 Epochs]    RMSE:0.04243,   MAE: 0.03444,  MAPE: 3.52%\n",
      "[18300 Epochs]    RMSE:0.04052,   MAE: 0.03327,  MAPE: 3.43%\n",
      "[18400 Epochs]    RMSE:0.04382,   MAE: 0.03626,  MAPE: 3.42%\n",
      "[18500 Epochs]    RMSE:0.06114,   MAE: 0.05052,  MAPE: 4.96%\n",
      "[18600 Epochs]    RMSE:0.04696,   MAE: 0.03565,  MAPE: 3.81%\n",
      "[18700 Epochs]    RMSE:0.06883,   MAE: 0.05532,  MAPE: 4.86%\n",
      "[18800 Epochs]    RMSE:0.07269,   MAE: 0.06409,  MAPE: 6.07%\n",
      "[18900 Epochs]    RMSE:0.03541,   MAE: 0.02909,  MAPE: 2.74%\n",
      "[19000 Epochs]    RMSE:0.03408,   MAE: 0.02655,  MAPE: 2.52%\n",
      "[19100 Epochs]    RMSE:0.06219,   MAE: 0.05267,  MAPE: 4.70%\n",
      "[19200 Epochs]    RMSE:0.07205,   MAE: 0.06327,  MAPE: 6.04%\n",
      "[19300 Epochs]    RMSE:0.04617,   MAE: 0.03803,  MAPE: 3.58%\n",
      "[19400 Epochs]    RMSE:0.04324,   MAE: 0.03404,  MAPE: 3.37%\n",
      "[19500 Epochs]    RMSE:0.05297,   MAE: 0.04277,  MAPE: 4.30%\n",
      "[19600 Epochs]    RMSE:0.06373,   MAE: 0.04273,  MAPE: 3.98%\n",
      "[19700 Epochs]    RMSE:0.03270,   MAE: 0.02668,  MAPE: 2.56%\n",
      "[19800 Epochs]    RMSE:0.08224,   MAE: 0.05921,  MAPE: 6.05%\n",
      "[19900 Epochs]    RMSE:0.05301,   MAE: 0.04503,  MAPE: 4.44%\n",
      "\n",
      "[Final Epochs]    RMSE:0.03814,   MAE: 0.03032,  MAPE: 2.77%\n"
     ]
    }
   ],
   "source": [
    "for M in range(1):\n",
    "\n",
    "    Tr_result_temp = pd.read_csv('D:/testoneblow/ANN_prediction5.0/P10 prediction/Tr_result_epoch5000.csv')\n",
    "    learningRate   = Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,1]\n",
    "    noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,2])\n",
    "    noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,3])\n",
    "    Epoch          = 20000\n",
    "    \n",
    "    print('\\n\\n\\nPrediction :' + Model[M])\n",
    "    print('Learning rate : {:.3}'.format(learningRate))\n",
    "    print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "    print('Hidden 2 neuron : %d'%(noOfNeuron2))\n",
    "    \n",
    "#     exec('Label_Trn = TrainLabel_%d'%(M+1))\n",
    "    \n",
    "    ################ 신경망 구조 재설계 ################\n",
    "\n",
    "    tf.keras.backend.clear_session()\n",
    "    def ANN_model(input_data):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron_in,\n",
    "                                     input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron2,                  activation = 'relu'))  # Hidden Layer 2\n",
    "        model.add(keras.layers.Dense(units = noOfNeuron_out,               )) # Output Layer\n",
    "        model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                      loss=keras.losses.mean_absolute_error,\n",
    "                      metrics=['mse','mae','mape'])\n",
    "        return model\n",
    "    model = ANN_model(TrainData)\n",
    "\n",
    "    ################ 신경망 학습 ################\n",
    "\n",
    "    BestModel_temp = model.fit(TrainData, TrainLabel, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100)\n",
    "    print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "          .format(np.sqrt(BestModel_temp.history['mse'][-1]), BestModel_temp.history['mae'][-1], BestModel_temp.history['mape'][-1]))\n",
    "    \n",
    "    # 모델 저장\n",
    "    model.save('D:/testoneblow/MLmodels/BestModel_2DOF_0410_M%d.h5'%(M+1))\n",
    "    \n",
    "    # 히스토리 저장\n",
    "    RMSE  = np.sqrt(np.array(BestModel_temp.history['mse'])[:, np.newaxis])\n",
    "    MAE   = np.array(BestModel_temp.history['mae'])[:, np.newaxis]\n",
    "    MAPE  = np.array(BestModel_temp.history['mape'])[:, np.newaxis]\n",
    "\n",
    "    History_temp = pd.DataFrame(np.concatenate([RMSE,MAE,MAPE],axis=1))\n",
    "    History_temp.to_csv(\"D:/testoneblow/MLmodels/BestModel_2DOF_0410_M%d_history.csv\"%(M+1), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, 100.0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(BestModel_temp.history['mape'])\n",
    "\n",
    "plt.ylabel(\"mape\", fontsize='16')\n",
    "plt.xlabel(\"epoch\", fontsize='16')\n",
    "plt.ylim(0,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00266373],\n",
       "       [0.0025697 ],\n",
       "       [0.00258017],\n",
       "       [0.00255452],\n",
       "       [0.00253639],\n",
       "       [0.00245616],\n",
       "       [0.00278801],\n",
       "       [0.002496  ],\n",
       "       [0.0025983 ],\n",
       "       [0.00276812],\n",
       "       [0.00260244],\n",
       "       [0.00263484],\n",
       "       [0.00271226],\n",
       "       [0.00270314],\n",
       "       [0.00255115],\n",
       "       [0.00252989],\n",
       "       [0.00259314],\n",
       "       [0.00267023],\n",
       "       [0.00252906],\n",
       "       [0.00268264],\n",
       "       [0.00275154],\n",
       "       [0.00260129],\n",
       "       [0.00270738],\n",
       "       [0.00258939],\n",
       "       [0.0026616 ],\n",
       "       [0.00260961],\n",
       "       [0.00248206],\n",
       "       [0.00257404],\n",
       "       [0.00266219],\n",
       "       [0.00270412],\n",
       "       [0.00250752],\n",
       "       [0.00273494],\n",
       "       [0.0027268 ],\n",
       "       [0.00258954],\n",
       "       [0.00272163],\n",
       "       [0.00265285],\n",
       "       [0.00267702],\n",
       "       [0.0024617 ],\n",
       "       [0.00274831],\n",
       "       [0.00271054],\n",
       "       [0.00247533],\n",
       "       [0.00260402],\n",
       "       [0.00265631],\n",
       "       [0.00270935],\n",
       "       [0.00271716],\n",
       "       [0.00272185],\n",
       "       [0.00269202],\n",
       "       [0.0025454 ],\n",
       "       [0.0025052 ],\n",
       "       [0.00260874],\n",
       "       [0.0026668 ],\n",
       "       [0.00259048],\n",
       "       [0.0024347 ],\n",
       "       [0.00258121],\n",
       "       [0.00268685],\n",
       "       [0.00271529],\n",
       "       [0.00249769],\n",
       "       [0.0025621 ],\n",
       "       [0.0024818 ],\n",
       "       [0.00249236],\n",
       "       [0.00273065],\n",
       "       [0.00276276],\n",
       "       [0.00275242],\n",
       "       [0.00261103],\n",
       "       [0.00272355],\n",
       "       [0.00256135],\n",
       "       [0.00271943],\n",
       "       [0.0026911 ],\n",
       "       [0.00262356],\n",
       "       [0.00244299],\n",
       "       [0.00273104],\n",
       "       [0.00271455],\n",
       "       [0.00274558],\n",
       "       [0.00263395],\n",
       "       [0.00253334],\n",
       "       [0.00253188],\n",
       "       [0.00261559],\n",
       "       [0.00269453],\n",
       "       [0.00264061],\n",
       "       [0.00261104],\n",
       "       [0.002594  ],\n",
       "       [0.00264634],\n",
       "       [0.00252091],\n",
       "       [0.00260164],\n",
       "       [0.00260761],\n",
       "       [0.00270346],\n",
       "       [0.00269258],\n",
       "       [0.00274276],\n",
       "       [0.00253386],\n",
       "       [0.00269445],\n",
       "       [0.00257243],\n",
       "       [0.00270926],\n",
       "       [0.00273145],\n",
       "       [0.00260735],\n",
       "       [0.00253013],\n",
       "       [0.00239932],\n",
       "       [0.0025611 ],\n",
       "       [0.00260972],\n",
       "       [0.00252958],\n",
       "       [0.00271659]], dtype=float32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(model.predict(TrainData)-0.5)*dist_value+min_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(TrainLabel_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1      0.002639\n",
       "2      0.002597\n",
       "3      0.002549\n",
       "4      0.002536\n",
       "5      0.002529\n",
       "         ...   \n",
       "96     0.002395\n",
       "97     0.002536\n",
       "98     0.002611\n",
       "99     0.002535\n",
       "100    0.002706\n",
       "Name: P10, Length: 100, dtype: float64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLabel_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00270594"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLabel_[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ErrorTable = np.zeros((TrainLabel.shape[0],4))\n",
    "ErrorTable[:,0] = TrainLabel_\n",
    "for i in range(TrainLabel.shape[0]):\n",
    "    a = ((model.predict(TrainData)-0.5)*dist_value+min_value)[i]\n",
    "    ErrorTable[i,1] = a\n",
    "    ErrorTable[i,2] = ((TrainLabel_[i+1]-a)/TrainLabel_[i+1])*100\n",
    "    ErrorTable[i,3] = np.abs(((TrainLabel_[i+1]-a)/TrainLabel_[i+1])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>-0.950532</td>\n",
       "      <td>0.950532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>1.058109</td>\n",
       "      <td>1.058109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>-1.241781</td>\n",
       "      <td>1.241781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>-0.721324</td>\n",
       "      <td>0.721324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>-0.306969</td>\n",
       "      <td>0.306969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.002399</td>\n",
       "      <td>-0.190289</td>\n",
       "      <td>0.190289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.002561</td>\n",
       "      <td>-0.993646</td>\n",
       "      <td>0.993646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.002610</td>\n",
       "      <td>0.036646</td>\n",
       "      <td>0.036646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.002535</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.232292</td>\n",
       "      <td>0.232292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.002706</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>-0.393515</td>\n",
       "      <td>0.393515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3\n",
       "0   0.002639  0.002664 -0.950532  0.950532\n",
       "1   0.002597  0.002570  1.058109  1.058109\n",
       "2   0.002549  0.002580 -1.241781  1.241781\n",
       "3   0.002536  0.002555 -0.721324  0.721324\n",
       "4   0.002529  0.002536 -0.306969  0.306969\n",
       "..       ...       ...       ...       ...\n",
       "95  0.002395  0.002399 -0.190289  0.190289\n",
       "96  0.002536  0.002561 -0.993646  0.993646\n",
       "97  0.002611  0.002610  0.036646  0.036646\n",
       "98  0.002535  0.002530  0.232292  0.232292\n",
       "99  0.002706  0.002717 -0.393515  0.393515\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ErrorTable = pd.DataFrame(ErrorTable)\n",
    "ErrorTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6405458883522078"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(ErrorTable.iloc[:,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ErrorTable.to_csv('D:/testoneblow/ANN_prediction5.0/P10 prediction/ErrorTable.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Fold = 5\n",
    "FoldDataNo = int(TrainData.shape[0]/Fold)\n",
    "FoldDataNo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 37)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>P10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.184604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.068196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.931607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.897109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.875775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.896182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>1.106091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.894975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.373488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          P10\n",
       "1    1.184604\n",
       "2    1.068196\n",
       "3    0.931607\n",
       "4    0.897109\n",
       "5    0.875775\n",
       "..        ...\n",
       "96   0.500000\n",
       "97   0.896182\n",
       "98   1.106091\n",
       "99   0.894975\n",
       "100  1.373488\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TrainLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.750000</td>\n",
       "      <td>373.657806</td>\n",
       "      <td>373.540253</td>\n",
       "      <td>...</td>\n",
       "      <td>377.957092</td>\n",
       "      <td>378.389252</td>\n",
       "      <td>374.274780</td>\n",
       "      <td>367.468018</td>\n",
       "      <td>360.661255</td>\n",
       "      <td>354.408600</td>\n",
       "      <td>353.307526</td>\n",
       "      <td>353.255890</td>\n",
       "      <td>353.203827</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>354.949982</td>\n",
       "      <td>354.950012</td>\n",
       "      <td>358.591217</td>\n",
       "      <td>363.235382</td>\n",
       "      <td>...</td>\n",
       "      <td>361.841492</td>\n",
       "      <td>358.276031</td>\n",
       "      <td>356.407104</td>\n",
       "      <td>355.542755</td>\n",
       "      <td>354.678406</td>\n",
       "      <td>353.884430</td>\n",
       "      <td>353.622620</td>\n",
       "      <td>353.467651</td>\n",
       "      <td>353.311493</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.750000</td>\n",
       "      <td>371.703918</td>\n",
       "      <td>371.645111</td>\n",
       "      <td>...</td>\n",
       "      <td>374.806030</td>\n",
       "      <td>369.079712</td>\n",
       "      <td>364.778473</td>\n",
       "      <td>361.321045</td>\n",
       "      <td>357.863647</td>\n",
       "      <td>354.687683</td>\n",
       "      <td>353.937683</td>\n",
       "      <td>353.679413</td>\n",
       "      <td>353.419159</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.950012</td>\n",
       "      <td>364.489075</td>\n",
       "      <td>363.901215</td>\n",
       "      <td>...</td>\n",
       "      <td>373.390411</td>\n",
       "      <td>378.900635</td>\n",
       "      <td>376.471191</td>\n",
       "      <td>369.340302</td>\n",
       "      <td>362.209381</td>\n",
       "      <td>355.658997</td>\n",
       "      <td>354.252747</td>\n",
       "      <td>353.891174</td>\n",
       "      <td>353.526825</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>367.750000</td>\n",
       "      <td>366.413361</td>\n",
       "      <td>364.708527</td>\n",
       "      <td>...</td>\n",
       "      <td>366.850708</td>\n",
       "      <td>360.800262</td>\n",
       "      <td>357.939240</td>\n",
       "      <td>356.966858</td>\n",
       "      <td>355.994476</td>\n",
       "      <td>355.101227</td>\n",
       "      <td>354.567841</td>\n",
       "      <td>354.102966</td>\n",
       "      <td>353.634521</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>361.350006</td>\n",
       "      <td>361.350006</td>\n",
       "      <td>361.350006</td>\n",
       "      <td>361.350006</td>\n",
       "      <td>361.350006</td>\n",
       "      <td>361.350006</td>\n",
       "      <td>361.350006</td>\n",
       "      <td>361.350006</td>\n",
       "      <td>363.977203</td>\n",
       "      <td>367.328064</td>\n",
       "      <td>...</td>\n",
       "      <td>369.020905</td>\n",
       "      <td>373.342651</td>\n",
       "      <td>372.303436</td>\n",
       "      <td>368.089722</td>\n",
       "      <td>363.876007</td>\n",
       "      <td>360.005310</td>\n",
       "      <td>358.033661</td>\n",
       "      <td>356.432404</td>\n",
       "      <td>354.818878</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>368.149994</td>\n",
       "      <td>368.149994</td>\n",
       "      <td>368.149994</td>\n",
       "      <td>368.149994</td>\n",
       "      <td>368.149994</td>\n",
       "      <td>368.149994</td>\n",
       "      <td>368.149994</td>\n",
       "      <td>368.149994</td>\n",
       "      <td>370.085846</td>\n",
       "      <td>372.554901</td>\n",
       "      <td>...</td>\n",
       "      <td>384.265594</td>\n",
       "      <td>388.263214</td>\n",
       "      <td>384.660431</td>\n",
       "      <td>376.557159</td>\n",
       "      <td>368.453857</td>\n",
       "      <td>361.010223</td>\n",
       "      <td>358.348755</td>\n",
       "      <td>356.644196</td>\n",
       "      <td>354.926544</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>385.750000</td>\n",
       "      <td>385.750000</td>\n",
       "      <td>385.750000</td>\n",
       "      <td>385.750000</td>\n",
       "      <td>385.750000</td>\n",
       "      <td>385.750000</td>\n",
       "      <td>385.750000</td>\n",
       "      <td>385.750000</td>\n",
       "      <td>385.888275</td>\n",
       "      <td>386.064636</td>\n",
       "      <td>...</td>\n",
       "      <td>374.688293</td>\n",
       "      <td>367.881531</td>\n",
       "      <td>364.467804</td>\n",
       "      <td>363.063232</td>\n",
       "      <td>361.658661</td>\n",
       "      <td>360.368439</td>\n",
       "      <td>358.663818</td>\n",
       "      <td>356.855957</td>\n",
       "      <td>355.034210</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>357.350006</td>\n",
       "      <td>357.350006</td>\n",
       "      <td>357.350006</td>\n",
       "      <td>357.350006</td>\n",
       "      <td>357.350006</td>\n",
       "      <td>357.350006</td>\n",
       "      <td>357.350006</td>\n",
       "      <td>357.350006</td>\n",
       "      <td>358.456177</td>\n",
       "      <td>359.867096</td>\n",
       "      <td>...</td>\n",
       "      <td>379.313110</td>\n",
       "      <td>389.253113</td>\n",
       "      <td>387.453278</td>\n",
       "      <td>378.701721</td>\n",
       "      <td>369.950165</td>\n",
       "      <td>361.911041</td>\n",
       "      <td>358.978882</td>\n",
       "      <td>357.067719</td>\n",
       "      <td>355.141876</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>375.750000</td>\n",
       "      <td>375.750000</td>\n",
       "      <td>375.750000</td>\n",
       "      <td>375.750000</td>\n",
       "      <td>375.750000</td>\n",
       "      <td>375.750000</td>\n",
       "      <td>375.750000</td>\n",
       "      <td>375.750000</td>\n",
       "      <td>373.261078</td>\n",
       "      <td>370.086548</td>\n",
       "      <td>...</td>\n",
       "      <td>369.686859</td>\n",
       "      <td>374.981018</td>\n",
       "      <td>374.235565</td>\n",
       "      <td>369.913818</td>\n",
       "      <td>365.592072</td>\n",
       "      <td>361.622101</td>\n",
       "      <td>359.293976</td>\n",
       "      <td>357.279480</td>\n",
       "      <td>355.249542</td>\n",
       "      <td>353.149994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0           1           2           3           4           5   \\\n",
       "0   373.750000  373.750000  373.750000  373.750000  373.750000  373.750000   \n",
       "1   354.950012  354.950012  354.950012  354.950012  354.950012  354.950012   \n",
       "2   371.750000  371.750000  371.750000  371.750000  371.750000  371.750000   \n",
       "3   364.950012  364.950012  364.950012  364.950012  364.950012  364.950012   \n",
       "4   367.750000  367.750000  367.750000  367.750000  367.750000  367.750000   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "15  361.350006  361.350006  361.350006  361.350006  361.350006  361.350006   \n",
       "16  368.149994  368.149994  368.149994  368.149994  368.149994  368.149994   \n",
       "17  385.750000  385.750000  385.750000  385.750000  385.750000  385.750000   \n",
       "18  357.350006  357.350006  357.350006  357.350006  357.350006  357.350006   \n",
       "19  375.750000  375.750000  375.750000  375.750000  375.750000  375.750000   \n",
       "\n",
       "            6           7           8           9   ...          27  \\\n",
       "0   373.750000  373.750000  373.657806  373.540253  ...  377.957092   \n",
       "1   354.949982  354.950012  358.591217  363.235382  ...  361.841492   \n",
       "2   371.750000  371.750000  371.703918  371.645111  ...  374.806030   \n",
       "3   364.950012  364.950012  364.489075  363.901215  ...  373.390411   \n",
       "4   367.750000  367.750000  366.413361  364.708527  ...  366.850708   \n",
       "..         ...         ...         ...         ...  ...         ...   \n",
       "15  361.350006  361.350006  363.977203  367.328064  ...  369.020905   \n",
       "16  368.149994  368.149994  370.085846  372.554901  ...  384.265594   \n",
       "17  385.750000  385.750000  385.888275  386.064636  ...  374.688293   \n",
       "18  357.350006  357.350006  358.456177  359.867096  ...  379.313110   \n",
       "19  375.750000  375.750000  373.261078  370.086548  ...  369.686859   \n",
       "\n",
       "            28          29          30          31          32          33  \\\n",
       "0   378.389252  374.274780  367.468018  360.661255  354.408600  353.307526   \n",
       "1   358.276031  356.407104  355.542755  354.678406  353.884430  353.622620   \n",
       "2   369.079712  364.778473  361.321045  357.863647  354.687683  353.937683   \n",
       "3   378.900635  376.471191  369.340302  362.209381  355.658997  354.252747   \n",
       "4   360.800262  357.939240  356.966858  355.994476  355.101227  354.567841   \n",
       "..         ...         ...         ...         ...         ...         ...   \n",
       "15  373.342651  372.303436  368.089722  363.876007  360.005310  358.033661   \n",
       "16  388.263214  384.660431  376.557159  368.453857  361.010223  358.348755   \n",
       "17  367.881531  364.467804  363.063232  361.658661  360.368439  358.663818   \n",
       "18  389.253113  387.453278  378.701721  369.950165  361.911041  358.978882   \n",
       "19  374.981018  374.235565  369.913818  365.592072  361.622101  359.293976   \n",
       "\n",
       "            34          35          36  \n",
       "0   353.255890  353.203827  353.149994  \n",
       "1   353.467651  353.311493  353.149994  \n",
       "2   353.679413  353.419159  353.149994  \n",
       "3   353.891174  353.526825  353.149994  \n",
       "4   354.102966  353.634521  353.149994  \n",
       "..         ...         ...         ...  \n",
       "15  356.432404  354.818878  353.149994  \n",
       "16  356.644196  354.926544  353.149994  \n",
       "17  356.855957  355.034210  353.149994  \n",
       "18  357.067719  355.141876  353.149994  \n",
       "19  357.279480  355.249542  353.149994  \n",
       "\n",
       "[20 rows x 37 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Validation dataset\n",
    "for i in range(Fold):\n",
    "    \n",
    "    temp_Valid_Data   = TrainData.iloc[FoldDataNo*i:FoldDataNo*(i+1) ,:]\n",
    "    s1 = 'ValidData_Fold%d = temp_Valid_Data'%(i+1)\n",
    "    exec(s1)\n",
    "    \n",
    "    temp_Valid_Label  = TrainLabel.iloc[FoldDataNo*i:FoldDataNo*(i+1) ,:]\n",
    "    s2 = 'ValidLabel_Fold%d = temp_Valid_Label'%(i+1)\n",
    "    exec(s2)\n",
    "\n",
    "ValidData_Fold1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 37), (80, 1))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training Dataset\n",
    "for i in range(Fold):\n",
    "    temp_Train_Data_Front = TrainData.iloc[:FoldDataNo*i,:]\n",
    "    temp_Train_Data_Back  = TrainData.iloc[FoldDataNo*(i+1):,:]\n",
    "    temp_Train_Data_Total = np.concatenate([temp_Train_Data_Front , temp_Train_Data_Back] , axis=0)\n",
    "    s1 ='TrainData_Fold%d  = temp_Train_Data_Total'%(i+1)\n",
    "    exec(s1)\n",
    "\n",
    "    temp_Train_Label_Front = TrainLabel.iloc[:FoldDataNo*i,:]\n",
    "    temp_Train_Label_Back  = TrainLabel.iloc[FoldDataNo*(i+1):,:]\n",
    "    temp_Train_Label_Total = np.concatenate([temp_Train_Label_Front , temp_Train_Label_Back] , axis=0)\n",
    "    s2 ='TrainLabel_Fold%d  = temp_Train_Label_Total'%(i+1)\n",
    "    exec(s2)\n",
    "    \n",
    "TrainData_Fold1.shape , TrainLabel_Fold1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "Model = ['thickness']\n",
    "\n",
    "# 고정 하이퍼파라미터 : 입력/출력층 뉴런 수, 학습 Epoch 수\n",
    "noOfNeuron_in  = 50\n",
    "noOfNeuron_out = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:170.55556,   MAE: 170.50270,  MAPE: 15898.43%\n",
      "[100 Epochs]    RMSE:15.60844,   MAE: 15.34535,  MAPE: 1450.60%\n",
      "[200 Epochs]    RMSE:9.06560,   MAE: 8.68158,  MAPE: 822.31%\n",
      "[300 Epochs]    RMSE:2.39694,   MAE: 1.88579,  MAPE: 176.50%\n",
      "[400 Epochs]    RMSE:2.53673,   MAE: 2.08139,  MAPE: 197.35%\n",
      "[500 Epochs]    RMSE:2.20820,   MAE: 1.83718,  MAPE: 173.52%\n",
      "[600 Epochs]    RMSE:2.04098,   MAE: 1.75951,  MAPE: 166.99%\n",
      "[700 Epochs]    RMSE:12.61699,   MAE: 12.56280,  MAPE: 1173.39%\n",
      "[800 Epochs]    RMSE:9.69480,   MAE: 9.61541,  MAPE: 905.46%\n",
      "[900 Epochs]    RMSE:8.58286,   MAE: 8.48443,  MAPE: 784.39%\n",
      "[1000 Epochs]    RMSE:6.87056,   MAE: 6.75680,  MAPE: 641.94%\n",
      "[1100 Epochs]    RMSE:1.82644,   MAE: 1.45337,  MAPE: 132.17%\n",
      "[1200 Epochs]    RMSE:0.98747,   MAE: 0.80905,  MAPE: 71.57%\n",
      "[1300 Epochs]    RMSE:0.61946,   MAE: 0.49358,  MAPE: 46.59%\n",
      "[1400 Epochs]    RMSE:7.78547,   MAE: 7.72351,  MAPE: 732.84%\n",
      "[1500 Epochs]    RMSE:3.60039,   MAE: 3.43238,  MAPE: 307.74%\n",
      "[1600 Epochs]    RMSE:1.94888,   MAE: 1.73783,  MAPE: 173.41%\n",
      "[1700 Epochs]    RMSE:1.15489,   MAE: 0.97132,  MAPE: 87.71%\n",
      "[1800 Epochs]    RMSE:1.15504,   MAE: 0.98688,  MAPE: 88.36%\n",
      "[1900 Epochs]    RMSE:1.13551,   MAE: 0.98058,  MAPE: 87.63%\n",
      "[2000 Epochs]    RMSE:1.04616,   MAE: 0.89724,  MAPE: 79.70%\n",
      "[2100 Epochs]    RMSE:0.93254,   MAE: 0.78598,  MAPE: 69.26%\n",
      "[2200 Epochs]    RMSE:1.04238,   MAE: 0.90906,  MAPE: 79.94%\n",
      "[2300 Epochs]    RMSE:0.82809,   MAE: 0.69269,  MAPE: 60.71%\n",
      "[2400 Epochs]    RMSE:0.96550,   MAE: 0.84713,  MAPE: 74.75%\n",
      "[2500 Epochs]    RMSE:0.87716,   MAE: 0.75679,  MAPE: 66.34%\n",
      "[2600 Epochs]    RMSE:1.03071,   MAE: 0.93731,  MAPE: 84.22%\n",
      "[2700 Epochs]    RMSE:0.66984,   MAE: 0.55806,  MAPE: 49.23%\n",
      "[2800 Epochs]    RMSE:0.79134,   MAE: 0.68941,  MAPE: 60.71%\n",
      "[2900 Epochs]    RMSE:0.73845,   MAE: 0.63985,  MAPE: 56.65%\n",
      "[3000 Epochs]    RMSE:0.70506,   MAE: 0.61303,  MAPE: 54.39%\n",
      "[3100 Epochs]    RMSE:0.52016,   MAE: 0.42673,  MAPE: 37.81%\n",
      "[3200 Epochs]    RMSE:0.56137,   MAE: 0.47859,  MAPE: 41.87%\n",
      "[3300 Epochs]    RMSE:0.67852,   MAE: 0.60926,  MAPE: 54.01%\n",
      "[3400 Epochs]    RMSE:0.52944,   MAE: 0.46187,  MAPE: 41.03%\n",
      "[3500 Epochs]    RMSE:0.43085,   MAE: 0.35476,  MAPE: 31.29%\n",
      "[3600 Epochs]    RMSE:0.40859,   MAE: 0.33894,  MAPE: 30.20%\n",
      "[3700 Epochs]    RMSE:0.20285,   MAE: 0.17154,  MAPE: 16.60%\n",
      "[3800 Epochs]    RMSE:0.47841,   MAE: 0.43204,  MAPE: 43.28%\n",
      "[3900 Epochs]    RMSE:0.38825,   MAE: 0.32797,  MAPE: 33.66%\n",
      "[4000 Epochs]    RMSE:0.33864,   MAE: 0.27634,  MAPE: 28.80%\n",
      "[4100 Epochs]    RMSE:0.33908,   MAE: 0.28508,  MAPE: 28.82%\n",
      "[4200 Epochs]    RMSE:0.27504,   MAE: 0.23457,  MAPE: 23.53%\n",
      "[4300 Epochs]    RMSE:0.15260,   MAE: 0.11983,  MAPE: 11.41%\n",
      "[4400 Epochs]    RMSE:0.38742,   MAE: 0.34731,  MAPE: 34.94%\n",
      "[4500 Epochs]    RMSE:0.14174,   MAE: 0.11118,  MAPE: 10.59%\n",
      "[4600 Epochs]    RMSE:0.48163,   MAE: 0.45665,  MAPE: 41.35%\n",
      "[4700 Epochs]    RMSE:0.12480,   MAE: 0.09945,  MAPE: 9.52%\n",
      "[4800 Epochs]    RMSE:0.12855,   MAE: 0.10242,  MAPE: 10.16%\n",
      "[4900 Epochs]    RMSE:0.13688,   MAE: 0.11076,  MAPE: 10.89%\n",
      "[5000 Epochs]    RMSE:0.19236,   MAE: 0.16347,  MAPE: 14.78%\n",
      "[5100 Epochs]    RMSE:0.24311,   MAE: 0.21153,  MAPE: 18.58%\n",
      "[5200 Epochs]    RMSE:0.15990,   MAE: 0.13168,  MAPE: 11.55%\n",
      "[5300 Epochs]    RMSE:0.20440,   MAE: 0.17539,  MAPE: 15.13%\n",
      "[5400 Epochs]    RMSE:0.11033,   MAE: 0.07974,  MAPE: 7.35%\n",
      "[5500 Epochs]    RMSE:0.19975,   MAE: 0.17301,  MAPE: 17.70%\n",
      "[5600 Epochs]    RMSE:0.10907,   MAE: 0.08778,  MAPE: 8.83%\n",
      "[5700 Epochs]    RMSE:0.34280,   MAE: 0.32273,  MAPE: 29.12%\n",
      "[5800 Epochs]    RMSE:0.08724,   MAE: 0.06599,  MAPE: 6.26%\n",
      "[5900 Epochs]    RMSE:0.12562,   MAE: 0.10332,  MAPE: 9.27%\n",
      "[6000 Epochs]    RMSE:0.11806,   MAE: 0.09788,  MAPE: 8.64%\n",
      "[6100 Epochs]    RMSE:0.17042,   MAE: 0.14392,  MAPE: 13.31%\n",
      "[6200 Epochs]    RMSE:0.08559,   MAE: 0.06504,  MAPE: 6.48%\n",
      "[6300 Epochs]    RMSE:0.08242,   MAE: 0.06283,  MAPE: 6.40%\n",
      "[6400 Epochs]    RMSE:0.12597,   MAE: 0.10729,  MAPE: 9.42%\n",
      "[6500 Epochs]    RMSE:0.08085,   MAE: 0.05965,  MAPE: 5.45%\n",
      "[6600 Epochs]    RMSE:0.08741,   MAE: 0.06573,  MAPE: 6.49%\n",
      "[6700 Epochs]    RMSE:0.11167,   MAE: 0.09362,  MAPE: 8.24%\n",
      "[6800 Epochs]    RMSE:0.07665,   MAE: 0.05927,  MAPE: 5.51%\n",
      "[6900 Epochs]    RMSE:0.07338,   MAE: 0.05586,  MAPE: 5.20%\n",
      "[7000 Epochs]    RMSE:0.13906,   MAE: 0.09912,  MAPE: 9.67%\n",
      "[7100 Epochs]    RMSE:0.17158,   MAE: 0.15376,  MAPE: 15.15%\n",
      "[7200 Epochs]    RMSE:0.11019,   MAE: 0.08610,  MAPE: 9.12%\n",
      "[7300 Epochs]    RMSE:0.12155,   MAE: 0.10247,  MAPE: 9.18%\n",
      "[7400 Epochs]    RMSE:0.08561,   MAE: 0.06793,  MAPE: 6.68%\n",
      "[7500 Epochs]    RMSE:0.09015,   MAE: 0.06951,  MAPE: 6.91%\n",
      "[7600 Epochs]    RMSE:0.11473,   MAE: 0.09672,  MAPE: 9.73%\n",
      "[7700 Epochs]    RMSE:0.08218,   MAE: 0.06181,  MAPE: 5.94%\n",
      "[7800 Epochs]    RMSE:0.12602,   MAE: 0.10750,  MAPE: 10.96%\n",
      "[7900 Epochs]    RMSE:0.17098,   MAE: 0.15003,  MAPE: 14.11%\n",
      "[8000 Epochs]    RMSE:0.21602,   MAE: 0.19832,  MAPE: 19.45%\n",
      "[8100 Epochs]    RMSE:0.13323,   MAE: 0.11976,  MAPE: 10.57%\n",
      "[8200 Epochs]    RMSE:0.07276,   MAE: 0.05752,  MAPE: 5.67%\n",
      "[8300 Epochs]    RMSE:0.15166,   MAE: 0.12967,  MAPE: 11.33%\n",
      "[8400 Epochs]    RMSE:0.09266,   MAE: 0.07210,  MAPE: 7.02%\n",
      "[8500 Epochs]    RMSE:0.08595,   MAE: 0.07175,  MAPE: 7.20%\n",
      "[8600 Epochs]    RMSE:0.23494,   MAE: 0.21703,  MAPE: 19.96%\n",
      "[8700 Epochs]    RMSE:0.12474,   MAE: 0.10529,  MAPE: 9.61%\n",
      "[8800 Epochs]    RMSE:0.09888,   MAE: 0.08256,  MAPE: 7.84%\n",
      "[8900 Epochs]    RMSE:0.08811,   MAE: 0.07363,  MAPE: 6.46%\n",
      "[9000 Epochs]    RMSE:0.14106,   MAE: 0.11540,  MAPE: 11.52%\n",
      "[9100 Epochs]    RMSE:0.11137,   MAE: 0.09607,  MAPE: 9.41%\n",
      "[9200 Epochs]    RMSE:0.09527,   MAE: 0.07954,  MAPE: 7.34%\n",
      "[9300 Epochs]    RMSE:0.11071,   MAE: 0.09046,  MAPE: 8.59%\n",
      "[9400 Epochs]    RMSE:0.11584,   MAE: 0.10421,  MAPE: 9.44%\n",
      "[9500 Epochs]    RMSE:0.08803,   MAE: 0.07533,  MAPE: 7.16%\n",
      "[9600 Epochs]    RMSE:0.09250,   MAE: 0.07443,  MAPE: 7.43%\n",
      "[9700 Epochs]    RMSE:0.14436,   MAE: 0.12302,  MAPE: 11.30%\n",
      "[9800 Epochs]    RMSE:0.15686,   MAE: 0.12711,  MAPE: 12.55%\n",
      "[9900 Epochs]    RMSE:0.08851,   MAE: 0.07514,  MAPE: 7.49%\n",
      "[10000 Epochs]    RMSE:0.09467,   MAE: 0.07596,  MAPE: 7.77%\n",
      "[10100 Epochs]    RMSE:0.09710,   MAE: 0.08425,  MAPE: 7.55%\n",
      "[10200 Epochs]    RMSE:0.07909,   MAE: 0.06004,  MAPE: 6.16%\n",
      "[10300 Epochs]    RMSE:0.23203,   MAE: 0.21741,  MAPE: 21.47%\n",
      "[10400 Epochs]    RMSE:0.08518,   MAE: 0.06220,  MAPE: 6.46%\n",
      "[10500 Epochs]    RMSE:0.08482,   MAE: 0.06733,  MAPE: 6.23%\n",
      "[10600 Epochs]    RMSE:0.07396,   MAE: 0.05558,  MAPE: 5.77%\n",
      "[10700 Epochs]    RMSE:0.07582,   MAE: 0.05543,  MAPE: 5.63%\n",
      "[10800 Epochs]    RMSE:0.16480,   MAE: 0.14795,  MAPE: 13.57%\n",
      "[10900 Epochs]    RMSE:0.08467,   MAE: 0.05924,  MAPE: 6.11%\n",
      "[11000 Epochs]    RMSE:0.06779,   MAE: 0.05357,  MAPE: 5.14%\n",
      "[11100 Epochs]    RMSE:0.06653,   MAE: 0.04929,  MAPE: 4.80%\n",
      "[11200 Epochs]    RMSE:0.08092,   MAE: 0.05926,  MAPE: 5.89%\n",
      "[11300 Epochs]    RMSE:0.06183,   MAE: 0.04466,  MAPE: 4.41%\n",
      "[11400 Epochs]    RMSE:0.07752,   MAE: 0.06331,  MAPE: 5.87%\n",
      "[11500 Epochs]    RMSE:0.16000,   MAE: 0.14463,  MAPE: 13.22%\n",
      "[11600 Epochs]    RMSE:0.05963,   MAE: 0.04487,  MAPE: 4.16%\n",
      "[11700 Epochs]    RMSE:0.09066,   MAE: 0.06729,  MAPE: 6.55%\n",
      "[11800 Epochs]    RMSE:0.06083,   MAE: 0.04827,  MAPE: 4.67%\n",
      "[11900 Epochs]    RMSE:0.05520,   MAE: 0.03931,  MAPE: 3.95%\n",
      "[12000 Epochs]    RMSE:0.06155,   MAE: 0.04687,  MAPE: 4.53%\n",
      "[12100 Epochs]    RMSE:0.07766,   MAE: 0.05653,  MAPE: 5.59%\n",
      "[12200 Epochs]    RMSE:0.09447,   MAE: 0.08382,  MAPE: 8.09%\n",
      "[12300 Epochs]    RMSE:0.07725,   MAE: 0.05906,  MAPE: 5.90%\n",
      "[12400 Epochs]    RMSE:0.07410,   MAE: 0.06052,  MAPE: 6.05%\n",
      "[12500 Epochs]    RMSE:0.09505,   MAE: 0.07884,  MAPE: 8.01%\n",
      "[12600 Epochs]    RMSE:0.08281,   MAE: 0.07171,  MAPE: 6.46%\n",
      "[12700 Epochs]    RMSE:0.12811,   MAE: 0.09666,  MAPE: 8.95%\n",
      "[12800 Epochs]    RMSE:0.19474,   MAE: 0.17405,  MAPE: 15.26%\n",
      "[12900 Epochs]    RMSE:0.10648,   MAE: 0.08739,  MAPE: 7.92%\n",
      "[13000 Epochs]    RMSE:0.05178,   MAE: 0.04145,  MAPE: 3.96%\n",
      "[13100 Epochs]    RMSE:0.14717,   MAE: 0.12932,  MAPE: 11.12%\n",
      "[13200 Epochs]    RMSE:0.06635,   MAE: 0.05290,  MAPE: 5.40%\n",
      "[13300 Epochs]    RMSE:0.07660,   MAE: 0.05796,  MAPE: 6.16%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13400 Epochs]    RMSE:0.05728,   MAE: 0.04464,  MAPE: 4.38%\n",
      "[13500 Epochs]    RMSE:0.10015,   MAE: 0.09016,  MAPE: 8.17%\n",
      "[13600 Epochs]    RMSE:0.06985,   MAE: 0.05245,  MAPE: 5.42%\n",
      "[13700 Epochs]    RMSE:0.03561,   MAE: 0.02636,  MAPE: 2.68%\n",
      "[13800 Epochs]    RMSE:0.06393,   MAE: 0.05559,  MAPE: 4.93%\n",
      "[13900 Epochs]    RMSE:0.15494,   MAE: 0.15009,  MAPE: 14.31%\n",
      "[14000 Epochs]    RMSE:0.03955,   MAE: 0.02933,  MAPE: 2.90%\n",
      "[14100 Epochs]    RMSE:0.17799,   MAE: 0.17195,  MAPE: 16.40%\n",
      "[14200 Epochs]    RMSE:0.09176,   MAE: 0.06833,  MAPE: 6.58%\n",
      "[14300 Epochs]    RMSE:0.09330,   MAE: 0.08234,  MAPE: 7.44%\n",
      "[14400 Epochs]    RMSE:0.06682,   MAE: 0.04961,  MAPE: 5.00%\n",
      "[14500 Epochs]    RMSE:0.07823,   MAE: 0.05947,  MAPE: 5.83%\n",
      "[14600 Epochs]    RMSE:0.08883,   MAE: 0.07830,  MAPE: 7.73%\n",
      "[14700 Epochs]    RMSE:0.04033,   MAE: 0.03019,  MAPE: 2.98%\n",
      "[14800 Epochs]    RMSE:0.15786,   MAE: 0.14828,  MAPE: 13.05%\n",
      "[14900 Epochs]    RMSE:0.10480,   MAE: 0.08048,  MAPE: 8.51%\n",
      "[15000 Epochs]    RMSE:0.07942,   MAE: 0.06475,  MAPE: 5.97%\n",
      "[15100 Epochs]    RMSE:0.10695,   MAE: 0.09743,  MAPE: 9.12%\n",
      "[15200 Epochs]    RMSE:0.06056,   MAE: 0.04785,  MAPE: 4.46%\n",
      "[15300 Epochs]    RMSE:0.08098,   MAE: 0.06699,  MAPE: 6.62%\n",
      "[15400 Epochs]    RMSE:0.05237,   MAE: 0.03893,  MAPE: 4.01%\n",
      "[15500 Epochs]    RMSE:0.11204,   MAE: 0.10047,  MAPE: 8.88%\n",
      "[15600 Epochs]    RMSE:0.13300,   MAE: 0.12357,  MAPE: 11.59%\n",
      "[15700 Epochs]    RMSE:0.05953,   MAE: 0.05037,  MAPE: 4.79%\n",
      "[15800 Epochs]    RMSE:0.08299,   MAE: 0.05884,  MAPE: 5.77%\n",
      "[15900 Epochs]    RMSE:0.03967,   MAE: 0.03294,  MAPE: 3.06%\n",
      "[16000 Epochs]    RMSE:0.16783,   MAE: 0.15543,  MAPE: 13.77%\n",
      "[16100 Epochs]    RMSE:0.04147,   MAE: 0.03285,  MAPE: 3.19%\n",
      "[16200 Epochs]    RMSE:0.06715,   MAE: 0.05255,  MAPE: 5.18%\n",
      "[16300 Epochs]    RMSE:0.09252,   MAE: 0.08353,  MAPE: 8.20%\n",
      "[16400 Epochs]    RMSE:0.07390,   MAE: 0.05213,  MAPE: 5.88%\n",
      "[16500 Epochs]    RMSE:0.08088,   MAE: 0.06159,  MAPE: 6.02%\n",
      "[16600 Epochs]    RMSE:0.06578,   MAE: 0.05204,  MAPE: 5.52%\n",
      "[16700 Epochs]    RMSE:0.04705,   MAE: 0.03386,  MAPE: 3.18%\n",
      "[16800 Epochs]    RMSE:0.08939,   MAE: 0.08197,  MAPE: 7.31%\n",
      "[16900 Epochs]    RMSE:0.03873,   MAE: 0.02665,  MAPE: 2.62%\n",
      "[17000 Epochs]    RMSE:0.03082,   MAE: 0.02187,  MAPE: 2.16%\n",
      "[17100 Epochs]    RMSE:0.09188,   MAE: 0.07976,  MAPE: 7.90%\n",
      "[17200 Epochs]    RMSE:0.04723,   MAE: 0.03767,  MAPE: 3.52%\n",
      "[17300 Epochs]    RMSE:0.03325,   MAE: 0.02557,  MAPE: 2.42%\n",
      "[17400 Epochs]    RMSE:0.08151,   MAE: 0.06754,  MAPE: 6.56%\n",
      "[17500 Epochs]    RMSE:0.10833,   MAE: 0.08197,  MAPE: 8.42%\n",
      "[17600 Epochs]    RMSE:0.08316,   MAE: 0.07554,  MAPE: 6.57%\n",
      "[17700 Epochs]    RMSE:0.02859,   MAE: 0.02132,  MAPE: 2.17%\n",
      "[17800 Epochs]    RMSE:0.04490,   MAE: 0.03315,  MAPE: 3.38%\n",
      "[17900 Epochs]    RMSE:0.05935,   MAE: 0.04627,  MAPE: 4.49%\n",
      "[18000 Epochs]    RMSE:0.10570,   MAE: 0.09267,  MAPE: 8.51%\n",
      "[18100 Epochs]    RMSE:0.07585,   MAE: 0.06984,  MAPE: 6.45%\n",
      "[18200 Epochs]    RMSE:0.06118,   MAE: 0.04512,  MAPE: 4.43%\n",
      "[18300 Epochs]    RMSE:0.08803,   MAE: 0.06964,  MAPE: 6.79%\n",
      "[18400 Epochs]    RMSE:0.05819,   MAE: 0.04358,  MAPE: 4.43%\n",
      "[18500 Epochs]    RMSE:0.05579,   MAE: 0.04297,  MAPE: 4.56%\n",
      "[18600 Epochs]    RMSE:0.03987,   MAE: 0.03069,  MAPE: 2.81%\n",
      "[18700 Epochs]    RMSE:0.03181,   MAE: 0.02678,  MAPE: 2.61%\n",
      "[18800 Epochs]    RMSE:0.05428,   MAE: 0.04529,  MAPE: 4.23%\n",
      "[18900 Epochs]    RMSE:0.02931,   MAE: 0.02070,  MAPE: 2.04%\n",
      "[19000 Epochs]    RMSE:0.05735,   MAE: 0.04045,  MAPE: 4.08%\n",
      "[19100 Epochs]    RMSE:0.03260,   MAE: 0.02662,  MAPE: 2.57%\n",
      "[19200 Epochs]    RMSE:0.04390,   MAE: 0.03658,  MAPE: 3.45%\n",
      "[19300 Epochs]    RMSE:0.03379,   MAE: 0.02628,  MAPE: 2.53%\n",
      "[19400 Epochs]    RMSE:0.06561,   MAE: 0.05973,  MAPE: 5.28%\n",
      "[19500 Epochs]    RMSE:0.08740,   MAE: 0.07804,  MAPE: 7.62%\n",
      "[19600 Epochs]    RMSE:0.03896,   MAE: 0.02889,  MAPE: 2.99%\n",
      "[19700 Epochs]    RMSE:0.02490,   MAE: 0.01826,  MAPE: 1.77%\n",
      "[19800 Epochs]    RMSE:0.07488,   MAE: 0.06864,  MAPE: 6.46%\n",
      "[19900 Epochs]    RMSE:0.03432,   MAE: 0.02622,  MAPE: 2.51%\n",
      "\n",
      "[Final Epochs]    RMSE:0.02598,   MAE: 0.02089,  MAPE: 2.04%\n",
      "\n",
      "\n",
      "\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:90.67575,   MAE: 90.64285,  MAPE: 8645.11%\n",
      "[100 Epochs]    RMSE:1.39757,   MAE: 1.10672,  MAPE: 99.98%\n",
      "[200 Epochs]    RMSE:1.26257,   MAE: 1.03112,  MAPE: 99.44%\n",
      "[300 Epochs]    RMSE:1.07117,   MAE: 0.90317,  MAPE: 83.25%\n",
      "[400 Epochs]    RMSE:2.73431,   MAE: 2.63638,  MAPE: 252.07%\n",
      "[500 Epochs]    RMSE:2.31416,   MAE: 2.20653,  MAPE: 212.33%\n",
      "[600 Epochs]    RMSE:1.64701,   MAE: 1.55486,  MAPE: 153.27%\n",
      "[700 Epochs]    RMSE:1.91996,   MAE: 1.84590,  MAPE: 181.27%\n",
      "[800 Epochs]    RMSE:1.88667,   MAE: 1.83212,  MAPE: 170.65%\n",
      "[900 Epochs]    RMSE:1.51590,   MAE: 1.42762,  MAPE: 130.01%\n",
      "[1000 Epochs]    RMSE:1.46091,   MAE: 1.37343,  MAPE: 124.92%\n",
      "[1100 Epochs]    RMSE:1.37452,   MAE: 1.28791,  MAPE: 116.84%\n",
      "[1200 Epochs]    RMSE:1.17345,   MAE: 1.07869,  MAPE: 96.92%\n",
      "[1300 Epochs]    RMSE:1.15262,   MAE: 1.06762,  MAPE: 96.09%\n",
      "[1400 Epochs]    RMSE:1.02184,   MAE: 0.92740,  MAPE: 82.39%\n",
      "[1500 Epochs]    RMSE:0.96665,   MAE: 0.88078,  MAPE: 78.26%\n",
      "[1600 Epochs]    RMSE:1.16837,   MAE: 1.11100,  MAPE: 100.79%\n",
      "[1700 Epochs]    RMSE:0.65061,   MAE: 0.56451,  MAPE: 49.07%\n",
      "[1800 Epochs]    RMSE:0.78597,   MAE: 0.71341,  MAPE: 62.86%\n",
      "[1900 Epochs]    RMSE:0.89038,   MAE: 0.83260,  MAPE: 74.62%\n",
      "[2000 Epochs]    RMSE:0.76294,   MAE: 0.72635,  MAPE: 72.73%\n",
      "[2100 Epochs]    RMSE:0.74069,   MAE: 0.68374,  MAPE: 67.55%\n",
      "[2200 Epochs]    RMSE:0.44746,   MAE: 0.37524,  MAPE: 39.97%\n",
      "[2300 Epochs]    RMSE:0.74949,   MAE: 0.70363,  MAPE: 71.68%\n",
      "[2400 Epochs]    RMSE:0.62133,   MAE: 0.56822,  MAPE: 57.83%\n",
      "[2500 Epochs]    RMSE:0.52929,   MAE: 0.46470,  MAPE: 48.59%\n",
      "[2600 Epochs]    RMSE:0.68117,   MAE: 0.64542,  MAPE: 57.93%\n",
      "[2700 Epochs]    RMSE:0.63783,   MAE: 0.59097,  MAPE: 52.49%\n",
      "[2800 Epochs]    RMSE:0.53838,   MAE: 0.49150,  MAPE: 43.15%\n",
      "[2900 Epochs]    RMSE:0.52698,   MAE: 0.48492,  MAPE: 42.96%\n",
      "[3000 Epochs]    RMSE:0.54125,   MAE: 0.50526,  MAPE: 44.99%\n",
      "[3100 Epochs]    RMSE:0.48164,   MAE: 0.44845,  MAPE: 39.93%\n",
      "[3200 Epochs]    RMSE:0.50706,   MAE: 0.47486,  MAPE: 42.02%\n",
      "[3300 Epochs]    RMSE:0.52483,   MAE: 0.49457,  MAPE: 44.62%\n",
      "[3400 Epochs]    RMSE:0.40919,   MAE: 0.37130,  MAPE: 32.26%\n",
      "[3500 Epochs]    RMSE:0.12508,   MAE: 0.09375,  MAPE: 9.20%\n",
      "[3600 Epochs]    RMSE:0.32741,   MAE: 0.26859,  MAPE: 28.20%\n",
      "[3700 Epochs]    RMSE:0.31499,   MAE: 0.28066,  MAPE: 29.13%\n",
      "[3800 Epochs]    RMSE:0.46424,   MAE: 0.44704,  MAPE: 44.68%\n",
      "[3900 Epochs]    RMSE:0.69372,   MAE: 0.66436,  MAPE: 66.28%\n",
      "[4000 Epochs]    RMSE:0.23889,   MAE: 0.21005,  MAPE: 18.26%\n",
      "[4100 Epochs]    RMSE:0.23393,   MAE: 0.15903,  MAPE: 13.92%\n",
      "[4200 Epochs]    RMSE:0.23178,   MAE: 0.21062,  MAPE: 18.59%\n",
      "[4300 Epochs]    RMSE:0.16457,   MAE: 0.14420,  MAPE: 12.89%\n",
      "[4400 Epochs]    RMSE:0.38175,   MAE: 0.35878,  MAPE: 32.62%\n",
      "[4500 Epochs]    RMSE:0.33807,   MAE: 0.31811,  MAPE: 28.30%\n",
      "[4600 Epochs]    RMSE:0.14999,   MAE: 0.12942,  MAPE: 11.51%\n",
      "[4700 Epochs]    RMSE:0.10631,   MAE: 0.08503,  MAPE: 8.88%\n",
      "[4800 Epochs]    RMSE:0.27274,   MAE: 0.25174,  MAPE: 25.92%\n",
      "[4900 Epochs]    RMSE:0.35661,   MAE: 0.33734,  MAPE: 31.06%\n",
      "[5000 Epochs]    RMSE:0.30668,   MAE: 0.29467,  MAPE: 29.25%\n",
      "[5100 Epochs]    RMSE:0.08036,   MAE: 0.06151,  MAPE: 6.00%\n",
      "[5200 Epochs]    RMSE:0.11883,   MAE: 0.09336,  MAPE: 8.87%\n",
      "[5300 Epochs]    RMSE:0.10699,   MAE: 0.08867,  MAPE: 8.07%\n",
      "[5400 Epochs]    RMSE:0.22362,   MAE: 0.19167,  MAPE: 19.61%\n",
      "[5500 Epochs]    RMSE:0.11901,   MAE: 0.09912,  MAPE: 9.13%\n",
      "[5600 Epochs]    RMSE:0.13595,   MAE: 0.12135,  MAPE: 12.11%\n",
      "[5700 Epochs]    RMSE:0.36677,   MAE: 0.31693,  MAPE: 27.34%\n",
      "[5800 Epochs]    RMSE:0.07885,   MAE: 0.05758,  MAPE: 5.48%\n",
      "[5900 Epochs]    RMSE:0.07400,   MAE: 0.05781,  MAPE: 5.83%\n",
      "[6000 Epochs]    RMSE:0.09875,   MAE: 0.07612,  MAPE: 7.79%\n",
      "[6100 Epochs]    RMSE:0.16967,   MAE: 0.14685,  MAPE: 15.23%\n",
      "[6200 Epochs]    RMSE:0.15175,   MAE: 0.13433,  MAPE: 12.52%\n",
      "[6300 Epochs]    RMSE:0.16153,   MAE: 0.13889,  MAPE: 14.56%\n",
      "[6400 Epochs]    RMSE:0.16641,   MAE: 0.13337,  MAPE: 12.48%\n",
      "[6500 Epochs]    RMSE:0.11026,   MAE: 0.09555,  MAPE: 8.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6600 Epochs]    RMSE:0.21904,   MAE: 0.19981,  MAPE: 18.14%\n",
      "[6700 Epochs]    RMSE:0.09365,   MAE: 0.07705,  MAPE: 7.93%\n",
      "[6800 Epochs]    RMSE:0.13804,   MAE: 0.11535,  MAPE: 10.58%\n",
      "[6900 Epochs]    RMSE:0.07338,   MAE: 0.05683,  MAPE: 5.66%\n",
      "[7000 Epochs]    RMSE:0.06399,   MAE: 0.04969,  MAPE: 5.02%\n",
      "[7100 Epochs]    RMSE:0.16213,   MAE: 0.14223,  MAPE: 12.95%\n",
      "[7200 Epochs]    RMSE:0.09011,   MAE: 0.06644,  MAPE: 6.89%\n",
      "[7300 Epochs]    RMSE:0.13852,   MAE: 0.12227,  MAPE: 11.41%\n",
      "[7400 Epochs]    RMSE:0.13615,   MAE: 0.12020,  MAPE: 12.14%\n",
      "[7500 Epochs]    RMSE:0.06999,   MAE: 0.05474,  MAPE: 5.09%\n",
      "[7600 Epochs]    RMSE:0.08144,   MAE: 0.06476,  MAPE: 6.92%\n",
      "[7700 Epochs]    RMSE:0.06674,   MAE: 0.05267,  MAPE: 5.15%\n",
      "[7800 Epochs]    RMSE:0.24640,   MAE: 0.19744,  MAPE: 20.42%\n",
      "[7900 Epochs]    RMSE:0.08170,   MAE: 0.06597,  MAPE: 6.58%\n",
      "[8000 Epochs]    RMSE:0.06220,   MAE: 0.04823,  MAPE: 4.83%\n",
      "[8100 Epochs]    RMSE:0.07805,   MAE: 0.05530,  MAPE: 5.10%\n",
      "[8200 Epochs]    RMSE:0.06731,   MAE: 0.05415,  MAPE: 5.42%\n",
      "[8300 Epochs]    RMSE:0.07662,   MAE: 0.06457,  MAPE: 6.42%\n",
      "[8400 Epochs]    RMSE:0.07401,   MAE: 0.05518,  MAPE: 5.26%\n",
      "[8500 Epochs]    RMSE:0.07697,   MAE: 0.06029,  MAPE: 6.32%\n",
      "[8600 Epochs]    RMSE:0.13080,   MAE: 0.08060,  MAPE: 7.98%\n",
      "[8700 Epochs]    RMSE:0.07038,   MAE: 0.05392,  MAPE: 4.80%\n",
      "[8800 Epochs]    RMSE:0.06066,   MAE: 0.04293,  MAPE: 4.10%\n",
      "[8900 Epochs]    RMSE:0.07265,   MAE: 0.05728,  MAPE: 5.62%\n",
      "[9000 Epochs]    RMSE:0.06850,   MAE: 0.05659,  MAPE: 5.54%\n",
      "[9100 Epochs]    RMSE:0.10702,   MAE: 0.08893,  MAPE: 8.04%\n",
      "[9200 Epochs]    RMSE:0.19489,   MAE: 0.16065,  MAPE: 16.42%\n",
      "[9300 Epochs]    RMSE:0.09452,   MAE: 0.07641,  MAPE: 7.72%\n",
      "[9400 Epochs]    RMSE:0.07855,   MAE: 0.05853,  MAPE: 5.73%\n",
      "[9500 Epochs]    RMSE:0.07384,   MAE: 0.05566,  MAPE: 5.17%\n",
      "[9600 Epochs]    RMSE:0.07487,   MAE: 0.05906,  MAPE: 6.09%\n",
      "[9700 Epochs]    RMSE:0.07316,   MAE: 0.05440,  MAPE: 5.24%\n",
      "[9800 Epochs]    RMSE:0.08684,   MAE: 0.06647,  MAPE: 6.26%\n",
      "[9900 Epochs]    RMSE:0.07957,   MAE: 0.05943,  MAPE: 6.26%\n",
      "[10000 Epochs]    RMSE:0.11365,   MAE: 0.09762,  MAPE: 9.86%\n",
      "[10100 Epochs]    RMSE:0.12089,   MAE: 0.10275,  MAPE: 10.61%\n",
      "[10200 Epochs]    RMSE:0.07695,   MAE: 0.05534,  MAPE: 5.34%\n",
      "[10300 Epochs]    RMSE:0.08595,   MAE: 0.06815,  MAPE: 6.94%\n",
      "[10400 Epochs]    RMSE:0.07433,   MAE: 0.05700,  MAPE: 5.72%\n",
      "[10500 Epochs]    RMSE:0.08011,   MAE: 0.06042,  MAPE: 5.79%\n",
      "[10600 Epochs]    RMSE:0.07310,   MAE: 0.05673,  MAPE: 5.67%\n",
      "[10700 Epochs]    RMSE:0.07606,   MAE: 0.05992,  MAPE: 6.16%\n",
      "[10800 Epochs]    RMSE:0.08092,   MAE: 0.06232,  MAPE: 6.62%\n",
      "[10900 Epochs]    RMSE:0.07301,   MAE: 0.05238,  MAPE: 5.64%\n",
      "[11000 Epochs]    RMSE:0.06054,   MAE: 0.04368,  MAPE: 4.23%\n",
      "[11100 Epochs]    RMSE:0.08168,   MAE: 0.06367,  MAPE: 6.07%\n",
      "[11200 Epochs]    RMSE:0.06025,   MAE: 0.04579,  MAPE: 4.66%\n",
      "[11300 Epochs]    RMSE:0.07038,   MAE: 0.05170,  MAPE: 5.27%\n",
      "[11400 Epochs]    RMSE:0.07963,   MAE: 0.05498,  MAPE: 5.49%\n",
      "[11500 Epochs]    RMSE:0.11693,   MAE: 0.09763,  MAPE: 10.24%\n",
      "[11600 Epochs]    RMSE:0.07404,   MAE: 0.05030,  MAPE: 5.58%\n",
      "[11700 Epochs]    RMSE:0.22437,   MAE: 0.19799,  MAPE: 17.09%\n",
      "[11800 Epochs]    RMSE:0.08880,   MAE: 0.06996,  MAPE: 7.18%\n",
      "[11900 Epochs]    RMSE:0.05788,   MAE: 0.04445,  MAPE: 4.21%\n",
      "[12000 Epochs]    RMSE:0.04993,   MAE: 0.03799,  MAPE: 3.81%\n",
      "[12100 Epochs]    RMSE:0.06117,   MAE: 0.05009,  MAPE: 5.02%\n",
      "[12200 Epochs]    RMSE:0.05456,   MAE: 0.03893,  MAPE: 3.98%\n",
      "[12300 Epochs]    RMSE:0.05618,   MAE: 0.04201,  MAPE: 4.45%\n",
      "[12400 Epochs]    RMSE:0.05274,   MAE: 0.03867,  MAPE: 4.13%\n",
      "[12500 Epochs]    RMSE:0.08073,   MAE: 0.06603,  MAPE: 6.58%\n",
      "[12600 Epochs]    RMSE:0.06968,   MAE: 0.06046,  MAPE: 5.79%\n",
      "[12700 Epochs]    RMSE:0.08232,   MAE: 0.06782,  MAPE: 6.70%\n",
      "[12800 Epochs]    RMSE:0.06298,   MAE: 0.04564,  MAPE: 4.43%\n",
      "[12900 Epochs]    RMSE:0.07656,   MAE: 0.05765,  MAPE: 6.15%\n",
      "[13000 Epochs]    RMSE:0.06484,   MAE: 0.05310,  MAPE: 4.86%\n",
      "[13100 Epochs]    RMSE:0.05355,   MAE: 0.04270,  MAPE: 3.92%\n",
      "[13200 Epochs]    RMSE:0.05853,   MAE: 0.04638,  MAPE: 4.32%\n",
      "[13300 Epochs]    RMSE:0.06643,   MAE: 0.05240,  MAPE: 5.26%\n",
      "[13400 Epochs]    RMSE:0.08252,   MAE: 0.07168,  MAPE: 6.85%\n",
      "[13500 Epochs]    RMSE:0.04175,   MAE: 0.02971,  MAPE: 3.00%\n",
      "[13600 Epochs]    RMSE:0.08215,   MAE: 0.06241,  MAPE: 6.70%\n",
      "[13700 Epochs]    RMSE:0.07912,   MAE: 0.06112,  MAPE: 6.07%\n",
      "[13800 Epochs]    RMSE:0.05130,   MAE: 0.04194,  MAPE: 4.10%\n",
      "[13900 Epochs]    RMSE:0.05866,   MAE: 0.04961,  MAPE: 4.71%\n",
      "[14000 Epochs]    RMSE:0.14837,   MAE: 0.14283,  MAPE: 13.50%\n",
      "[14100 Epochs]    RMSE:0.05981,   MAE: 0.04648,  MAPE: 5.03%\n",
      "[14200 Epochs]    RMSE:0.11605,   MAE: 0.10512,  MAPE: 9.72%\n",
      "[14300 Epochs]    RMSE:0.04884,   MAE: 0.03947,  MAPE: 3.72%\n",
      "[14400 Epochs]    RMSE:0.07988,   MAE: 0.05725,  MAPE: 5.54%\n",
      "[14500 Epochs]    RMSE:0.07348,   MAE: 0.05583,  MAPE: 5.27%\n",
      "[14600 Epochs]    RMSE:0.09267,   MAE: 0.07488,  MAPE: 7.67%\n",
      "[14700 Epochs]    RMSE:0.08045,   MAE: 0.07098,  MAPE: 6.45%\n",
      "[14800 Epochs]    RMSE:0.06957,   MAE: 0.05467,  MAPE: 5.57%\n",
      "[14900 Epochs]    RMSE:0.06655,   MAE: 0.05522,  MAPE: 5.21%\n",
      "[15000 Epochs]    RMSE:0.03830,   MAE: 0.02953,  MAPE: 2.82%\n",
      "[15100 Epochs]    RMSE:0.03285,   MAE: 0.02567,  MAPE: 2.59%\n",
      "[15200 Epochs]    RMSE:0.04393,   MAE: 0.03394,  MAPE: 3.61%\n",
      "[15300 Epochs]    RMSE:0.10251,   MAE: 0.08966,  MAPE: 7.95%\n",
      "[15400 Epochs]    RMSE:0.07969,   MAE: 0.07002,  MAPE: 7.18%\n",
      "[15500 Epochs]    RMSE:0.07115,   MAE: 0.05387,  MAPE: 5.30%\n",
      "[15600 Epochs]    RMSE:0.05280,   MAE: 0.04378,  MAPE: 4.21%\n",
      "[15700 Epochs]    RMSE:0.08730,   MAE: 0.07681,  MAPE: 6.91%\n",
      "[15800 Epochs]    RMSE:0.07683,   MAE: 0.05415,  MAPE: 5.26%\n",
      "[15900 Epochs]    RMSE:0.03434,   MAE: 0.02839,  MAPE: 2.86%\n",
      "[16000 Epochs]    RMSE:0.06194,   MAE: 0.05366,  MAPE: 4.71%\n",
      "[16100 Epochs]    RMSE:0.03542,   MAE: 0.02936,  MAPE: 2.72%\n",
      "[16200 Epochs]    RMSE:0.03833,   MAE: 0.03186,  MAPE: 3.17%\n",
      "[16300 Epochs]    RMSE:0.03079,   MAE: 0.02393,  MAPE: 2.31%\n",
      "[16400 Epochs]    RMSE:0.03420,   MAE: 0.02826,  MAPE: 2.66%\n",
      "[16500 Epochs]    RMSE:0.03989,   MAE: 0.03471,  MAPE: 3.31%\n",
      "[16600 Epochs]    RMSE:0.03349,   MAE: 0.02755,  MAPE: 2.71%\n",
      "[16700 Epochs]    RMSE:0.03836,   MAE: 0.03255,  MAPE: 3.12%\n",
      "[16800 Epochs]    RMSE:0.05838,   MAE: 0.05047,  MAPE: 4.97%\n",
      "[16900 Epochs]    RMSE:0.05653,   MAE: 0.04845,  MAPE: 4.33%\n",
      "[17000 Epochs]    RMSE:0.04983,   MAE: 0.04150,  MAPE: 3.65%\n",
      "[17100 Epochs]    RMSE:0.03966,   MAE: 0.03218,  MAPE: 3.20%\n",
      "[17200 Epochs]    RMSE:0.03657,   MAE: 0.03075,  MAPE: 2.84%\n",
      "[17300 Epochs]    RMSE:0.02717,   MAE: 0.02249,  MAPE: 2.19%\n",
      "[17400 Epochs]    RMSE:0.02687,   MAE: 0.02092,  MAPE: 2.02%\n",
      "[17500 Epochs]    RMSE:0.02872,   MAE: 0.02253,  MAPE: 2.18%\n",
      "[17600 Epochs]    RMSE:0.04220,   MAE: 0.03500,  MAPE: 3.11%\n",
      "[17700 Epochs]    RMSE:0.02544,   MAE: 0.01994,  MAPE: 1.87%\n",
      "[17800 Epochs]    RMSE:0.04787,   MAE: 0.04096,  MAPE: 3.66%\n",
      "[17900 Epochs]    RMSE:0.03604,   MAE: 0.03094,  MAPE: 2.93%\n",
      "[18000 Epochs]    RMSE:0.03129,   MAE: 0.02461,  MAPE: 2.44%\n",
      "[18100 Epochs]    RMSE:0.08186,   MAE: 0.07261,  MAPE: 7.10%\n",
      "[18200 Epochs]    RMSE:0.06063,   MAE: 0.05372,  MAPE: 5.12%\n",
      "[18300 Epochs]    RMSE:0.03464,   MAE: 0.02812,  MAPE: 2.51%\n",
      "[18400 Epochs]    RMSE:0.03938,   MAE: 0.03292,  MAPE: 3.07%\n",
      "[18500 Epochs]    RMSE:0.07566,   MAE: 0.05894,  MAPE: 6.25%\n",
      "[18600 Epochs]    RMSE:0.03830,   MAE: 0.03113,  MAPE: 3.06%\n",
      "[18700 Epochs]    RMSE:0.03265,   MAE: 0.02589,  MAPE: 2.44%\n",
      "[18800 Epochs]    RMSE:0.02680,   MAE: 0.02163,  MAPE: 2.09%\n",
      "[18900 Epochs]    RMSE:0.05533,   MAE: 0.04829,  MAPE: 4.36%\n",
      "[19000 Epochs]    RMSE:0.03452,   MAE: 0.02832,  MAPE: 2.59%\n",
      "[19100 Epochs]    RMSE:0.03321,   MAE: 0.02779,  MAPE: 2.86%\n",
      "[19200 Epochs]    RMSE:0.04060,   MAE: 0.03380,  MAPE: 3.05%\n",
      "[19300 Epochs]    RMSE:0.04825,   MAE: 0.04097,  MAPE: 3.70%\n",
      "[19400 Epochs]    RMSE:0.05353,   MAE: 0.04844,  MAPE: 4.47%\n",
      "[19500 Epochs]    RMSE:0.03011,   MAE: 0.02417,  MAPE: 2.27%\n",
      "[19600 Epochs]    RMSE:0.06083,   MAE: 0.05664,  MAPE: 5.39%\n",
      "[19700 Epochs]    RMSE:0.03055,   MAE: 0.02396,  MAPE: 2.32%\n",
      "[19800 Epochs]    RMSE:0.04523,   MAE: 0.03762,  MAPE: 3.34%\n",
      "[19900 Epochs]    RMSE:0.02943,   MAE: 0.02302,  MAPE: 2.08%\n",
      "\n",
      "[Final Epochs]    RMSE:0.05483,   MAE: 0.04997,  MAPE: 4.86%\n",
      "\n",
      "\n",
      "\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 30\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 Epochs]    RMSE:181.82441,   MAE: 181.79935,  MAPE: 16842.93%\n",
      "[100 Epochs]    RMSE:1.33981,   MAE: 1.07920,  MAPE: 101.66%\n",
      "[200 Epochs]    RMSE:1.03219,   MAE: 0.83809,  MAPE: 78.70%\n",
      "[300 Epochs]    RMSE:3.62686,   MAE: 3.54020,  MAPE: 329.59%\n",
      "[400 Epochs]    RMSE:1.51248,   MAE: 1.33133,  MAPE: 123.80%\n",
      "[500 Epochs]    RMSE:1.23921,   MAE: 1.07341,  MAPE: 100.39%\n",
      "[600 Epochs]    RMSE:1.62167,   MAE: 1.50901,  MAPE: 137.73%\n",
      "[700 Epochs]    RMSE:2.87183,   MAE: 2.80290,  MAPE: 259.87%\n",
      "[800 Epochs]    RMSE:2.50790,   MAE: 2.42231,  MAPE: 225.87%\n",
      "[900 Epochs]    RMSE:2.00663,   MAE: 1.89301,  MAPE: 177.56%\n",
      "[1000 Epochs]    RMSE:1.90044,   MAE: 1.78117,  MAPE: 167.37%\n",
      "[1100 Epochs]    RMSE:0.89878,   MAE: 0.72797,  MAPE: 65.43%\n",
      "[1200 Epochs]    RMSE:0.54828,   MAE: 0.46101,  MAPE: 41.65%\n",
      "[1300 Epochs]    RMSE:1.28435,   MAE: 1.23438,  MAPE: 114.81%\n",
      "[1400 Epochs]    RMSE:0.57587,   MAE: 0.46015,  MAPE: 43.18%\n",
      "[1500 Epochs]    RMSE:5.37572,   MAE: 5.36361,  MAPE: 495.93%\n",
      "[1600 Epochs]    RMSE:0.37724,   MAE: 0.30595,  MAPE: 29.02%\n",
      "[1700 Epochs]    RMSE:1.84213,   MAE: 1.81912,  MAPE: 168.70%\n",
      "[1800 Epochs]    RMSE:0.55460,   MAE: 0.49097,  MAPE: 46.25%\n",
      "[1900 Epochs]    RMSE:0.56764,   MAE: 0.51119,  MAPE: 48.30%\n",
      "[2000 Epochs]    RMSE:0.62871,   MAE: 0.57918,  MAPE: 54.71%\n",
      "[2100 Epochs]    RMSE:0.62144,   MAE: 0.57609,  MAPE: 54.42%\n",
      "[2200 Epochs]    RMSE:2.95995,   MAE: 2.94843,  MAPE: 273.47%\n",
      "[2300 Epochs]    RMSE:0.29229,   MAE: 0.23639,  MAPE: 22.56%\n",
      "[2400 Epochs]    RMSE:0.60685,   MAE: 0.57182,  MAPE: 53.67%\n",
      "[2500 Epochs]    RMSE:1.58602,   MAE: 1.53996,  MAPE: 142.15%\n",
      "[2600 Epochs]    RMSE:0.63158,   MAE: 0.57049,  MAPE: 51.39%\n",
      "[2700 Epochs]    RMSE:0.81226,   MAE: 0.76638,  MAPE: 68.46%\n",
      "[2800 Epochs]    RMSE:0.48974,   MAE: 0.44010,  MAPE: 39.86%\n",
      "[2900 Epochs]    RMSE:0.21208,   MAE: 0.16626,  MAPE: 16.31%\n",
      "[3000 Epochs]    RMSE:0.36559,   MAE: 0.33959,  MAPE: 30.88%\n",
      "[3100 Epochs]    RMSE:1.37315,   MAE: 1.36107,  MAPE: 124.27%\n",
      "[3200 Epochs]    RMSE:1.75028,   MAE: 1.73574,  MAPE: 162.51%\n",
      "[3300 Epochs]    RMSE:0.57044,   MAE: 0.53915,  MAPE: 47.92%\n",
      "[3400 Epochs]    RMSE:0.62497,   MAE: 0.59734,  MAPE: 53.26%\n",
      "[3500 Epochs]    RMSE:0.20275,   MAE: 0.17534,  MAPE: 16.19%\n",
      "[3600 Epochs]    RMSE:0.28266,   MAE: 0.23817,  MAPE: 23.62%\n",
      "[3700 Epochs]    RMSE:0.58788,   MAE: 0.56599,  MAPE: 51.58%\n",
      "[3800 Epochs]    RMSE:0.21229,   MAE: 0.18048,  MAPE: 16.64%\n",
      "[3900 Epochs]    RMSE:0.22482,   MAE: 0.17815,  MAPE: 18.21%\n",
      "[4000 Epochs]    RMSE:0.19324,   MAE: 0.15338,  MAPE: 16.20%\n",
      "[4100 Epochs]    RMSE:0.49518,   MAE: 0.47610,  MAPE: 42.24%\n",
      "[4200 Epochs]    RMSE:0.38174,   MAE: 0.36199,  MAPE: 32.04%\n",
      "[4300 Epochs]    RMSE:0.24729,   MAE: 0.22350,  MAPE: 19.83%\n",
      "[4400 Epochs]    RMSE:0.13086,   MAE: 0.10151,  MAPE: 9.79%\n",
      "[4500 Epochs]    RMSE:0.32985,   MAE: 0.31374,  MAPE: 27.60%\n",
      "[4600 Epochs]    RMSE:0.17596,   MAE: 0.14544,  MAPE: 13.41%\n",
      "[4700 Epochs]    RMSE:0.14509,   MAE: 0.12103,  MAPE: 10.94%\n",
      "[4800 Epochs]    RMSE:0.42813,   MAE: 0.41348,  MAPE: 36.32%\n",
      "[4900 Epochs]    RMSE:0.20911,   MAE: 0.19114,  MAPE: 16.79%\n",
      "[5000 Epochs]    RMSE:0.18245,   MAE: 0.15692,  MAPE: 15.76%\n",
      "[5100 Epochs]    RMSE:0.14743,   MAE: 0.12730,  MAPE: 11.33%\n",
      "[5200 Epochs]    RMSE:0.13300,   MAE: 0.10562,  MAPE: 10.84%\n",
      "[5300 Epochs]    RMSE:0.15028,   MAE: 0.12177,  MAPE: 12.50%\n",
      "[5400 Epochs]    RMSE:0.24865,   MAE: 0.23516,  MAPE: 20.62%\n",
      "[5500 Epochs]    RMSE:0.21809,   MAE: 0.20199,  MAPE: 17.77%\n",
      "[5600 Epochs]    RMSE:0.16121,   MAE: 0.14013,  MAPE: 12.19%\n",
      "[5700 Epochs]    RMSE:0.13608,   MAE: 0.11582,  MAPE: 10.35%\n",
      "[5800 Epochs]    RMSE:0.11492,   MAE: 0.09449,  MAPE: 8.50%\n",
      "[5900 Epochs]    RMSE:0.08624,   MAE: 0.06193,  MAPE: 5.75%\n",
      "[6000 Epochs]    RMSE:0.08399,   MAE: 0.06145,  MAPE: 6.06%\n",
      "[6100 Epochs]    RMSE:0.16472,   MAE: 0.15185,  MAPE: 13.59%\n",
      "[6200 Epochs]    RMSE:0.08228,   MAE: 0.06354,  MAPE: 6.03%\n",
      "[6300 Epochs]    RMSE:0.07397,   MAE: 0.05436,  MAPE: 5.37%\n",
      "[6400 Epochs]    RMSE:0.10427,   MAE: 0.08507,  MAPE: 7.79%\n",
      "[6500 Epochs]    RMSE:0.07129,   MAE: 0.04812,  MAPE: 4.57%\n",
      "[6600 Epochs]    RMSE:0.13954,   MAE: 0.10054,  MAPE: 9.12%\n",
      "[6700 Epochs]    RMSE:0.08126,   MAE: 0.05855,  MAPE: 5.87%\n",
      "[6800 Epochs]    RMSE:0.08786,   MAE: 0.07055,  MAPE: 6.88%\n",
      "[6900 Epochs]    RMSE:0.11915,   MAE: 0.10432,  MAPE: 9.06%\n",
      "[7000 Epochs]    RMSE:0.07934,   MAE: 0.05943,  MAPE: 5.66%\n",
      "[7100 Epochs]    RMSE:0.09521,   MAE: 0.07687,  MAPE: 7.47%\n",
      "[7200 Epochs]    RMSE:0.07139,   MAE: 0.05542,  MAPE: 5.10%\n",
      "[7300 Epochs]    RMSE:0.06521,   MAE: 0.04974,  MAPE: 4.92%\n",
      "[7400 Epochs]    RMSE:0.10738,   MAE: 0.09363,  MAPE: 8.71%\n",
      "[7500 Epochs]    RMSE:0.06717,   MAE: 0.05229,  MAPE: 4.73%\n",
      "[7600 Epochs]    RMSE:0.06075,   MAE: 0.04726,  MAPE: 4.76%\n",
      "[7700 Epochs]    RMSE:0.15198,   MAE: 0.12569,  MAPE: 12.70%\n",
      "[7800 Epochs]    RMSE:0.08772,   MAE: 0.07423,  MAPE: 7.48%\n",
      "[7900 Epochs]    RMSE:0.05601,   MAE: 0.04293,  MAPE: 3.91%\n",
      "[8000 Epochs]    RMSE:0.06969,   MAE: 0.05779,  MAPE: 5.78%\n",
      "[8100 Epochs]    RMSE:0.09636,   MAE: 0.08151,  MAPE: 8.22%\n",
      "[8200 Epochs]    RMSE:0.05618,   MAE: 0.04332,  MAPE: 4.11%\n",
      "[8300 Epochs]    RMSE:0.08049,   MAE: 0.06871,  MAPE: 5.97%\n",
      "[8400 Epochs]    RMSE:0.12947,   MAE: 0.11742,  MAPE: 11.03%\n",
      "[8500 Epochs]    RMSE:0.07304,   MAE: 0.05572,  MAPE: 5.11%\n",
      "[8600 Epochs]    RMSE:0.06240,   MAE: 0.04566,  MAPE: 4.13%\n",
      "[8700 Epochs]    RMSE:0.06785,   MAE: 0.05595,  MAPE: 5.21%\n",
      "[8800 Epochs]    RMSE:0.12033,   MAE: 0.10176,  MAPE: 10.15%\n",
      "[8900 Epochs]    RMSE:0.06073,   MAE: 0.04892,  MAPE: 4.27%\n",
      "[9000 Epochs]    RMSE:0.08636,   MAE: 0.06083,  MAPE: 5.72%\n",
      "[9100 Epochs]    RMSE:0.07186,   MAE: 0.06158,  MAPE: 5.90%\n",
      "[9200 Epochs]    RMSE:0.08381,   MAE: 0.06227,  MAPE: 6.20%\n",
      "[9300 Epochs]    RMSE:0.18937,   MAE: 0.17811,  MAPE: 15.96%\n",
      "[9400 Epochs]    RMSE:0.06876,   MAE: 0.05368,  MAPE: 5.18%\n",
      "[9500 Epochs]    RMSE:0.05988,   MAE: 0.04515,  MAPE: 4.54%\n",
      "[9600 Epochs]    RMSE:0.10936,   MAE: 0.07831,  MAPE: 7.12%\n",
      "[9700 Epochs]    RMSE:0.07017,   MAE: 0.06123,  MAPE: 5.53%\n",
      "[9800 Epochs]    RMSE:0.07481,   MAE: 0.06292,  MAPE: 5.93%\n",
      "[9900 Epochs]    RMSE:0.06092,   MAE: 0.04861,  MAPE: 5.02%\n",
      "[10000 Epochs]    RMSE:0.13248,   MAE: 0.12091,  MAPE: 11.58%\n",
      "[10100 Epochs]    RMSE:0.12316,   MAE: 0.11173,  MAPE: 10.56%\n",
      "[10200 Epochs]    RMSE:0.12431,   MAE: 0.11524,  MAPE: 10.71%\n",
      "[10300 Epochs]    RMSE:0.07054,   MAE: 0.05073,  MAPE: 4.93%\n",
      "[10400 Epochs]    RMSE:0.09993,   MAE: 0.08081,  MAPE: 7.78%\n",
      "[10500 Epochs]    RMSE:0.12004,   MAE: 0.09582,  MAPE: 9.28%\n",
      "[10600 Epochs]    RMSE:0.08222,   MAE: 0.05991,  MAPE: 6.23%\n",
      "[10700 Epochs]    RMSE:0.07033,   MAE: 0.05149,  MAPE: 5.40%\n",
      "[10800 Epochs]    RMSE:0.08129,   MAE: 0.06227,  MAPE: 6.37%\n",
      "[10900 Epochs]    RMSE:0.10040,   MAE: 0.08457,  MAPE: 8.48%\n",
      "[11000 Epochs]    RMSE:0.15550,   MAE: 0.11493,  MAPE: 12.63%\n",
      "[11100 Epochs]    RMSE:0.09721,   MAE: 0.08283,  MAPE: 7.42%\n",
      "[11200 Epochs]    RMSE:0.07128,   MAE: 0.05464,  MAPE: 5.42%\n",
      "[11300 Epochs]    RMSE:0.13902,   MAE: 0.11347,  MAPE: 10.59%\n",
      "[11400 Epochs]    RMSE:0.08721,   MAE: 0.07488,  MAPE: 7.37%\n",
      "[11500 Epochs]    RMSE:0.09798,   MAE: 0.08482,  MAPE: 7.65%\n",
      "[11600 Epochs]    RMSE:0.08772,   MAE: 0.06940,  MAPE: 6.53%\n",
      "[11700 Epochs]    RMSE:0.11917,   MAE: 0.10554,  MAPE: 9.61%\n",
      "[11800 Epochs]    RMSE:0.08678,   MAE: 0.06542,  MAPE: 7.00%\n",
      "[11900 Epochs]    RMSE:0.06445,   MAE: 0.05118,  MAPE: 5.00%\n",
      "[12000 Epochs]    RMSE:0.08937,   MAE: 0.07366,  MAPE: 6.54%\n",
      "[12100 Epochs]    RMSE:0.08037,   MAE: 0.06978,  MAPE: 6.70%\n",
      "[12200 Epochs]    RMSE:0.10770,   MAE: 0.08860,  MAPE: 7.73%\n",
      "[12300 Epochs]    RMSE:0.05079,   MAE: 0.03748,  MAPE: 3.72%\n",
      "[12400 Epochs]    RMSE:0.06701,   MAE: 0.05938,  MAPE: 5.63%\n",
      "[12500 Epochs]    RMSE:0.18232,   MAE: 0.15664,  MAPE: 15.78%\n",
      "[12600 Epochs]    RMSE:0.08799,   MAE: 0.06348,  MAPE: 6.22%\n",
      "[12700 Epochs]    RMSE:0.08335,   MAE: 0.06922,  MAPE: 6.42%\n",
      "[12800 Epochs]    RMSE:0.11433,   MAE: 0.09980,  MAPE: 9.27%\n",
      "[12900 Epochs]    RMSE:0.07928,   MAE: 0.06824,  MAPE: 6.27%\n",
      "[13000 Epochs]    RMSE:0.13196,   MAE: 0.12244,  MAPE: 10.87%\n",
      "[13100 Epochs]    RMSE:0.06851,   MAE: 0.05815,  MAPE: 5.38%\n",
      "[13200 Epochs]    RMSE:0.09454,   MAE: 0.08424,  MAPE: 7.83%\n",
      "[13300 Epochs]    RMSE:0.08638,   MAE: 0.06400,  MAPE: 6.92%\n",
      "[13400 Epochs]    RMSE:0.07169,   MAE: 0.05156,  MAPE: 4.96%\n",
      "[13500 Epochs]    RMSE:0.23734,   MAE: 0.22463,  MAPE: 21.07%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13600 Epochs]    RMSE:0.12178,   MAE: 0.10976,  MAPE: 10.88%\n",
      "[13700 Epochs]    RMSE:0.05560,   MAE: 0.04297,  MAPE: 4.01%\n",
      "[13800 Epochs]    RMSE:0.04994,   MAE: 0.03845,  MAPE: 3.51%\n",
      "[13900 Epochs]    RMSE:0.07280,   MAE: 0.05861,  MAPE: 5.91%\n",
      "[14000 Epochs]    RMSE:0.08922,   MAE: 0.07691,  MAPE: 6.39%\n",
      "[14100 Epochs]    RMSE:0.08409,   MAE: 0.07129,  MAPE: 6.82%\n",
      "[14200 Epochs]    RMSE:0.06221,   MAE: 0.04704,  MAPE: 4.87%\n",
      "[14300 Epochs]    RMSE:0.07991,   MAE: 0.06021,  MAPE: 6.25%\n",
      "[14400 Epochs]    RMSE:0.07927,   MAE: 0.07011,  MAPE: 6.07%\n",
      "[14500 Epochs]    RMSE:0.07256,   MAE: 0.06326,  MAPE: 5.60%\n",
      "[14600 Epochs]    RMSE:0.05457,   MAE: 0.04422,  MAPE: 4.07%\n",
      "[14700 Epochs]    RMSE:0.08621,   MAE: 0.06744,  MAPE: 7.19%\n",
      "[14800 Epochs]    RMSE:0.05989,   MAE: 0.04666,  MAPE: 4.76%\n",
      "[14900 Epochs]    RMSE:0.05370,   MAE: 0.04039,  MAPE: 4.13%\n",
      "[15000 Epochs]    RMSE:0.05193,   MAE: 0.04322,  MAPE: 3.61%\n",
      "[15100 Epochs]    RMSE:0.07934,   MAE: 0.06939,  MAPE: 6.44%\n",
      "[15200 Epochs]    RMSE:0.04350,   MAE: 0.03497,  MAPE: 3.08%\n",
      "[15300 Epochs]    RMSE:0.07636,   MAE: 0.06631,  MAPE: 6.00%\n",
      "[15400 Epochs]    RMSE:0.07408,   MAE: 0.06138,  MAPE: 5.88%\n",
      "[15500 Epochs]    RMSE:0.07057,   MAE: 0.06157,  MAPE: 5.64%\n",
      "[15600 Epochs]    RMSE:0.05050,   MAE: 0.04263,  MAPE: 3.97%\n",
      "[15700 Epochs]    RMSE:0.05343,   MAE: 0.04457,  MAPE: 4.08%\n",
      "[15800 Epochs]    RMSE:0.05011,   MAE: 0.04389,  MAPE: 4.01%\n",
      "[15900 Epochs]    RMSE:0.04664,   MAE: 0.03922,  MAPE: 3.83%\n",
      "[16000 Epochs]    RMSE:0.04942,   MAE: 0.04304,  MAPE: 3.78%\n",
      "[16100 Epochs]    RMSE:0.03786,   MAE: 0.03044,  MAPE: 3.05%\n",
      "[16200 Epochs]    RMSE:0.07934,   MAE: 0.06021,  MAPE: 6.44%\n",
      "[16300 Epochs]    RMSE:0.04204,   MAE: 0.03407,  MAPE: 3.32%\n",
      "[16400 Epochs]    RMSE:0.04595,   MAE: 0.03625,  MAPE: 3.72%\n",
      "[16500 Epochs]    RMSE:0.08465,   MAE: 0.05743,  MAPE: 6.46%\n",
      "[16600 Epochs]    RMSE:0.08025,   MAE: 0.06385,  MAPE: 6.15%\n",
      "[16700 Epochs]    RMSE:0.06725,   MAE: 0.05273,  MAPE: 5.46%\n",
      "[16800 Epochs]    RMSE:0.06696,   MAE: 0.04988,  MAPE: 5.01%\n",
      "[16900 Epochs]    RMSE:0.05648,   MAE: 0.04458,  MAPE: 4.41%\n",
      "[17000 Epochs]    RMSE:0.05668,   MAE: 0.04038,  MAPE: 4.35%\n",
      "[17100 Epochs]    RMSE:0.06483,   MAE: 0.04631,  MAPE: 4.98%\n",
      "[17200 Epochs]    RMSE:0.05512,   MAE: 0.04457,  MAPE: 4.35%\n",
      "[17300 Epochs]    RMSE:0.05482,   MAE: 0.04125,  MAPE: 4.27%\n",
      "[17400 Epochs]    RMSE:0.05005,   MAE: 0.03822,  MAPE: 3.67%\n",
      "[17500 Epochs]    RMSE:0.04206,   MAE: 0.03131,  MAPE: 3.03%\n",
      "[17600 Epochs]    RMSE:0.07616,   MAE: 0.06502,  MAPE: 6.15%\n",
      "[17700 Epochs]    RMSE:0.06136,   MAE: 0.04679,  MAPE: 4.81%\n",
      "[17800 Epochs]    RMSE:0.09247,   MAE: 0.07672,  MAPE: 7.10%\n",
      "[17900 Epochs]    RMSE:0.15555,   MAE: 0.13671,  MAPE: 13.50%\n",
      "[18000 Epochs]    RMSE:0.06090,   MAE: 0.05171,  MAPE: 5.12%\n",
      "[18100 Epochs]    RMSE:0.07216,   MAE: 0.06274,  MAPE: 5.80%\n",
      "[18200 Epochs]    RMSE:0.10038,   MAE: 0.08603,  MAPE: 8.35%\n",
      "[18300 Epochs]    RMSE:0.06410,   MAE: 0.05284,  MAPE: 5.34%\n",
      "[18400 Epochs]    RMSE:0.07855,   MAE: 0.05351,  MAPE: 5.44%\n",
      "[18500 Epochs]    RMSE:0.07000,   MAE: 0.04980,  MAPE: 4.94%\n",
      "[18600 Epochs]    RMSE:0.08581,   MAE: 0.07572,  MAPE: 6.86%\n",
      "[18700 Epochs]    RMSE:0.03857,   MAE: 0.02893,  MAPE: 3.01%\n",
      "[18800 Epochs]    RMSE:0.03929,   MAE: 0.02816,  MAPE: 2.69%\n",
      "[18900 Epochs]    RMSE:0.05783,   MAE: 0.04868,  MAPE: 4.56%\n",
      "[19000 Epochs]    RMSE:0.02913,   MAE: 0.02076,  MAPE: 1.96%\n",
      "[19100 Epochs]    RMSE:0.08229,   MAE: 0.05607,  MAPE: 5.48%\n",
      "[19200 Epochs]    RMSE:0.04875,   MAE: 0.04035,  MAPE: 3.93%\n",
      "[19300 Epochs]    RMSE:0.04533,   MAE: 0.03503,  MAPE: 3.29%\n",
      "[19400 Epochs]    RMSE:0.03384,   MAE: 0.02630,  MAPE: 2.64%\n",
      "[19500 Epochs]    RMSE:0.02949,   MAE: 0.02164,  MAPE: 2.17%\n",
      "[19600 Epochs]    RMSE:0.05416,   MAE: 0.04537,  MAPE: 4.11%\n",
      "[19700 Epochs]    RMSE:0.03069,   MAE: 0.02395,  MAPE: 2.18%\n",
      "[19800 Epochs]    RMSE:0.06642,   MAE: 0.04523,  MAPE: 4.28%\n",
      "[19900 Epochs]    RMSE:0.06800,   MAE: 0.06180,  MAPE: 5.72%\n",
      "\n",
      "[Final Epochs]    RMSE:0.07504,   MAE: 0.05395,  MAPE: 5.18%\n",
      "\n",
      "\n",
      "\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:59.70384,   MAE: 59.61298,  MAPE: 5693.07%\n",
      "[100 Epochs]    RMSE:3.70690,   MAE: 3.27565,  MAPE: 285.94%\n",
      "[200 Epochs]    RMSE:2.88855,   MAE: 2.51225,  MAPE: 220.81%\n",
      "[300 Epochs]    RMSE:2.22840,   MAE: 1.82584,  MAPE: 160.43%\n",
      "[400 Epochs]    RMSE:2.43458,   MAE: 2.12025,  MAPE: 188.09%\n",
      "[500 Epochs]    RMSE:3.24715,   MAE: 3.02446,  MAPE: 304.70%\n",
      "[600 Epochs]    RMSE:1.53871,   MAE: 1.31321,  MAPE: 118.70%\n",
      "[700 Epochs]    RMSE:3.63317,   MAE: 3.57251,  MAPE: 335.04%\n",
      "[800 Epochs]    RMSE:2.48525,   MAE: 2.36720,  MAPE: 238.09%\n",
      "[900 Epochs]    RMSE:1.98362,   MAE: 1.93581,  MAPE: 181.92%\n",
      "[1000 Epochs]    RMSE:2.18365,   MAE: 2.06674,  MAPE: 188.12%\n",
      "[1100 Epochs]    RMSE:1.71960,   MAE: 1.58301,  MAPE: 142.54%\n",
      "[1200 Epochs]    RMSE:1.18048,   MAE: 1.05668,  MAPE: 95.28%\n",
      "[1300 Epochs]    RMSE:1.75719,   MAE: 1.68166,  MAPE: 154.42%\n",
      "[1400 Epochs]    RMSE:1.59225,   MAE: 1.48534,  MAPE: 134.39%\n",
      "[1500 Epochs]    RMSE:1.49336,   MAE: 1.36820,  MAPE: 140.15%\n",
      "[1600 Epochs]    RMSE:1.70779,   MAE: 1.57922,  MAPE: 161.93%\n",
      "[1700 Epochs]    RMSE:1.09003,   MAE: 0.99932,  MAPE: 91.20%\n",
      "[1800 Epochs]    RMSE:1.25896,   MAE: 1.19258,  MAPE: 109.89%\n",
      "[1900 Epochs]    RMSE:0.39246,   MAE: 0.33140,  MAPE: 33.72%\n",
      "[2000 Epochs]    RMSE:1.01962,   MAE: 0.94661,  MAPE: 85.88%\n",
      "[2100 Epochs]    RMSE:0.80353,   MAE: 0.72008,  MAPE: 64.39%\n",
      "[2200 Epochs]    RMSE:1.00476,   MAE: 0.94546,  MAPE: 86.28%\n",
      "[2300 Epochs]    RMSE:0.88622,   MAE: 0.82191,  MAPE: 74.26%\n",
      "[2400 Epochs]    RMSE:0.83051,   MAE: 0.75991,  MAPE: 68.11%\n",
      "[2500 Epochs]    RMSE:0.70041,   MAE: 0.63581,  MAPE: 57.27%\n",
      "[2600 Epochs]    RMSE:0.54879,   MAE: 0.48270,  MAPE: 43.45%\n",
      "[2700 Epochs]    RMSE:0.68496,   MAE: 0.62955,  MAPE: 57.19%\n",
      "[2800 Epochs]    RMSE:1.03844,   MAE: 1.01484,  MAPE: 97.50%\n",
      "[2900 Epochs]    RMSE:1.10933,   MAE: 1.09176,  MAPE: 101.02%\n",
      "[3000 Epochs]    RMSE:1.01876,   MAE: 0.97073,  MAPE: 99.63%\n",
      "[3100 Epochs]    RMSE:0.48902,   MAE: 0.44813,  MAPE: 39.50%\n",
      "[3200 Epochs]    RMSE:0.47975,   MAE: 0.44748,  MAPE: 46.55%\n",
      "[3300 Epochs]    RMSE:0.21347,   MAE: 0.18630,  MAPE: 19.79%\n",
      "[3400 Epochs]    RMSE:0.20467,   MAE: 0.17801,  MAPE: 16.00%\n",
      "[3500 Epochs]    RMSE:0.49836,   MAE: 0.47059,  MAPE: 42.33%\n",
      "[3600 Epochs]    RMSE:1.31493,   MAE: 1.25568,  MAPE: 114.47%\n",
      "[3700 Epochs]    RMSE:0.99394,   MAE: 0.96979,  MAPE: 97.87%\n",
      "[3800 Epochs]    RMSE:0.14504,   MAE: 0.10936,  MAPE: 11.06%\n",
      "[3900 Epochs]    RMSE:0.76950,   MAE: 0.74568,  MAPE: 74.85%\n",
      "[4000 Epochs]    RMSE:0.33380,   MAE: 0.30992,  MAPE: 29.19%\n",
      "[4100 Epochs]    RMSE:0.68437,   MAE: 0.66261,  MAPE: 66.75%\n",
      "[4200 Epochs]    RMSE:0.33084,   MAE: 0.30395,  MAPE: 31.35%\n",
      "[4300 Epochs]    RMSE:0.29474,   MAE: 0.26725,  MAPE: 27.40%\n",
      "[4400 Epochs]    RMSE:0.27598,   MAE: 0.24883,  MAPE: 22.23%\n",
      "[4500 Epochs]    RMSE:0.23623,   MAE: 0.20611,  MAPE: 18.27%\n",
      "[4600 Epochs]    RMSE:0.20049,   MAE: 0.18401,  MAPE: 18.37%\n",
      "[4700 Epochs]    RMSE:0.23380,   MAE: 0.21107,  MAPE: 18.93%\n",
      "[4800 Epochs]    RMSE:0.17451,   MAE: 0.14672,  MAPE: 12.89%\n",
      "[4900 Epochs]    RMSE:0.25230,   MAE: 0.23563,  MAPE: 23.82%\n",
      "[5000 Epochs]    RMSE:0.16617,   MAE: 0.14592,  MAPE: 14.84%\n",
      "[5100 Epochs]    RMSE:0.09482,   MAE: 0.07597,  MAPE: 7.06%\n",
      "[5200 Epochs]    RMSE:0.11326,   MAE: 0.09212,  MAPE: 8.55%\n",
      "[5300 Epochs]    RMSE:0.08927,   MAE: 0.07269,  MAPE: 6.76%\n",
      "[5400 Epochs]    RMSE:0.26251,   MAE: 0.25287,  MAPE: 24.07%\n",
      "[5500 Epochs]    RMSE:0.15498,   MAE: 0.13593,  MAPE: 14.37%\n",
      "[5600 Epochs]    RMSE:0.13643,   MAE: 0.11777,  MAPE: 12.20%\n",
      "[5700 Epochs]    RMSE:0.07260,   MAE: 0.05745,  MAPE: 5.72%\n",
      "[5800 Epochs]    RMSE:0.05530,   MAE: 0.04330,  MAPE: 4.21%\n",
      "[5900 Epochs]    RMSE:0.13955,   MAE: 0.12346,  MAPE: 11.03%\n",
      "[6000 Epochs]    RMSE:0.07001,   MAE: 0.04895,  MAPE: 4.84%\n",
      "[6100 Epochs]    RMSE:0.07186,   MAE: 0.05388,  MAPE: 5.14%\n",
      "[6200 Epochs]    RMSE:0.06616,   MAE: 0.04448,  MAPE: 4.47%\n",
      "[6300 Epochs]    RMSE:0.16127,   MAE: 0.14093,  MAPE: 12.53%\n",
      "[6400 Epochs]    RMSE:0.17295,   MAE: 0.15864,  MAPE: 14.52%\n",
      "[6500 Epochs]    RMSE:0.15828,   MAE: 0.14423,  MAPE: 13.87%\n",
      "[6600 Epochs]    RMSE:0.09642,   MAE: 0.08292,  MAPE: 8.32%\n",
      "[6700 Epochs]    RMSE:0.09109,   MAE: 0.06384,  MAPE: 6.55%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6800 Epochs]    RMSE:0.06453,   MAE: 0.04785,  MAPE: 4.53%\n",
      "[6900 Epochs]    RMSE:0.10298,   MAE: 0.09048,  MAPE: 8.95%\n",
      "[7000 Epochs]    RMSE:0.05511,   MAE: 0.04018,  MAPE: 3.89%\n",
      "[7100 Epochs]    RMSE:0.14187,   MAE: 0.12642,  MAPE: 11.79%\n",
      "[7200 Epochs]    RMSE:0.05577,   MAE: 0.04498,  MAPE: 4.49%\n",
      "[7300 Epochs]    RMSE:0.08438,   MAE: 0.07219,  MAPE: 6.79%\n",
      "[7400 Epochs]    RMSE:0.12090,   MAE: 0.10653,  MAPE: 10.40%\n",
      "[7500 Epochs]    RMSE:0.11639,   MAE: 0.10235,  MAPE: 9.62%\n",
      "[7600 Epochs]    RMSE:0.12556,   MAE: 0.11007,  MAPE: 10.47%\n",
      "[7700 Epochs]    RMSE:0.10755,   MAE: 0.08422,  MAPE: 8.94%\n",
      "[7800 Epochs]    RMSE:0.07789,   MAE: 0.05870,  MAPE: 5.55%\n",
      "[7900 Epochs]    RMSE:0.10793,   MAE: 0.09200,  MAPE: 9.37%\n",
      "[8000 Epochs]    RMSE:0.07686,   MAE: 0.06249,  MAPE: 5.94%\n",
      "[8100 Epochs]    RMSE:0.09419,   MAE: 0.07195,  MAPE: 7.36%\n",
      "[8200 Epochs]    RMSE:0.06468,   MAE: 0.04744,  MAPE: 5.13%\n",
      "[8300 Epochs]    RMSE:0.08224,   MAE: 0.06010,  MAPE: 5.82%\n",
      "[8400 Epochs]    RMSE:0.08376,   MAE: 0.05716,  MAPE: 5.77%\n",
      "[8500 Epochs]    RMSE:0.14951,   MAE: 0.13327,  MAPE: 12.32%\n",
      "[8600 Epochs]    RMSE:0.13447,   MAE: 0.12069,  MAPE: 11.15%\n",
      "[8700 Epochs]    RMSE:0.11554,   MAE: 0.09038,  MAPE: 7.80%\n",
      "[8800 Epochs]    RMSE:0.06173,   MAE: 0.04747,  MAPE: 4.40%\n",
      "[8900 Epochs]    RMSE:0.06546,   MAE: 0.04617,  MAPE: 4.79%\n",
      "[9000 Epochs]    RMSE:0.11150,   MAE: 0.08611,  MAPE: 8.63%\n",
      "[9100 Epochs]    RMSE:0.08359,   MAE: 0.06634,  MAPE: 6.91%\n",
      "[9200 Epochs]    RMSE:0.09010,   MAE: 0.08023,  MAPE: 7.83%\n",
      "[9300 Epochs]    RMSE:0.20494,   MAE: 0.19629,  MAPE: 18.47%\n",
      "[9400 Epochs]    RMSE:0.10487,   MAE: 0.08091,  MAPE: 7.12%\n",
      "[9500 Epochs]    RMSE:0.11045,   MAE: 0.08778,  MAPE: 9.58%\n",
      "[9600 Epochs]    RMSE:0.12759,   MAE: 0.11163,  MAPE: 11.44%\n",
      "[9700 Epochs]    RMSE:0.11508,   MAE: 0.10485,  MAPE: 9.64%\n",
      "[9800 Epochs]    RMSE:0.09252,   MAE: 0.07454,  MAPE: 8.00%\n",
      "[9900 Epochs]    RMSE:0.12145,   MAE: 0.11155,  MAPE: 10.54%\n",
      "[10000 Epochs]    RMSE:0.05755,   MAE: 0.04544,  MAPE: 4.77%\n",
      "[10100 Epochs]    RMSE:0.07850,   MAE: 0.06896,  MAPE: 6.95%\n",
      "[10200 Epochs]    RMSE:0.13848,   MAE: 0.12465,  MAPE: 11.30%\n",
      "[10300 Epochs]    RMSE:0.08809,   MAE: 0.07934,  MAPE: 7.74%\n",
      "[10400 Epochs]    RMSE:0.07583,   MAE: 0.05351,  MAPE: 5.04%\n",
      "[10500 Epochs]    RMSE:0.06148,   MAE: 0.04445,  MAPE: 4.80%\n",
      "[10600 Epochs]    RMSE:0.06879,   MAE: 0.05591,  MAPE: 5.65%\n",
      "[10700 Epochs]    RMSE:0.08069,   MAE: 0.05863,  MAPE: 5.84%\n",
      "[10800 Epochs]    RMSE:0.09712,   MAE: 0.08415,  MAPE: 7.59%\n",
      "[10900 Epochs]    RMSE:0.06355,   MAE: 0.04832,  MAPE: 4.60%\n",
      "[11000 Epochs]    RMSE:0.11536,   MAE: 0.09331,  MAPE: 8.25%\n",
      "[11100 Epochs]    RMSE:0.05182,   MAE: 0.04086,  MAPE: 4.11%\n",
      "[11200 Epochs]    RMSE:0.11829,   MAE: 0.09210,  MAPE: 9.01%\n",
      "[11300 Epochs]    RMSE:0.12762,   MAE: 0.11688,  MAPE: 10.86%\n",
      "[11400 Epochs]    RMSE:0.06226,   MAE: 0.04658,  MAPE: 4.58%\n",
      "[11500 Epochs]    RMSE:0.09582,   MAE: 0.07792,  MAPE: 8.02%\n",
      "[11600 Epochs]    RMSE:0.07382,   MAE: 0.05746,  MAPE: 6.25%\n",
      "[11700 Epochs]    RMSE:0.05300,   MAE: 0.03677,  MAPE: 3.88%\n",
      "[11800 Epochs]    RMSE:0.06304,   MAE: 0.04924,  MAPE: 4.77%\n",
      "[11900 Epochs]    RMSE:0.04606,   MAE: 0.03392,  MAPE: 3.46%\n",
      "[12000 Epochs]    RMSE:0.06283,   MAE: 0.05321,  MAPE: 5.11%\n",
      "[12100 Epochs]    RMSE:0.11012,   MAE: 0.09745,  MAPE: 9.22%\n",
      "[12200 Epochs]    RMSE:0.08559,   MAE: 0.07375,  MAPE: 7.60%\n",
      "[12300 Epochs]    RMSE:0.06618,   MAE: 0.04868,  MAPE: 4.69%\n",
      "[12400 Epochs]    RMSE:0.15461,   MAE: 0.13581,  MAPE: 12.39%\n",
      "[12500 Epochs]    RMSE:0.15087,   MAE: 0.13275,  MAPE: 13.38%\n",
      "[12600 Epochs]    RMSE:0.07128,   MAE: 0.04873,  MAPE: 4.86%\n",
      "[12700 Epochs]    RMSE:0.11243,   MAE: 0.09565,  MAPE: 9.37%\n",
      "[12800 Epochs]    RMSE:0.10566,   MAE: 0.09947,  MAPE: 9.76%\n",
      "[12900 Epochs]    RMSE:0.04100,   MAE: 0.02984,  MAPE: 2.92%\n",
      "[13000 Epochs]    RMSE:0.13604,   MAE: 0.10960,  MAPE: 11.87%\n",
      "[13100 Epochs]    RMSE:0.04494,   MAE: 0.03327,  MAPE: 3.42%\n",
      "[13200 Epochs]    RMSE:0.07647,   MAE: 0.06190,  MAPE: 5.77%\n",
      "[13300 Epochs]    RMSE:0.06243,   MAE: 0.04453,  MAPE: 4.46%\n",
      "[13400 Epochs]    RMSE:0.13271,   MAE: 0.12054,  MAPE: 11.15%\n",
      "[13500 Epochs]    RMSE:0.08782,   MAE: 0.07529,  MAPE: 7.13%\n",
      "[13600 Epochs]    RMSE:0.07879,   MAE: 0.06626,  MAPE: 6.50%\n",
      "[13700 Epochs]    RMSE:0.05079,   MAE: 0.03342,  MAPE: 3.44%\n",
      "[13800 Epochs]    RMSE:0.05028,   MAE: 0.04064,  MAPE: 3.95%\n",
      "[13900 Epochs]    RMSE:0.07844,   MAE: 0.06448,  MAPE: 6.45%\n",
      "[14000 Epochs]    RMSE:0.06105,   MAE: 0.04283,  MAPE: 4.71%\n",
      "[14100 Epochs]    RMSE:0.05252,   MAE: 0.03889,  MAPE: 4.14%\n",
      "[14200 Epochs]    RMSE:0.06861,   MAE: 0.05883,  MAPE: 5.45%\n",
      "[14300 Epochs]    RMSE:0.13810,   MAE: 0.12449,  MAPE: 11.62%\n",
      "[14400 Epochs]    RMSE:0.04737,   MAE: 0.03363,  MAPE: 3.36%\n",
      "[14500 Epochs]    RMSE:0.20687,   MAE: 0.19914,  MAPE: 18.19%\n",
      "[14600 Epochs]    RMSE:0.05550,   MAE: 0.04225,  MAPE: 4.58%\n",
      "[14700 Epochs]    RMSE:0.05859,   MAE: 0.04965,  MAPE: 4.68%\n",
      "[14800 Epochs]    RMSE:0.04413,   MAE: 0.03406,  MAPE: 3.35%\n",
      "[14900 Epochs]    RMSE:0.04654,   MAE: 0.03553,  MAPE: 3.55%\n",
      "[15000 Epochs]    RMSE:0.11195,   MAE: 0.09698,  MAPE: 9.88%\n",
      "[15100 Epochs]    RMSE:0.07991,   MAE: 0.06505,  MAPE: 6.16%\n",
      "[15200 Epochs]    RMSE:0.06444,   MAE: 0.04915,  MAPE: 5.27%\n",
      "[15300 Epochs]    RMSE:0.05793,   MAE: 0.04703,  MAPE: 4.35%\n",
      "[15400 Epochs]    RMSE:0.07362,   MAE: 0.06561,  MAPE: 6.69%\n",
      "[15500 Epochs]    RMSE:0.07613,   MAE: 0.06907,  MAPE: 6.34%\n",
      "[15600 Epochs]    RMSE:0.10481,   MAE: 0.08948,  MAPE: 8.25%\n",
      "[15700 Epochs]    RMSE:0.05931,   MAE: 0.05081,  MAPE: 4.77%\n",
      "[15800 Epochs]    RMSE:0.05833,   MAE: 0.04949,  MAPE: 5.10%\n",
      "[15900 Epochs]    RMSE:0.07283,   MAE: 0.06455,  MAPE: 6.21%\n",
      "[16000 Epochs]    RMSE:0.03494,   MAE: 0.02290,  MAPE: 2.22%\n",
      "[16100 Epochs]    RMSE:0.43719,   MAE: 0.40904,  MAPE: 36.23%\n",
      "[16200 Epochs]    RMSE:0.08967,   MAE: 0.06769,  MAPE: 7.20%\n",
      "[16300 Epochs]    RMSE:0.08982,   MAE: 0.06592,  MAPE: 6.44%\n",
      "[16400 Epochs]    RMSE:0.08423,   MAE: 0.06566,  MAPE: 7.02%\n",
      "[16500 Epochs]    RMSE:0.08387,   MAE: 0.06394,  MAPE: 6.77%\n",
      "[16600 Epochs]    RMSE:0.13028,   MAE: 0.11628,  MAPE: 10.64%\n",
      "[16700 Epochs]    RMSE:0.09772,   MAE: 0.07154,  MAPE: 6.75%\n",
      "[16800 Epochs]    RMSE:0.08189,   MAE: 0.06179,  MAPE: 6.57%\n",
      "[16900 Epochs]    RMSE:0.08065,   MAE: 0.05735,  MAPE: 5.60%\n",
      "[17000 Epochs]    RMSE:0.07457,   MAE: 0.05355,  MAPE: 5.60%\n",
      "[17100 Epochs]    RMSE:0.07548,   MAE: 0.05399,  MAPE: 5.92%\n",
      "[17200 Epochs]    RMSE:0.07092,   MAE: 0.04966,  MAPE: 5.44%\n",
      "[17300 Epochs]    RMSE:0.06573,   MAE: 0.04567,  MAPE: 4.68%\n",
      "[17400 Epochs]    RMSE:0.06260,   MAE: 0.04540,  MAPE: 4.69%\n",
      "[17500 Epochs]    RMSE:0.06947,   MAE: 0.05020,  MAPE: 5.44%\n",
      "[17600 Epochs]    RMSE:0.06031,   MAE: 0.04250,  MAPE: 4.49%\n",
      "[17700 Epochs]    RMSE:0.06914,   MAE: 0.05196,  MAPE: 5.49%\n",
      "[17800 Epochs]    RMSE:0.06126,   MAE: 0.04244,  MAPE: 4.52%\n",
      "[17900 Epochs]    RMSE:0.05505,   MAE: 0.03821,  MAPE: 3.99%\n",
      "[18000 Epochs]    RMSE:0.05498,   MAE: 0.03801,  MAPE: 4.02%\n",
      "[18100 Epochs]    RMSE:0.05954,   MAE: 0.03978,  MAPE: 4.39%\n",
      "[18200 Epochs]    RMSE:0.06009,   MAE: 0.04421,  MAPE: 4.58%\n",
      "[18300 Epochs]    RMSE:0.05210,   MAE: 0.03711,  MAPE: 3.87%\n",
      "[18400 Epochs]    RMSE:0.06884,   MAE: 0.05503,  MAPE: 5.73%\n",
      "[18500 Epochs]    RMSE:0.07220,   MAE: 0.05943,  MAPE: 5.63%\n",
      "[18600 Epochs]    RMSE:0.05598,   MAE: 0.04135,  MAPE: 4.32%\n",
      "[18700 Epochs]    RMSE:0.09122,   MAE: 0.07723,  MAPE: 7.47%\n",
      "[18800 Epochs]    RMSE:0.05571,   MAE: 0.04228,  MAPE: 4.39%\n",
      "[18900 Epochs]    RMSE:0.05499,   MAE: 0.03954,  MAPE: 4.09%\n",
      "[19000 Epochs]    RMSE:0.05834,   MAE: 0.04452,  MAPE: 4.37%\n",
      "[19100 Epochs]    RMSE:0.05295,   MAE: 0.04043,  MAPE: 4.10%\n",
      "[19200 Epochs]    RMSE:0.08947,   MAE: 0.07652,  MAPE: 8.00%\n",
      "[19300 Epochs]    RMSE:0.04234,   MAE: 0.03048,  MAPE: 3.16%\n",
      "[19400 Epochs]    RMSE:0.05383,   MAE: 0.04092,  MAPE: 4.25%\n",
      "[19500 Epochs]    RMSE:0.07353,   MAE: 0.05827,  MAPE: 6.10%\n",
      "[19600 Epochs]    RMSE:0.08234,   MAE: 0.05511,  MAPE: 5.58%\n",
      "[19700 Epochs]    RMSE:0.09599,   MAE: 0.08492,  MAPE: 7.78%\n",
      "[19800 Epochs]    RMSE:0.05990,   MAE: 0.04928,  MAPE: 4.56%\n",
      "[19900 Epochs]    RMSE:0.05028,   MAE: 0.03720,  MAPE: 3.94%\n",
      "\n",
      "[Final Epochs]    RMSE:0.04773,   MAE: 0.03439,  MAPE: 3.52%\n",
      "\n",
      "\n",
      "\n",
      "Prediction :thickness\n",
      "Learning rate : 0.001\n",
      "Hidden 1 neuron : 60\n",
      "Hidden 2 neuron : 30\n",
      "[0 Epochs]    RMSE:189.58817,   MAE: 189.51462,  MAPE: 17782.59%\n",
      "[100 Epochs]    RMSE:3.50251,   MAE: 2.79929,  MAPE: 267.77%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[200 Epochs]    RMSE:3.96354,   MAE: 3.68345,  MAPE: 346.37%\n",
      "[300 Epochs]    RMSE:2.65271,   MAE: 2.43230,  MAPE: 227.65%\n",
      "[400 Epochs]    RMSE:5.35906,   MAE: 5.26516,  MAPE: 491.52%\n",
      "[500 Epochs]    RMSE:4.82048,   MAE: 4.72504,  MAPE: 447.40%\n",
      "[600 Epochs]    RMSE:2.03930,   MAE: 1.82291,  MAPE: 167.34%\n",
      "[700 Epochs]    RMSE:2.54447,   MAE: 2.40531,  MAPE: 222.63%\n",
      "[800 Epochs]    RMSE:2.68304,   MAE: 2.57238,  MAPE: 244.88%\n",
      "[900 Epochs]    RMSE:0.53354,   MAE: 0.45981,  MAPE: 43.54%\n",
      "[1000 Epochs]    RMSE:0.95706,   MAE: 0.91574,  MAPE: 85.71%\n",
      "[1100 Epochs]    RMSE:1.76007,   MAE: 1.70569,  MAPE: 160.99%\n",
      "[1200 Epochs]    RMSE:1.77272,   MAE: 1.71380,  MAPE: 160.15%\n",
      "[1300 Epochs]    RMSE:0.95235,   MAE: 0.93143,  MAPE: 88.64%\n",
      "[1400 Epochs]    RMSE:1.01228,   MAE: 0.99829,  MAPE: 91.69%\n",
      "[1500 Epochs]    RMSE:0.60058,   MAE: 0.55675,  MAPE: 51.59%\n",
      "[1600 Epochs]    RMSE:0.84640,   MAE: 0.80372,  MAPE: 74.63%\n",
      "[1700 Epochs]    RMSE:1.79587,   MAE: 1.73527,  MAPE: 157.52%\n",
      "[1800 Epochs]    RMSE:1.05406,   MAE: 1.04139,  MAPE: 98.58%\n",
      "[1900 Epochs]    RMSE:0.93079,   MAE: 0.90879,  MAPE: 83.76%\n",
      "[2000 Epochs]    RMSE:0.44545,   MAE: 0.40525,  MAPE: 39.82%\n",
      "[2100 Epochs]    RMSE:0.19241,   MAE: 0.16144,  MAPE: 16.24%\n",
      "[2200 Epochs]    RMSE:0.33411,   MAE: 0.30583,  MAPE: 30.38%\n",
      "[2300 Epochs]    RMSE:0.27326,   MAE: 0.23955,  MAPE: 23.97%\n",
      "[2400 Epochs]    RMSE:0.38212,   MAE: 0.36587,  MAPE: 32.88%\n",
      "[2500 Epochs]    RMSE:0.46503,   MAE: 0.44649,  MAPE: 40.49%\n",
      "[2600 Epochs]    RMSE:0.19995,   MAE: 0.17546,  MAPE: 15.53%\n",
      "[2700 Epochs]    RMSE:0.11745,   MAE: 0.09345,  MAPE: 8.18%\n",
      "[2800 Epochs]    RMSE:0.21090,   MAE: 0.18803,  MAPE: 16.38%\n",
      "[2900 Epochs]    RMSE:0.09020,   MAE: 0.07200,  MAPE: 6.74%\n",
      "[3000 Epochs]    RMSE:0.08917,   MAE: 0.06923,  MAPE: 6.96%\n",
      "[3100 Epochs]    RMSE:0.12996,   MAE: 0.11219,  MAPE: 11.14%\n",
      "[3200 Epochs]    RMSE:0.07971,   MAE: 0.06118,  MAPE: 5.78%\n",
      "[3300 Epochs]    RMSE:0.10028,   MAE: 0.08258,  MAPE: 8.26%\n",
      "[3400 Epochs]    RMSE:0.16220,   MAE: 0.14434,  MAPE: 12.83%\n",
      "[3500 Epochs]    RMSE:0.12427,   MAE: 0.10688,  MAPE: 10.71%\n",
      "[3600 Epochs]    RMSE:0.08170,   MAE: 0.06364,  MAPE: 5.99%\n",
      "[3700 Epochs]    RMSE:0.18703,   MAE: 0.16532,  MAPE: 16.46%\n",
      "[3800 Epochs]    RMSE:0.07990,   MAE: 0.05603,  MAPE: 5.62%\n",
      "[3900 Epochs]    RMSE:0.15036,   MAE: 0.12399,  MAPE: 11.50%\n",
      "[4000 Epochs]    RMSE:0.08110,   MAE: 0.06199,  MAPE: 5.85%\n",
      "[4100 Epochs]    RMSE:0.08158,   MAE: 0.05900,  MAPE: 5.88%\n",
      "[4200 Epochs]    RMSE:0.08627,   MAE: 0.06771,  MAPE: 6.21%\n",
      "[4300 Epochs]    RMSE:0.08084,   MAE: 0.06277,  MAPE: 6.25%\n",
      "[4400 Epochs]    RMSE:0.09001,   MAE: 0.07238,  MAPE: 7.41%\n",
      "[4500 Epochs]    RMSE:0.19247,   MAE: 0.17185,  MAPE: 15.44%\n",
      "[4600 Epochs]    RMSE:0.09530,   MAE: 0.08048,  MAPE: 7.87%\n",
      "[4700 Epochs]    RMSE:0.09890,   MAE: 0.08176,  MAPE: 7.33%\n",
      "[4800 Epochs]    RMSE:0.07084,   MAE: 0.05388,  MAPE: 5.20%\n",
      "[4900 Epochs]    RMSE:0.06793,   MAE: 0.05294,  MAPE: 5.36%\n",
      "[5000 Epochs]    RMSE:0.09778,   MAE: 0.08306,  MAPE: 8.07%\n",
      "[5100 Epochs]    RMSE:0.07812,   MAE: 0.06014,  MAPE: 5.99%\n",
      "[5200 Epochs]    RMSE:0.17997,   MAE: 0.16686,  MAPE: 15.12%\n",
      "[5300 Epochs]    RMSE:0.11467,   MAE: 0.09338,  MAPE: 8.55%\n",
      "[5400 Epochs]    RMSE:0.07193,   MAE: 0.05306,  MAPE: 5.34%\n",
      "[5500 Epochs]    RMSE:0.07431,   MAE: 0.05306,  MAPE: 5.21%\n",
      "[5600 Epochs]    RMSE:0.12860,   MAE: 0.11133,  MAPE: 10.99%\n",
      "[5700 Epochs]    RMSE:0.06512,   MAE: 0.05035,  MAPE: 4.95%\n",
      "[5800 Epochs]    RMSE:0.10223,   MAE: 0.08585,  MAPE: 8.54%\n",
      "[5900 Epochs]    RMSE:0.07802,   MAE: 0.06285,  MAPE: 6.25%\n",
      "[6000 Epochs]    RMSE:0.06079,   MAE: 0.04648,  MAPE: 4.51%\n",
      "[6100 Epochs]    RMSE:0.07325,   MAE: 0.05907,  MAPE: 5.74%\n",
      "[6200 Epochs]    RMSE:0.06847,   MAE: 0.04943,  MAPE: 5.04%\n",
      "[6300 Epochs]    RMSE:0.37722,   MAE: 0.34890,  MAPE: 34.57%\n",
      "[6400 Epochs]    RMSE:0.06983,   MAE: 0.05693,  MAPE: 5.56%\n",
      "[6500 Epochs]    RMSE:0.08744,   MAE: 0.07458,  MAPE: 7.19%\n",
      "[6600 Epochs]    RMSE:0.10506,   MAE: 0.08448,  MAPE: 7.99%\n",
      "[6700 Epochs]    RMSE:0.22814,   MAE: 0.21543,  MAPE: 19.98%\n",
      "[6800 Epochs]    RMSE:0.33480,   MAE: 0.26785,  MAPE: 27.52%\n",
      "[6900 Epochs]    RMSE:0.06152,   MAE: 0.04885,  MAPE: 4.80%\n",
      "[7000 Epochs]    RMSE:0.06114,   MAE: 0.04791,  MAPE: 4.73%\n",
      "[7100 Epochs]    RMSE:0.06102,   MAE: 0.05093,  MAPE: 4.96%\n",
      "[7200 Epochs]    RMSE:0.13569,   MAE: 0.10990,  MAPE: 10.09%\n",
      "[7300 Epochs]    RMSE:0.15083,   MAE: 0.13012,  MAPE: 11.55%\n",
      "[7400 Epochs]    RMSE:0.10245,   MAE: 0.08634,  MAPE: 8.44%\n",
      "[7500 Epochs]    RMSE:0.09044,   MAE: 0.06986,  MAPE: 6.44%\n",
      "[7600 Epochs]    RMSE:0.06905,   MAE: 0.05204,  MAPE: 4.75%\n",
      "[7700 Epochs]    RMSE:0.10611,   MAE: 0.08877,  MAPE: 8.97%\n",
      "[7800 Epochs]    RMSE:0.16670,   MAE: 0.14985,  MAPE: 14.09%\n",
      "[7900 Epochs]    RMSE:0.05627,   MAE: 0.04612,  MAPE: 4.34%\n",
      "[8000 Epochs]    RMSE:0.08778,   MAE: 0.07156,  MAPE: 6.52%\n",
      "[8100 Epochs]    RMSE:0.08841,   MAE: 0.07413,  MAPE: 7.38%\n",
      "[8200 Epochs]    RMSE:0.06840,   MAE: 0.05715,  MAPE: 5.59%\n",
      "[8300 Epochs]    RMSE:0.09910,   MAE: 0.08537,  MAPE: 7.66%\n",
      "[8400 Epochs]    RMSE:0.06108,   MAE: 0.04695,  MAPE: 4.50%\n",
      "[8500 Epochs]    RMSE:0.16008,   MAE: 0.14471,  MAPE: 14.37%\n",
      "[8600 Epochs]    RMSE:0.12825,   MAE: 0.11564,  MAPE: 11.12%\n",
      "[8700 Epochs]    RMSE:0.08739,   MAE: 0.07164,  MAPE: 6.39%\n",
      "[8800 Epochs]    RMSE:0.09713,   MAE: 0.08726,  MAPE: 8.37%\n",
      "[8900 Epochs]    RMSE:0.06117,   MAE: 0.04581,  MAPE: 4.68%\n",
      "[9000 Epochs]    RMSE:0.16186,   MAE: 0.13331,  MAPE: 12.34%\n",
      "[9100 Epochs]    RMSE:0.10197,   MAE: 0.08916,  MAPE: 8.92%\n",
      "[9200 Epochs]    RMSE:0.12593,   MAE: 0.10831,  MAPE: 9.71%\n",
      "[9300 Epochs]    RMSE:0.07612,   MAE: 0.06012,  MAPE: 5.60%\n",
      "[9400 Epochs]    RMSE:0.08741,   MAE: 0.07850,  MAPE: 7.35%\n",
      "[9500 Epochs]    RMSE:0.08285,   MAE: 0.06920,  MAPE: 6.30%\n",
      "[9600 Epochs]    RMSE:0.05471,   MAE: 0.04061,  MAPE: 4.10%\n",
      "[9700 Epochs]    RMSE:0.06434,   MAE: 0.05398,  MAPE: 5.22%\n",
      "[9800 Epochs]    RMSE:0.05705,   MAE: 0.04484,  MAPE: 4.15%\n",
      "[9900 Epochs]    RMSE:0.05836,   MAE: 0.04615,  MAPE: 4.46%\n",
      "[10000 Epochs]    RMSE:0.07330,   MAE: 0.05888,  MAPE: 5.98%\n",
      "[10100 Epochs]    RMSE:0.11202,   MAE: 0.09126,  MAPE: 9.06%\n",
      "[10200 Epochs]    RMSE:0.12037,   MAE: 0.09766,  MAPE: 8.70%\n",
      "[10300 Epochs]    RMSE:0.10828,   MAE: 0.08634,  MAPE: 7.94%\n",
      "[10400 Epochs]    RMSE:0.19856,   MAE: 0.18801,  MAPE: 17.08%\n",
      "[10500 Epochs]    RMSE:0.12867,   MAE: 0.11273,  MAPE: 10.06%\n",
      "[10600 Epochs]    RMSE:0.06179,   MAE: 0.04926,  MAPE: 4.56%\n",
      "[10700 Epochs]    RMSE:0.12588,   MAE: 0.10370,  MAPE: 9.18%\n",
      "[10800 Epochs]    RMSE:0.14594,   MAE: 0.13080,  MAPE: 11.75%\n",
      "[10900 Epochs]    RMSE:0.06031,   MAE: 0.04609,  MAPE: 4.33%\n",
      "[11000 Epochs]    RMSE:0.04563,   MAE: 0.03451,  MAPE: 3.19%\n",
      "[11100 Epochs]    RMSE:0.06459,   MAE: 0.04763,  MAPE: 4.62%\n",
      "[11200 Epochs]    RMSE:0.12127,   MAE: 0.11267,  MAPE: 10.67%\n",
      "[11300 Epochs]    RMSE:0.08001,   MAE: 0.06248,  MAPE: 6.25%\n",
      "[11400 Epochs]    RMSE:0.06162,   MAE: 0.05302,  MAPE: 5.24%\n",
      "[11500 Epochs]    RMSE:0.08340,   MAE: 0.07333,  MAPE: 6.87%\n",
      "[11600 Epochs]    RMSE:0.08540,   MAE: 0.06880,  MAPE: 6.23%\n",
      "[11700 Epochs]    RMSE:0.07560,   MAE: 0.06660,  MAPE: 6.06%\n",
      "[11800 Epochs]    RMSE:0.08792,   MAE: 0.06670,  MAPE: 6.33%\n",
      "[11900 Epochs]    RMSE:0.06798,   MAE: 0.05225,  MAPE: 5.54%\n",
      "[12000 Epochs]    RMSE:0.08093,   MAE: 0.07016,  MAPE: 6.29%\n",
      "[12100 Epochs]    RMSE:0.08097,   MAE: 0.06998,  MAPE: 6.02%\n",
      "[12200 Epochs]    RMSE:0.07508,   MAE: 0.05919,  MAPE: 5.75%\n",
      "[12300 Epochs]    RMSE:0.04912,   MAE: 0.03761,  MAPE: 3.84%\n",
      "[12400 Epochs]    RMSE:0.09597,   MAE: 0.08307,  MAPE: 7.44%\n",
      "[12500 Epochs]    RMSE:0.13872,   MAE: 0.12548,  MAPE: 11.40%\n",
      "[12600 Epochs]    RMSE:0.05290,   MAE: 0.04362,  MAPE: 3.95%\n",
      "[12700 Epochs]    RMSE:0.09071,   MAE: 0.07979,  MAPE: 8.10%\n",
      "[12800 Epochs]    RMSE:0.13818,   MAE: 0.13018,  MAPE: 11.85%\n",
      "[12900 Epochs]    RMSE:0.04325,   MAE: 0.03615,  MAPE: 3.36%\n",
      "[13000 Epochs]    RMSE:0.06840,   MAE: 0.05967,  MAPE: 5.39%\n",
      "[13100 Epochs]    RMSE:0.04435,   MAE: 0.03223,  MAPE: 3.05%\n",
      "[13200 Epochs]    RMSE:0.09086,   MAE: 0.06671,  MAPE: 6.62%\n",
      "[13300 Epochs]    RMSE:0.06482,   MAE: 0.05456,  MAPE: 5.18%\n",
      "[13400 Epochs]    RMSE:0.12962,   MAE: 0.10745,  MAPE: 9.63%\n",
      "[13500 Epochs]    RMSE:0.04397,   MAE: 0.03355,  MAPE: 3.34%\n",
      "[13600 Epochs]    RMSE:0.03481,   MAE: 0.02599,  MAPE: 2.57%\n",
      "[13700 Epochs]    RMSE:0.06091,   MAE: 0.05325,  MAPE: 5.04%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13800 Epochs]    RMSE:0.07218,   MAE: 0.06018,  MAPE: 5.77%\n",
      "[13900 Epochs]    RMSE:0.08269,   MAE: 0.06904,  MAPE: 7.16%\n",
      "[14000 Epochs]    RMSE:0.06920,   MAE: 0.04821,  MAPE: 4.84%\n",
      "[14100 Epochs]    RMSE:0.08067,   MAE: 0.07140,  MAPE: 6.52%\n",
      "[14200 Epochs]    RMSE:0.05237,   MAE: 0.03958,  MAPE: 3.73%\n",
      "[14300 Epochs]    RMSE:0.04797,   MAE: 0.04001,  MAPE: 3.78%\n",
      "[14400 Epochs]    RMSE:0.03503,   MAE: 0.02713,  MAPE: 2.67%\n",
      "[14500 Epochs]    RMSE:0.11956,   MAE: 0.09775,  MAPE: 10.18%\n",
      "[14600 Epochs]    RMSE:0.03074,   MAE: 0.02345,  MAPE: 2.21%\n",
      "[14700 Epochs]    RMSE:0.04184,   MAE: 0.03127,  MAPE: 3.15%\n",
      "[14800 Epochs]    RMSE:0.05079,   MAE: 0.03896,  MAPE: 3.84%\n",
      "[14900 Epochs]    RMSE:0.10848,   MAE: 0.08943,  MAPE: 8.47%\n",
      "[15000 Epochs]    RMSE:0.06398,   MAE: 0.05398,  MAPE: 5.31%\n",
      "[15100 Epochs]    RMSE:0.06812,   MAE: 0.05554,  MAPE: 4.93%\n",
      "[15200 Epochs]    RMSE:0.05971,   MAE: 0.05248,  MAPE: 4.80%\n",
      "[15300 Epochs]    RMSE:0.04026,   MAE: 0.03331,  MAPE: 3.16%\n",
      "[15400 Epochs]    RMSE:0.04423,   MAE: 0.03358,  MAPE: 3.08%\n",
      "[15500 Epochs]    RMSE:0.04063,   MAE: 0.03294,  MAPE: 3.07%\n",
      "[15600 Epochs]    RMSE:0.04170,   MAE: 0.03408,  MAPE: 3.24%\n",
      "[15700 Epochs]    RMSE:0.05398,   MAE: 0.04079,  MAPE: 4.10%\n",
      "[15800 Epochs]    RMSE:0.03694,   MAE: 0.02910,  MAPE: 2.98%\n",
      "[15900 Epochs]    RMSE:0.03182,   MAE: 0.02476,  MAPE: 2.38%\n",
      "[16000 Epochs]    RMSE:0.07205,   MAE: 0.05873,  MAPE: 5.56%\n",
      "[16100 Epochs]    RMSE:0.04626,   MAE: 0.03639,  MAPE: 3.33%\n",
      "[16200 Epochs]    RMSE:0.05602,   MAE: 0.04807,  MAPE: 4.53%\n",
      "[16300 Epochs]    RMSE:0.10130,   MAE: 0.09306,  MAPE: 8.63%\n",
      "[16400 Epochs]    RMSE:0.04494,   MAE: 0.03589,  MAPE: 3.44%\n",
      "[16500 Epochs]    RMSE:0.02703,   MAE: 0.02106,  MAPE: 1.99%\n",
      "[16600 Epochs]    RMSE:0.04386,   MAE: 0.03544,  MAPE: 3.32%\n",
      "[16700 Epochs]    RMSE:0.07555,   MAE: 0.06391,  MAPE: 5.63%\n",
      "[16800 Epochs]    RMSE:0.06159,   MAE: 0.05158,  MAPE: 4.74%\n",
      "[16900 Epochs]    RMSE:0.05978,   MAE: 0.04676,  MAPE: 4.49%\n",
      "[17000 Epochs]    RMSE:0.06992,   MAE: 0.04914,  MAPE: 4.73%\n",
      "[17100 Epochs]    RMSE:0.05579,   MAE: 0.04664,  MAPE: 4.50%\n",
      "[17200 Epochs]    RMSE:0.04341,   MAE: 0.03354,  MAPE: 3.28%\n",
      "[17300 Epochs]    RMSE:0.12315,   MAE: 0.10982,  MAPE: 9.55%\n",
      "[17400 Epochs]    RMSE:0.02876,   MAE: 0.02155,  MAPE: 2.05%\n",
      "[17500 Epochs]    RMSE:0.04034,   MAE: 0.03134,  MAPE: 3.11%\n",
      "[17600 Epochs]    RMSE:0.03866,   MAE: 0.03119,  MAPE: 2.99%\n",
      "[17700 Epochs]    RMSE:0.07214,   MAE: 0.06408,  MAPE: 5.99%\n",
      "[17800 Epochs]    RMSE:0.03482,   MAE: 0.02787,  MAPE: 2.63%\n",
      "[17900 Epochs]    RMSE:0.03875,   MAE: 0.03237,  MAPE: 3.15%\n",
      "[18000 Epochs]    RMSE:0.03813,   MAE: 0.03191,  MAPE: 3.04%\n",
      "[18100 Epochs]    RMSE:0.05894,   MAE: 0.05040,  MAPE: 4.83%\n",
      "[18200 Epochs]    RMSE:0.02928,   MAE: 0.02326,  MAPE: 2.30%\n",
      "[18300 Epochs]    RMSE:0.04376,   MAE: 0.03515,  MAPE: 3.32%\n",
      "[18400 Epochs]    RMSE:0.03888,   MAE: 0.03069,  MAPE: 2.97%\n",
      "[18500 Epochs]    RMSE:0.05317,   MAE: 0.04214,  MAPE: 4.04%\n",
      "[18600 Epochs]    RMSE:0.03708,   MAE: 0.02880,  MAPE: 2.76%\n",
      "[18700 Epochs]    RMSE:0.10938,   MAE: 0.09311,  MAPE: 8.26%\n",
      "[18800 Epochs]    RMSE:0.03132,   MAE: 0.02583,  MAPE: 2.63%\n",
      "[18900 Epochs]    RMSE:0.04041,   MAE: 0.03215,  MAPE: 3.04%\n",
      "[19000 Epochs]    RMSE:0.06762,   MAE: 0.05412,  MAPE: 5.46%\n",
      "[19100 Epochs]    RMSE:0.06030,   MAE: 0.05051,  MAPE: 4.80%\n",
      "[19200 Epochs]    RMSE:0.02462,   MAE: 0.01966,  MAPE: 1.84%\n",
      "[19300 Epochs]    RMSE:0.02829,   MAE: 0.02169,  MAPE: 2.11%\n",
      "[19400 Epochs]    RMSE:0.03844,   MAE: 0.03243,  MAPE: 3.20%\n",
      "[19500 Epochs]    RMSE:0.02318,   MAE: 0.01721,  MAPE: 1.58%\n",
      "[19600 Epochs]    RMSE:0.02379,   MAE: 0.01935,  MAPE: 1.81%\n",
      "[19700 Epochs]    RMSE:0.02242,   MAE: 0.01878,  MAPE: 1.79%\n",
      "[19800 Epochs]    RMSE:0.02539,   MAE: 0.02036,  MAPE: 1.85%\n",
      "[19900 Epochs]    RMSE:0.06094,   MAE: 0.05165,  MAPE: 4.80%\n",
      "\n",
      "[Final Epochs]    RMSE:0.03728,   MAE: 0.03206,  MAPE: 2.92%\n"
     ]
    }
   ],
   "source": [
    "for F in range(Fold):\n",
    "    s1 = 'TrainData  = TrainData_Fold%d'%(F+1)\n",
    "    exec(s1)\n",
    "    s2 = 'TrainLabel = TrainLabel_Fold%d'%(F+1)\n",
    "    exec(s2)\n",
    "    \n",
    "    for M in range(1):\n",
    "\n",
    "        Tr_result_temp = pd.read_csv('D:/testoneblow/ANN_prediction5.0/Tr_result_epoch5000.csv')\n",
    "        learningRate   = Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,1]\n",
    "        noOfNeuron1    = np.int(Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,2])\n",
    "        noOfNeuron2    = np.int(Tr_result_temp.sort_values(['MAE'],ascending=True).iloc[0,3])\n",
    "        Epoch          = 20000\n",
    "\n",
    "        print('\\n\\n\\nPrediction :' + Model[M])\n",
    "        print('Learning rate : {:.3}'.format(learningRate))\n",
    "        print('Hidden 1 neuron : %d'%(noOfNeuron1))\n",
    "        print('Hidden 2 neuron : %d'%(noOfNeuron2))\n",
    "\n",
    "    #     exec('Label_Trn = TrainLabel_%d'%(M+1))\n",
    "\n",
    "        ################ 신경망 구조 재설계 ################\n",
    "\n",
    "        tf.keras.backend.clear_session()\n",
    "        def ANN_model(input_data):\n",
    "            model = keras.Sequential()\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron_in,\n",
    "                                         input_shape = (input_data.shape[1],), activation = 'relu'))  # Input  Layer\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron1,                  activation = 'relu'))  # Hidden Layer 1\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron2,                  activation = 'relu'))  # Hidden Layer 2\n",
    "            model.add(keras.layers.Dense(units = noOfNeuron_out,               )) # Output Layer\n",
    "            model.compile(optimizer= keras.optimizers.Adam(learning_rate = learningRate),\n",
    "                          loss=keras.losses.mean_absolute_error,\n",
    "                          metrics=['mse','mae','mape'])\n",
    "            return model\n",
    "        model = ANN_model(TrainData)\n",
    "\n",
    "        ################ 신경망 학습 ################\n",
    "\n",
    "        BestModel_temp = model.fit(TrainData, TrainLabel, epochs=Epoch, verbose=0, callbacks=[AccuracyPerEpoch()], batch_size=100)\n",
    "        print(\"\\n[Final Epochs]    RMSE:{:.5f},   MAE: {:.5f},  MAPE: {:.2f}%\"\n",
    "              .format(np.sqrt(BestModel_temp.history['mse'][-1]), BestModel_temp.history['mae'][-1], BestModel_temp.history['mape'][-1]))\n",
    "\n",
    "        # 모델 저장\n",
    "        model.save('D:/testoneblow/ANN_prediction5.0/k-fold/BestModel_M%d_Fold%d.h5'%(M+1,F+1))\n",
    "\n",
    "        # 히스토리 저장\n",
    "        RMSE  = np.sqrt(np.array(BestModel_temp.history['mse'])[:, np.newaxis])\n",
    "        MAE   = np.array(BestModel_temp.history['mae'])[:, np.newaxis]\n",
    "        MAPE  = np.array(BestModel_temp.history['mape'])[:, np.newaxis]\n",
    "\n",
    "        History_temp = pd.DataFrame(np.concatenate([RMSE,MAE,MAPE],axis=1))\n",
    "        History_temp.to_csv(\"D:/testoneblow/ANN_prediction5.0/k-fold/BestModel_M%d_Fold%d_history.csv\"%(M+1,F+1), index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "for F in range(Fold):\n",
    "    s = \"Model_Fold%d = keras.models.load_model('D:/testoneblow/ANN_prediction5.0/k-fold/BestModel_M1_Fold%d.h5')\"%(F+1,F+1)\n",
    "    exec(s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 1220 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000264EF2F4670> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 1221 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000264EE77EC10> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    }
   ],
   "source": [
    "for F in range (Fold):\n",
    "    s1 = \"real = ((ValidLabel_Fold%d)-0.5)*dist_value+min_value\"%(F+1)\n",
    "    exec(s1)\n",
    "    s2 = \"predict = (Model_Fold%d.predict(ValidData_Fold%d)-0.5)*dist_value+min_value\"%(F+1,F+1)\n",
    "    exec(s2)\n",
    "    s3 = 'Result_Fold%d =  pd.DataFrame(np.concatenate((real,predict), axis = 1))'%(F+1)\n",
    "    exec(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.737864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.908095</td>\n",
       "      <td>0.908095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>1.226881</td>\n",
       "      <td>1.226881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.708627</td>\n",
       "      <td>0.708627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>-0.987072</td>\n",
       "      <td>0.987072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>-0.077098</td>\n",
       "      <td>0.077098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>-0.646595</td>\n",
       "      <td>0.646595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>-0.012610</td>\n",
       "      <td>0.012610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>-1.419007</td>\n",
       "      <td>1.419007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>1.134576</td>\n",
       "      <td>1.134576</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3\n",
       "0   0.002639  0.002619  0.737864  0.737864\n",
       "1   0.002597  0.002574  0.908095  0.908095\n",
       "2   0.002549  0.002517  1.226881  1.226881\n",
       "3   0.002536  0.002518  0.708627  0.708627\n",
       "4   0.002529  0.002554 -0.987072  0.987072\n",
       "..       ...       ...       ...       ...\n",
       "15  0.002557  0.002559 -0.077098  0.077098\n",
       "16  0.002570  0.002587 -0.646595  0.646595\n",
       "17  0.002674  0.002674 -0.012610  0.012610\n",
       "18  0.002518  0.002553 -1.419007  1.419007\n",
       "19  0.002679  0.002649  1.134576  1.134576\n",
       "\n",
       "[20 rows x 4 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Error = pd.DataFrame(((Result_Fold1.iloc[:,0]-Result_Fold1.iloc[:,1])/Result_Fold1.iloc[:,0])*100)\n",
    "absError = np.abs(Error)\n",
    "Result1 = pd.DataFrame(np.concatenate((Result_Fold1,Error,absError),axis = 1))\n",
    "Result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "for F in range (Fold):\n",
    "    exec(\"MAE = pd.DataFrame(np.abs(Result_Fold%d.iloc[:,0]-Result_Fold%d.iloc[:,1]))\"%(F+1,F+1))\n",
    "    s1 = 'Error = pd.DataFrame(((Result_Fold%d.iloc[:,0]-Result_Fold%d.iloc[:,1])/Result_Fold%d.iloc[:,0])*100)'%(F+1,F+1,F+1)\n",
    "    exec(s1)\n",
    "    s2 = 'Result%d = pd.DataFrame(np.concatenate((Result_Fold%d,Error,np.abs(Error),MAE),axis = 1))'%(F+1,F+1)\n",
    "    exec(s2)\n",
    "    s3 = \"Result%d.to_csv('D:/testoneblow/ANN_prediction5.0/k-fold/Result%d.csv')\"%(F+1,F+1)\n",
    "    exec(s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>0.737864</td>\n",
       "      <td>1.946964e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002597</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.908095</td>\n",
       "      <td>0.908095</td>\n",
       "      <td>2.358485e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.002517</td>\n",
       "      <td>1.226881</td>\n",
       "      <td>1.226881</td>\n",
       "      <td>3.126731e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.708627</td>\n",
       "      <td>0.708627</td>\n",
       "      <td>1.797241e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>-0.987072</td>\n",
       "      <td>0.987072</td>\n",
       "      <td>2.495941e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.002559</td>\n",
       "      <td>-0.077098</td>\n",
       "      <td>0.077098</td>\n",
       "      <td>1.971571e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>-0.646595</td>\n",
       "      <td>0.646595</td>\n",
       "      <td>1.661677e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.002674</td>\n",
       "      <td>0.002674</td>\n",
       "      <td>-0.012610</td>\n",
       "      <td>0.012610</td>\n",
       "      <td>3.371234e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>-1.419007</td>\n",
       "      <td>1.419007</td>\n",
       "      <td>3.572491e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>1.134576</td>\n",
       "      <td>1.134576</td>\n",
       "      <td>3.039711e-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3             4\n",
       "0   0.002639  0.002619  0.737864  0.737864  1.946964e-05\n",
       "1   0.002597  0.002574  0.908095  0.908095  2.358485e-05\n",
       "2   0.002549  0.002517  1.226881  1.226881  3.126731e-05\n",
       "3   0.002536  0.002518  0.708627  0.708627  1.797241e-05\n",
       "4   0.002529  0.002554 -0.987072  0.987072  2.495941e-05\n",
       "..       ...       ...       ...       ...           ...\n",
       "15  0.002557  0.002559 -0.077098  0.077098  1.971571e-06\n",
       "16  0.002570  0.002587 -0.646595  0.646595  1.661677e-05\n",
       "17  0.002674  0.002674 -0.012610  0.012610  3.371234e-07\n",
       "18  0.002518  0.002553 -1.419007  1.419007  3.572491e-05\n",
       "19  0.002679  0.002649  1.134576  1.134576  3.039711e-05\n",
       "\n",
       "[20 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_Error_Fold = []\n",
    "Max_Error_Fold = []\n",
    "for F in range(Fold):\n",
    "    exec(\"a = np.mean(Result%d.iloc[:,3])\"%(F+1))\n",
    "    average_Error_Fold = np.append(average_Error_Fold,a)\n",
    "    exec(\"b = np.max(Result%d.iloc[:,3])\"%(F+1))\n",
    "    Max_Error_Fold = np.append(Max_Error_Fold,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.83891537, 1.06890633, 0.5911853 , 0.50649926, 1.02988992])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_Error_Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8070792381662617"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_Error = np.mean(average_Error_Fold)\n",
    "average_Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.74860354, 3.71573225, 1.70588913, 1.84816508, 3.55075694])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Max_Error_Fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
